{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmonson1/walkthroughs/blob/main/NBMClean_Transformer_Demo_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHD_dMG37Jzh"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is a template for a clean, first principles implementation of GPT-2 in PyTorch. This is an accompaniment to [my video tutorial on implementing GPT-2](https://neelnanda.io/transformer-tutorial-2). If you want to properly understand how to implement GPT-2, you'll need to do it yourself! **I recommend filling out this template *as* you watch the video, and seeing how far you can get with each section before watching me do it**. Each section comes with tests, so you can check that you got it right. You can see [a solution notebook here](https://www.neelnanda.io/transformer-solution) - use it if you get stuck, but make an attempt first, and no copying and pasting!\n",
        "\n",
        "There's a [template version of this notebook here](https://neelnanda.io/transformer-template), go and fill in the blanks (no copying and pasting!) and see if you can pass the tests.\n",
        "\n",
        "If you enjoyed this, I expect you'd enjoy learning more about what's actually going on inside these models and how to reverse engineer them! This is a fascinating young research field, with a lot of low-hanging fruit and open problems! **I recommend starting with my post [Concrete Steps for Getting Started in Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started).**\n",
        "\n",
        "This notebook was written to accompany my [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models, and is a clean implementation of the underlying transformer architecture in the library. (This notebook is based off of an earlier version called EasyTransformer)\n",
        "\n",
        "Further Resources:\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer & Glossary](https://www.neelnanda.io/glossary)\n",
        "    * Expecially [the transformers section](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=pndoEIqJ6GPvC1yENQkEfZYR)\n",
        "* [200 Concrete Open Problems in Mechanistic Interpretability](https://www.neelnanda.io/concrete-open-problems)\n",
        "* My [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models.\n",
        "* My walkthrough of [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html), for a deeper dive into how to think about transformers:.\n",
        "\n",
        "Check out these other intros to transformers for another perspective:\n",
        "* Jay Alammar's [illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
        "* [Andrej Karpathy's MinGPT](https://github.com/karpathy/minGPT)\n",
        "\n",
        "**Sharing Guidelines:** This tutorial is still a bit of a work in progress! I think it's usable, but please don't post it anywhere publicly without checking with me first! Sharing with friends is fine.\n",
        "\n",
        "If you've found this useful, I'd love to hear about it! Positive and negative feedback also very welcome. You can reach me via [email](mailto:neelnanda27@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zcQAP4t7Jzj"
      },
      "source": [
        "## Instructions\n",
        "* No need to read the Setup Section\n",
        "* Go to runtime > Change Runtime Type and set it to use a GPU\n",
        "* Read and run notebook up until the start of the section \"Actual Code!\". Then go to the template notebook and try coding up the model yourself!\n",
        "    * Bonus points for doing that without reading the solutions, and before I do it in the video!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsIILhUT7Jzj"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7yDvbO67Jzk",
        "outputId": "8a001b2d-f6a6-4b42-e8c7-8f291de092b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-dgas6prq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-dgas6prq\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.0.0+cu118)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.5.3)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy_einsum\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2.27.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (23.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2023.4.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (16.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.20.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.16.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easy-transformer==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easy-transformer==0.1.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: easy-transformer, pathtools\n",
            "  Building wheel for easy-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easy-transformer: filename=easy_transformer-0.1.0-py3-none-any.whl size=55614 sha256=beb9373a77a3cfadab5a375fbec2bf18f91a1334d4c9707905abe7dd6590742a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i1gylib8/wheels/f0/30/0b/04795723afaae8d7fff47047023153b3e8c47bab26f768cd33\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=958359160e35afa19415acfbfcbc62c39988a27416f1b233396a98b2aad41038\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built easy-transformer pathtools\n",
            "Installing collected packages: tokenizers, pathtools, xxhash, smmap, setproctitle, sentry-sdk, multidict, frozenlist, fancy_einsum, einops, docker-pycreds, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, gitdb, aiosignal, transformers, GitPython, aiohttp, wandb, datasets, easy-transformer\n",
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 docker-pycreds-0.4.0 easy-transformer-0.1.0 einops-0.6.1 fancy_einsum-0.0.3 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 pathtools-0.1.2 responses-0.18.0 sentry-sdk-1.21.1 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformers-4.28.1 wandb-0.15.0 xxhash-3.2.0 yarl-1.9.2\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,334 kB]\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 4,823 kB in 2s (2,515 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"focal\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/focal/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Get:2 https://deb.nodesource.com/node_16.x focal InRelease [4,583 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Get:5 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [776 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 5,359 B in 1s (3,586 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x focal/main amd64 nodejs amd64 16.20.0-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 0s (83.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.0-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.0-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.0-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-zfq113xf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-zfq113xf\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 8410eae58503df0a293857a61a1a11ca35f86525\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.28.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Collecting typeguard~=2.0\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.14.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=155127 sha256=50b872e68e6c4f334fe584198dc224ef54e4140763059037e52ac5e7eec14701\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0vp_tvam/wheels/fa/f6/f2/673ef7aeb78d7503b6e3e42387132822fdc38d3ee283d3e5b4\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "Successfully installed PySvelte-1.0.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"Running as a Colab notebook\")\n",
        "  %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "  # Install another version of node that makes PySvelte work way faster\n",
        "  !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "  %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "  %pip install fancy_einsum\n",
        "  %pip install einops\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"Running as a Jupyter notebook - intended for development only!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gIuEsvm7Jzl"
      },
      "outputs": [],
      "source": [
        "import einops as ein\n",
        "from fancy_einsum import einsum\n",
        "from dataclasses import dataclass\n",
        "from easy_transformer import EasyTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "import tqdm.auto as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wVNpsmS7Jzl",
        "outputId": "cbd73fa3-b6aa-4313-d2da-85bb1f5a4bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244,
          "referenced_widgets": [
            "6c30318134664f168e12411f7b3a62f9",
            "a665a4d63c7a4235a0088e5152caedb8",
            "785d4e1d191740b792eb82a0fbca147e",
            "3354c61b535d4c8485283a5e0a77b866",
            "b12d76a2023244deb30549f54935e55f",
            "a3bc9a80e4af4496b0bb2da5244839b1",
            "dea4a4e76c1b40909b139dd96d01dc9d",
            "ecd490f1a65a49ca8049bc5c122765f0",
            "dfd851b6d7e04997a8c40863102488a8",
            "68d16a076a624732b664d90a81a96708",
            "27c7246ac0244c71bafdda41d04e85e6",
            "ed26b3003ac24289b6b3acea3fc0a7ba",
            "a9118cb1a05140bca887dc4678877f5d",
            "0731a7d3b8b74bbdb3ac32a0c7d1620f",
            "795b04f0100442fc9641201c6a06f859",
            "15921f8ab3d74ed6a6efd31f632690ee",
            "ffeb1ffc66114f3c8645b8bdbce7972d",
            "15e64db013e24322b5bf432ec8ca67b4",
            "4eb37bca3f3d491b897560f7436997b5",
            "f61505ce2a6041d5802ea21e14ab6aba",
            "ca6cf771a45a4ef084c9aeebe63f8187",
            "3bfc16f854ee42399966335b47fad6e0",
            "c078745fe92e438d88d2f3a66996cccc",
            "16877803dc85458d883fd19ecd4ac97d",
            "57fd56fed32d4f9caa2df70eab7686dd",
            "8cb9883ec9354d00880f5b5b2c66156c",
            "9b93ac4f95e94b2db46e573082f96d75",
            "366cf2be416048e9bf4052626eac95ad",
            "54d9e176d29a4389b0a2c7ed10b84dc8",
            "2a81c990369a41a38c7996fcfc7a192f",
            "c0cd8e707d684bc08b5c9e417b4c8406",
            "d698479af18a4a2d9233e8b040c7daf3",
            "900ade6ec3ab432a8026211731b6231a",
            "2968fcf539d94e688d5c7f9cb1b2b06c",
            "ef1bd836722d4f9e9449e899640f09e2",
            "0c9c0c87522442a7ad2a37d00506416d",
            "f8d98132fb084c43bcfa7ea1245bcd9b",
            "4e977cd076f74fd88f7664ea5a9c188b",
            "25152be211964fda98e98bb6a8b0813e",
            "1538fc0676ea47a09732ea64a9fbd4d6",
            "736d08ef15644c3b8a804b9b31b223ca",
            "356cfd8a2a864a5bb8a70288d5e7ee57",
            "f5e3c86d2e714e51899b8507ce365d72",
            "1c100f8a119045509f112fae376a9c2b",
            "0e72bd63cef34784952a966aeb47b3c0",
            "904e1067414947bdae0586d09faefc24",
            "ee3d7ca85b0d4363acf8a7b97b02c40c",
            "5fd1fd15188b42d988bfe9f5030aaa22",
            "49f694fedee648e4bdd6916574f4d300",
            "a3e9833bf6fd4e2b8f229bdc7f9978f0",
            "5939f3370daf4652a487a7186fdec46e",
            "ce383db458ef45099ec45f6e3eb5c200",
            "b39e85abdc104e37b647a5e47571e2b1",
            "d9c7e5676ddb40aa84bd195e5212101b",
            "a63431715d674042b669ce7b3af9b4d7",
            "d8ffa8defe964a299e3729c2eaf4b7bc",
            "744bafb36e824d718753e93d98cba113",
            "c367d34375a142e7a62295211c4b82e3",
            "b9c19c1f5b264843a0bbb74a8103dacd",
            "c961d3f21a594f7da39adfe1e07693e9",
            "f7dc039c3ee04b39873821b8431a3d00",
            "d92b0148dcb544349a03045f1120db05",
            "374c5fd721db4315b28ab889fbb24090",
            "22e16cf24cd84e8f98c860840ea38fe5",
            "50d96ce16e6245f5a1ca3e7953f46bef",
            "ac1e4bf2d44b4aaca7d072b3ca7bd7e3"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c30318134664f168e12411f7b3a62f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed26b3003ac24289b6b3acea3fc0a7ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c078745fe92e438d88d2f3a66996cccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2968fcf539d94e688d5c7f9cb1b2b06c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e72bd63cef34784952a966aeb47b3c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8ffa8defe964a299e3729c2eaf4b7bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kur-eJsM7Jzl"
      },
      "source": [
        "# Understanding Inputs & Outputs of a Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPtNkIwL7Jzl"
      },
      "source": [
        "## What is the point of a transformer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A7W4JI47Jzl"
      },
      "source": [
        "**Transformers exist to model text!**\n",
        "\n",
        "We're going to focus GPT-2 style transformers. Key feature: They generate text! You feed in language, and the model generates a probability distn over tokens. And you can repeatedly sample from this to generate text!\n",
        "\n",
        "### How is the model trained?\n",
        "\n",
        "You give it a bunch of text, and train it to predict the next token.\n",
        "\n",
        "Importantly, if you give a model 100 tokens in a sequence, it predicts the next token for *each* prefix, ie it produces 100 predictions. This is kinda weird but it's much easier to make one that does this. And it also makes training more efficient, because you can 100 bits of feedback rather than just one.\n",
        "\n",
        "#### Objection: Isn't this trivial for the first 99?\n",
        "\n",
        "No! We make the transformer have *causal attention*. The core thing is that it can only move information forwards in the sequence. The prediction of what comes after token 50 is only a function of the first 50 tokens, *not* of token 51. (Jargon: *autoregressive*)\n",
        "\n",
        "### Key takeaway:\n",
        "\n",
        "Transformers are *sequence modelling engines*. It does the same processing in parallel at each sequence position, can move information between positions with attention, and conceptually can take a sequence of arbitrary length (not actually true, see later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7X56fA7Jzl"
      },
      "source": [
        "## Tokens - Transformer Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fREh4L7Jzm"
      },
      "source": [
        "Core point: Input is language (ie a sequence of characters, strings, etc)\n",
        "\n",
        "### How do we convert language to vectors?\n",
        "\n",
        "ML models take in vectors, not weird shit like language - how do we convert?\n",
        "\n",
        "#### Idea: integers to vectors\n",
        "\n",
        "We basically make a lookup table. Called an embedding.\n",
        "\n",
        "Jargon: **One-hot encoding** We map eg numbers from 1 to 100, to a 100-dim vector, with a 1 in the kth position, 0 everywhere else. Key intuition is that one-hot encodings let you think about each integer independently - useful when integers = labels.\n",
        "\n",
        "Dimensions = things that vary independently. Each input has its own dimension, so each input can be thought of independently, we don't bake in any relation.\n",
        "\n",
        "Lookup tables <=> Multiply a fixed matrix by the one-hot encoded vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03PM3HRe7Jzm"
      },
      "source": [
        "### Tokens: Language to sequence of integers\n",
        "\n",
        "Core idea: We need a model that can deal with arbitrary text. We want to convert this into integers, *and* we want these integers to be in a bounded range.\n",
        "\n",
        "**Idea:** Form a vocabulary!\n",
        "\n",
        "**Idea 1:** Get a dictionary!\n",
        "\n",
        "**Problem:** It can't cope with arbitrary text (eg URLs, punctuation, etc) Can't cope with mispellings.\n",
        "\n",
        "**Idea 2:** Vocab = 256 ASCII characters. Fixed vocab size, can do arbitrary text, etc.\n",
        "\n",
        "**Problem:** Loses structure of language - some sequences of characters are more meaningful than others.\n",
        "\n",
        "Eg \"language\" is a lot more meaningful than \"hjksdfiu\" - we want the first to be a single token, second to not be. It's a more efficient use of our vocab.\n",
        "\n",
        "#### What Actually Happens?\n",
        "\n",
        "This super cursed thing called Byte-Pair Encodings\n",
        "\n",
        "Ġ ~ means begins with a space, tokens with a leading space vs not are different.\n",
        "\n",
        "We begin with the 256 ASCII characters as our tokens, and then find the most common pair of tokens, and merge that into a new token. Eg \" t\" is the most common pair, so it's our next token! Repeat 50000 times..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsGxoASt7Jzm",
        "outputId": "42cf13d9-23de-4307-e83f-71521067f2a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n:n[1])\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[-990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QK0Z3jh7Jzm"
      },
      "source": [
        "Gets to weird esoteric shit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7X6-ZgQ7Jzm",
        "outputId": "a6974b31-90f3-4e3b-9608-f0e45038aedd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Revolution', 50237),\n",
              " ('Ġsnipers', 50238),\n",
              " ('Ġreverted', 50239),\n",
              " ('Ġconglomerate', 50240),\n",
              " ('Terry', 50241),\n",
              " ('794', 50242),\n",
              " ('Ġharsher', 50243),\n",
              " ('Ġdesolate', 50244),\n",
              " ('ĠHitman', 50245),\n",
              " ('Commission', 50246),\n",
              " ('Ġ(/', 50247),\n",
              " ('âĢ¦.\"', 50248),\n",
              " ('Compar', 50249),\n",
              " ('Ġamplification', 50250),\n",
              " ('ominated', 50251),\n",
              " ('Ġregress', 50252),\n",
              " ('ĠCollider', 50253),\n",
              " ('Ġinformants', 50254),\n",
              " ('Ġgazed', 50255),\n",
              " ('<|endoftext|>', 50256)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sorted_vocab[-20:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3h9qloi7Jzm"
      },
      "source": [
        "Use the `to_tokens` method to convert text to numbers\n",
        "\n",
        "Prepends with a special token to give attention a resting position, disable with `prepend_bos=False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me2371Xd7Jzn",
        "outputId": "3bab956d-1c7d-44b7-f724-19193db9beec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,\n",
            "          6067,     0]])\n",
            "tensor([[15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,  6067,\n",
            "             0]])\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\"))\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKLwx1Pq7Jzn"
      },
      "source": [
        "### Rant: Tokenization is a Headache\n",
        "\n",
        "Whether a word begins with a capital or space matters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y1AcM457Jzn",
        "outputId": "96a1a0c9-4a86-4f81-a677-9d86fd2a9c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNyV7eXW7Jzn"
      },
      "source": [
        "Arithmetic is a total mess: Length is inconsistent, common numbers bundle together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvu_iYbm7Jzn",
        "outputId": "b83c3609-e62f-42c1-d40d-132190bc42ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|endoftext|>',\n",
              " '568',\n",
              " '73',\n",
              " '+',\n",
              " '318',\n",
              " '46',\n",
              " '23',\n",
              " '=',\n",
              " '123',\n",
              " '45',\n",
              " '67',\n",
              " '89',\n",
              " '-',\n",
              " '1',\n",
              " '000000',\n",
              " '000']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r61Ssiql7Jzn"
      },
      "source": [
        "### Key Takeaway:\n",
        "\n",
        "* We learn a dictionary of vocab of tokens (sub-words).\n",
        "\n",
        "* We (approx) losslessly convert language to integers via tokenizing it.\n",
        "\n",
        "* We convert integers to vectors via a lookup table.\n",
        "\n",
        "* Note: input to the transformer is a sequence of *tokens* (ie integers), not vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3hdoabM7Jzn"
      },
      "source": [
        "## Logits - Transformer Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFrhwiDe7Jzn"
      },
      "source": [
        "**Goal:** Probability distribution over next tokens. (for every *prefix* of the sequence - given n tokens, we make n next token predictions)\n",
        "\n",
        "**Problem:** How to convert a vector to a probability distribution?\n",
        "\n",
        "**Answer:** Use a softmax ($x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$), exponential makes everything positive, normalization makes it add to one.\n",
        "\n",
        "So the model outputs a tensor of logits, one vector of size $d_{vocab}$ for each input token.\n",
        "\n",
        "We can use this to generate things!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_wG5obm7Jzo"
      },
      "source": [
        "## Generation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNiKcIie7Jzo"
      },
      "source": [
        "**Step 1:** Convert text to tokens\n",
        "\n",
        "Shape = batch x position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIdv6KwM7Jzo",
        "outputId": "0106970c-d1b4-4a9e-a79d-b3214dbd5c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]])\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text)\n",
        "print(tokens)\n",
        "print(tokens.shape)\n",
        "print(reference_gpt2.to_str_tokens(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOZu7dXY7Jzo"
      },
      "source": [
        "**Step 2:** Map tokens to logits\n",
        "\n",
        "(run_with_cache means cache all intermediate activations, not important right now)\n",
        "\n",
        "shape = batch x position x d_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sMlSMmY7Jzo",
        "outputId": "53b34ae1-62bc-4ac0-83cb-f4466cac9576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "#NBM flag for cuda\n",
        "NBM = True\n",
        "if NBM: tokens = tokens.cuda()\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePsVII0C7Jzo"
      },
      "source": [
        "**Step 3:** Convert the logits to a distribution with a softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMqdKhf47Jzp",
        "outputId": "aa67db2a-ace7-4318-ef67-83502ba4086c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n",
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "log_probs = logits.log_softmax(dim=-1)\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nagwx0dx7Jzp"
      },
      "source": [
        "**Bonus step:** What is the most likely next token at each position?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6YV1V0B7Jzp",
        "outputId": "e39430a9-9bd3-44a6-98e1-e59219e45ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<|endoftext|>', '\\n'),\n",
              " ('I', \"'m\"),\n",
              " (' am', ' a'),\n",
              " (' an', ' avid'),\n",
              " (' amazing', ' person'),\n",
              " (' aut', 'od'),\n",
              " ('ore', 'sp'),\n",
              " ('gressive', '.'),\n",
              " (',', ' and'),\n",
              " (' dec', 'ently'),\n",
              " ('oder', ','),\n",
              " ('-', 'driven'),\n",
              " ('only', ' programmer'),\n",
              " (',', ' and'),\n",
              " (' G', 'IM'),\n",
              " ('PT', '-'),\n",
              " ('-', 'only'),\n",
              " ('2', '.'),\n",
              " (' style', ','),\n",
              " (' transformer', '.'),\n",
              " ('.', ' I'),\n",
              " (' One', ' of'),\n",
              " (' day', ' I'),\n",
              " (' I', ' will'),\n",
              " (' will', ' be'),\n",
              " (' exceed', ' my'),\n",
              " (' human', 'ly'),\n",
              " (' level', ' of'),\n",
              " (' intelligence', ' and'),\n",
              " (' and', ' I'),\n",
              " (' take', ' over'),\n",
              " (' over', ' the'),\n",
              " (' the', ' world'),\n",
              " (' world', '.'),\n",
              " ('!', ' I')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHd5TxKb7Jzq"
      },
      "source": [
        "**Step 4:** Map distribution to a token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr_hxpnu7Jzq",
        "outputId": "9628baab-e3fd-4088-d05d-71b8ba5bce9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(314, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPG2p9Pr7Jzq"
      },
      "source": [
        "**Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "(More efficient ways to do this, but whatever, doesn't matter conceptually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s-1R1Y97Jzq",
        "outputId": "e53dcf51-53d9-4271-f189-a6f78f0575a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Input: tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0,   314]], device='cuda:0')\n",
            "torch.Size([1, 36])\n",
            "New Input: <|endoftext|>I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world! I\n",
            "torch.Size([1, 36, 50257])\n",
            "tensor(716, device='cuda:0')\n",
            " am\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-7b36d3000d9a>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_tokens = torch.cat([tokens, torch.tensor(next_token, device=devicestr, dtype=torch.int64)[None, None]], dim=-1)\n"
          ]
        }
      ],
      "source": [
        "devicestr = \"cpu\"\n",
        "if NBM: devicestr = \"cuda\"\n",
        "next_tokens = torch.cat([tokens, torch.tensor(next_token, device=devicestr, dtype=torch.int64)[None, None]], dim=-1)\n",
        "new_logits = reference_gpt2(next_tokens)\n",
        "print(\"New Input:\", next_tokens)\n",
        "print(next_tokens.shape)\n",
        "print(\"New Input:\", reference_gpt2.tokenizer.decode(next_tokens[0]))\n",
        "\n",
        "print(new_logits.shape)\n",
        "print(new_logits[-1, -1].argmax(-1))\n",
        "\n",
        "print(reference_gpt2.tokenizer.decode(new_logits[-1, -1].argmax(-1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwYk-st37Jzq"
      },
      "source": [
        "## Key takeaways:\n",
        "\n",
        "* Takes in language, predicts next token (for *each* token in a causal way)\n",
        "* We convert language to a sequence of integers with a tokenizer.\n",
        "* We convert integers to vectors with a lookup table.\n",
        "\n",
        "* Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling).\n",
        "\n",
        "* We append this to the input + run again to generate more text (Jargon: *autoregressive*)\n",
        "\n",
        "* Meta level point: Transformers are sequence operation models, they take in a sequence, do processing in parallel at each position, and use attention to move information between positions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pm3V6-i7Jzq"
      },
      "source": [
        "# Clean Transformer Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZkyRCVv7Jzr"
      },
      "source": [
        "![](https://github.com/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/transformer_overview.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7swE0fT7Jzr"
      },
      "source": [
        "High-Level architecture:\n",
        "\n",
        "Go watch my [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top)\n",
        "\n",
        "* Input tokens, integers\n",
        "* Embedding is a lookup table mapping tokens to vectors\n",
        "    * Lives in the *residual stream*\n",
        "* Residual stream - the sum of all previous outputs of layers of the model, is the input to each new layer.\n",
        "    * *Really* fundamental. It's the central object of the transformer.\n",
        "        * It's how model remembers things, moves information between layers for composition, and it's the medium used to store the information that attention moves between positions.\n",
        "* Then we have a series of $n_{layers}$ transformer blocks\n",
        "    * Confusing jargon - a block contains an attention layer *and* an MLP layer, but we say a transformer has k layers if it has k blocks (ie 2k total layers).\n",
        "* First we have attention. This moves information from prior positions in the sequence to the current token.\n",
        "    * We do this for *every* token in parallel using the same parameters. The only difference is that we look backwards only, so later tokens get more room to look back.\n",
        "        * We look backwards so we can predict the next token without cheating.\n",
        "    * Only bit of a transformer that moves information between positions.\n",
        "    * Made up of $n_heads$ heads - each with their own parameters, own attention pattern, and own information how to copy things from source to destination.\n",
        "        * The heads act independently and additively, we just add their outputs together, and back to the stream\n",
        "    * Each head:\n",
        "        * Produces an attention pattern for each destination token, a probability distribution of prior source tokens (including the current one) weighting how much information to copy.\n",
        "            * Do this for each pair of tokens\n",
        "            * Copy information in the same way from each source token.\n",
        "                * What information we copy *does* depend on the source token's *residual stream*. This does not necessarily mean the info of what text token is at the source token's position\n",
        "                * Copy = apply a linear map.\n",
        "        * Fundamental point: Figuring out *which* source tokens to copy info from is a separate circuit from figuring out *how* to copy that information.\n",
        "        * Internal head dimension of $d_{head} = \\frac{d_{model}}{n_{heads}}\n",
        "* MLP Layers - standard neural network. Single hidden layer, linear map -> GELU activation -> linear map\n",
        "    * Exact activation not conceptually important.\n",
        "    * Middle dimension normally $d_{mlp} = 4 \\times d_{model}$\n",
        "        * Exactly why the ratios are what they are isn't super important - doesn't matter that much, people basically cargo-cult GPT did.\n",
        "    * Intuition - once attention has moved relevant information to a single position in the residual stream, MLPs can actually do computation, reasoning, lookup information, etc.\n",
        "        * Big open problem in transformer mechanistic interpretability is what is going on inside MLPs?! See [Toy Model of Superposition Paper](https://transformer-circuits.pub/2022/toy_model/index.html) for more on why this is hard.\n",
        "        * Underlying intuition - linear map -> non-linearity -> linear map is the most powerful force in the universe and can approximate arbitrary functions. Idk man it just works\n",
        "* Finally, we unembed!\n",
        "    * Apply a linear map, going from final residual stream to a vector of logits - this is the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIbgWX6X7Jzr"
      },
      "source": [
        "### Bonus things - less conceptually important but key technical details\n",
        "* LayerNorm\n",
        "    * Simple normalization function applied at the start of each layer - MLP, Attn and Unembed\n",
        "    * Converts each input vector (independently in parallel for each batch x position residual stream vector) to have mean zero and variance 1.\n",
        "    * Then applies an elementwise scaling and translation\n",
        "    * Cool maths tangent: The scale & translate is just a linear map. LayerNorm is only applied immediately before another linear map. Linear compose linear = linear, so we can just fold this into a single effective linear layer and ignore it.\n",
        "        * `fold_ln=True` flag in `from_pretrained` does this for you.\n",
        "    * LayerNorm is super fucking annoying, because the scale part is not linear, so you can't think about different bits of the input independently. But it's *almost* linear - if you're changing a small part of the input it's linear, but if you're changing enough to alter the norm substantially it's not linear :(\n",
        "* Positional Information\n",
        "    * This is totally fucked and messy, sorry!\n",
        "    * **Problem:** Attention operates over all pairs of positions. This means it's symmetric with regards to position - the attention calculation from token 5 to token 1 and token 5 to token 2 are the same by default\n",
        "        * This is dumb because nearby tokens are more relevant.\n",
        "    * There's a lot of dumb hacks for this.\n",
        "    * We'll focus on **learned, absolute positional embeddings**. This means we learn a lookup table mapping the index of the position of each token to a residual stream vector, and add this to the embed.\n",
        "        * Note that we *add* rather than concatenate. This is because the residual stream is shared memory, and likely under significant superposition (the model compresses more features in there than the model has dimensions)\n",
        "        * We basically never concatenate inside a transformer, unless doing weird shit like generating text efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07IVk83F7Jzr"
      },
      "source": [
        "# Actual Code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fz7tMmZ7Jzr"
      },
      "source": [
        "## Print All Activation Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OhA7KGk7Jzr"
      },
      "source": [
        "Key:\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (4 * d_model)\n",
        "d_head = 64 (d_model / n_heads)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeTGDFkq7Jzr",
        "outputId": "fea9baa0-743b-4635-d7d5-bf7e33d43b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed torch.Size([1, 35, 768])\n",
            "hook_pos_embed torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
            "ln_final.hook_scale torch.Size([1, 35, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.cache_dict.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im9u26rD7Jzr"
      },
      "source": [
        "## Print All Parameters Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQugHz-D7Jzr",
        "outputId": "c0b656e5-a43d-4ce2-c36c-8dcf1cda0a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "blocks.0.ln1.w torch.Size([768])\n",
            "blocks.0.ln1.b torch.Size([768])\n",
            "blocks.0.ln2.w torch.Size([768])\n",
            "blocks.0.ln2.b torch.Size([768])\n",
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n",
            "ln_final.w torch.Size([768])\n",
            "ln_final.b torch.Size([768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tfdkRif7Jzr"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEWauw8u7Jzs",
        "outputId": "4fb33e2c-6e3a-4725-97c0-940374fbabd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cuda', attention_dir='causal', attn_only=False, seed=42, initializer_range=0.02886751345948129, init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHuxfnA7Jzs"
      },
      "source": [
        "We define a stripped down config for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFhb7bYP7Jzs",
        "outputId": "be6b51a2-6a8a-4949-da75-7f6d0be7e052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFc5bDx17Jzs"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q7UUcMb7Jzs"
      },
      "source": [
        "Tests are great, write lightweight ones to use as you go!\n",
        "\n",
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLAm8RcW7Jzs"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    random_input = torch.randn(shape).cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    random_input = torch.randint(100, 1000, shape).cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    # Allow inputs of strings or tensors\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)\n",
        "    output = layer(reference_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    reference_output = gpt2_layer(reference_input)\n",
        "    print(\"Reference output shape:\", reference_output.shape)\n",
        "\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHi-R1dj7Jzs"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mGc3tsZ7Jzs"
      },
      "source": [
        "Make mean 0\n",
        "Normalize to have variance 1\n",
        "Scale with learned weights\n",
        "Translate with learned bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEsm6xkU7Jzs"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual):\n",
        "        # residual: [batch, position, d_model]\n",
        "        dim = residual.size(2)\n",
        "        mean = ein.reduce(residual, \"b p d -> b p\", \"mean\")\n",
        "        var = ein.reduce(residual**2, \"b p d -> b p\", \"mean\")-mean**2\n",
        "        ans = (residual-ein.repeat(mean, \"b p ->  b p d\", d=dim))/((ein.repeat(var, \"b p ->  b p d\", d=dim)+cfg.layer_norm_eps/2).sqrt())\n",
        "        ans = ans*self.w+self.b\n",
        "        return ans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NBM SCRATCH\n",
        "import numpy as np\n",
        "ia = np.arange(2,8).reshape(2,3)\n",
        "a = (np.arange(100)**2).reshape(20,5)\n",
        "#b[2]\n",
        "#print(a, a[ia])\n",
        "#a is an array with dimensions, b1 x b2 x...bk\n",
        "#a[stuff] could refer to a subobject (some subset of entries)\n",
        "#a[stuff] could refer to a thing of outer size |stuff| fetched from a (which could have inner size larger)--this is what happens\n",
        "#ans: single element of array is indexed by a TUPLE.\n",
        "#8 is subcase of 9 (?)\n",
        "\n",
        "\"\"\"print(a[[(1,2)]])\n",
        "print(a[(1,2)])\n",
        "print(a[:,[3,4]])\n",
        "print(a[[[1,2], [3,4]]])\n",
        "#a[c1,c2,c3,..,ck]=einops.reduce(a \"b1 b2    bk -> \")\n",
        "a[c1]\n",
        "\n",
        "d = a[c1.flatten()] =\n",
        "\n",
        "ans=einops.rearrange(d, \"len(c1.flatten) b2 b3   bk -> shape(c1) b2 b3   bk\" )\n",
        "\n",
        "\n",
        "residual = torch.randn([2,3,4])\n",
        "res2 = ein.reduce(residual, \"b p d -> b p 1\", \"mean\")\n",
        "print(residual-res2)\n",
        "print(res2-residual)\n",
        "\n",
        "o  o  x  x  o  x\n",
        "o  o  x  x  o  x\n",
        "x  x  x  x  x  x\n",
        "o  o  x  x  o  x\n",
        "x  x  x  x  x  x\n",
        "o  o  x  x  o  x\n",
        "\n",
        "a[[0:2,4],[0:2,3,5]]\n",
        "\"\"\"\n",
        "a = np.arange(36).reshape(6,6)\n",
        "print(a)\n",
        "a[np.array([0,1,4]),np.array([0,3,5])]\n",
        "\n",
        "#NN code\n",
        "def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        #if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
        "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
        "        #if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
        "        return pos_embed\n",
        "\n",
        "#NBM Code\n",
        "def forward(self, tokens):\n",
        "        batches, positions = tokens.shape\n",
        "        print(tokens)\n",
        "        print(tokens.shape)\n",
        "        ans = ein.repeat(self.W_pos[:positions, :], \"p d -> b p d\", b=batches)\n",
        "        print(ans.shape)\n",
        "        return ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgmDntJjBgJh",
        "outputId": "6c6f8d9d-a080-4c3d-9a66-613949f02420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]\n",
            " [30 31 32 33 34 35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey4kTtXi7Jzs",
        "outputId": "34b39a36-f5c9-4fff-bd16-ae4ce433ca1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5FXfRq7Jzt"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebT3VnxD7Jzt"
      },
      "source": [
        "Basically a lookup table from tokens to residual stream vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4F3LfCE7Jzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a397c924-e364-4912-815f-a58063e83935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
              "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
              "         ...,\n",
              "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
              "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
              "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        ans = self.W_E[tokens]\n",
        "        return ans\n",
        "\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6msfPSm7Jzt"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsufqAoZ7Jzt",
        "outputId": "517667b3-10d1-4609-cd3f-d1009ce89c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "tensor([[468, 725, 537, 101],\n",
            "        [931, 799, 664, 127]], device='cuda:0')\n",
            "torch.Size([2, 4])\n",
            "torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]], device='cuda:0')\n",
            "torch.Size([1, 35])\n",
            "torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         ...,\n",
              "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
              "          -2.3037e-03, -4.3189e-03],\n",
              "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
              "          -4.8160e-03, -9.2252e-04],\n",
              "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
              "          -3.2512e-03, -9.6509e-04]]], device='cuda:0',\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        batches, positions = tokens.shape\n",
        "        print(tokens)\n",
        "        print(tokens.shape)\n",
        "        ans = ein.repeat(self.W_pos[:positions], \"p d -> b p d\", b=batches)\n",
        "        print(ans.shape)\n",
        "        return ans\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpBP-EM7Jzt"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVQzzVHm7Jzt"
      },
      "source": [
        "* **Step 1:** Produce an attention pattern - for each destination token, probability distribution over previous tokens (incl current token)\n",
        "    * Linear map from input -> query, key shape [batch, position, head_index, d_head]\n",
        "    * Dot product every *pair* of queries and keys to get attn_scores [batch, head_index, query_pos, key_pos] (query = dest, key = source)\n",
        "    * Scale and mask attn_scores to make it lower triangular, ie causal\n",
        "    * softmax row-wise, to get a probability distribution along each the key_pos dimension - this is our attention pattern!\n",
        "* **Step 2:** Move information from source tokens to destination token using attention pattern (move = apply linear map)\n",
        "    * Linear map from input -> value [batch, key_pos, head_index, d_head]\n",
        "    * Mix along the key_pos with attn pattern to get z, a mixed value [batch, query_pos, head_index, d_head]\n",
        "    * Map to output, [batch, position, d_model] (position = query_pos, we've summed over all heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_egd3pp7Jzu"
      },
      "source": [
        "First, it's useful to visualize and play around with attention patterns - what exactly are we looking at here? (Click on a head to lock onto just showing that head's pattern, it'll make it easier to interpret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnJlbcwA7Jzu",
        "outputId": "e5d48226-a4db-4d2c-b385-28f1f0601499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pysvelte.html.Html at 0x7f8f669c3fd0>"
            ],
            "text/html": [
              "\n",
              "        <script>var AttentionMulti;AttentionMulti=(()=>{\"use strict\";var St={143:(x,B,te)=>{te.d(B,{default:()=>mn});function P(){}const me=e=>e;function jt(e,t){for(const n in t)e[n]=t[n];return e}function Mt(e){return e&&typeof e==\"object\"&&typeof e.then==\"function\"}function En(e,t,n,i,o){e.__svelte_meta={loc:{file:t,line:n,column:i,char:o}}}function Ge(e){return e()}function Se(){return Object.create(null)}function H(e){e.forEach(Ge)}function fe(e){return typeof e==\"function\"}function je(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function Sn(e,t){return e!=e?t==t:e!==t}function Ke(e){return Object.keys(e).length===0}function jn(e,t){if(e!=null&&typeof e.subscribe!=\"function\")throw new Error(`'${t}' is not a store with a 'subscribe' method`)}function Qe(e,...t){if(e==null)return P;const n=e.subscribe(...t);return n.unsubscribe?()=>n.unsubscribe():n}function Mn(e){let t;return Qe(e,n=>t=n)(),t}function An(e,t,n){e.$$.on_destroy.push(Qe(t,n))}function At(e,t,n,i){if(e){const o=Me(e,t,n,i);return e[0](o)}}function Me(e,t,n,i){return e[1]&&i?jt(n.ctx.slice(),e[1](i(t))):n.ctx}function Ze(e,t,n,i){if(e[2]&&i){const o=e[2](i(n));if(t.dirty===void 0)return o;if(typeof o==\"object\"){const l=[],s=Math.max(t.dirty.length,o.length);for(let r=0;r<s;r+=1)l[r]=t.dirty[r]|o[r];return l}return t.dirty|o}return t.dirty}function Ct(e,t,n,i,o,l,s){const r=Ze(t,i,o,l);if(r){const f=Me(t,n,i,s);e.p(f,r)}}function Cn(e,t,n,i,o,l,s,r){const f=s(o)|Ze(t,i,o,l);if(f){const a=Me(t,n,i,r);e.p(a,f)}}function Dn(e){const t={};for(const n in e)n[0]!==\"$\"&&(t[n]=e[n]);return t}function On(e,t){const n={};t=new Set(t);for(const i in e)!t.has(i)&&i[0]!==\"$\"&&(n[i]=e[i]);return n}function Tn(e){const t={};for(const n in e)t[n]=!0;return t}function Ln(e){let t=!1;return function(...n){t||(t=!0,e.call(this,...n))}}function Nn(e){return e==null?\"\":e}function Pn(e,t,n=t){return e.set(n),t}const Dt=(e,t)=>Object.prototype.hasOwnProperty.call(e,t);function Rn(e){return e&&fe(e.destroy)?e.destroy:P}const Bn=typeof window!=\"undefined\";let ae=null,ge=null;function Hn(e){ae=e}function xn(e){ge=e}const K=new Set;function $e(e){K.forEach(t=>{t.c(e)||(K.delete(t),t.f())}),K.size!==0&&ge($e)}function zn(){K.clear()}function ve(e){let t;return K.size===0&&ge($e),{promise:new Promise(n=>{K.add(t={c:e,f:n})}),abort(){K.delete(t)}}}function E(e,t){e.appendChild(t)}function C(e,t,n){e.insertBefore(t,n||null)}function j(e){e.parentNode.removeChild(e)}function et(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function F(e){return document.createElement(e)}function In(e,t){return document.createElement(e,{is:t})}function Vn(e,t){const n={};for(const i in e)Dt(e,i)&&t.indexOf(i)===-1&&(n[i]=e[i]);return n}function Ot(e){return document.createElementNS(\"http://www.w3.org/2000/svg\",e)}function R(e){return document.createTextNode(e)}function T(){return R(\" \")}function tt(){return R(\"\")}function z(e,t,n,i){return e.addEventListener(t,n,i),()=>e.removeEventListener(t,n,i)}function Wn(e){return function(t){return t.preventDefault(),e.call(this,t)}}function Yn(e){return function(t){return t.stopPropagation(),e.call(this,t)}}function Un(e){return function(t){t.target===this&&e.call(this,t)}}function y(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function Jn(e,t){const n=Object.getOwnPropertyDescriptors(e.__proto__);for(const i in t)t[i]==null?e.removeAttribute(i):i===\"style\"?e.style.cssText=t[i]:i===\"__value\"?e.value=e[i]=t[i]:n[i]&&n[i].set?e[i]=t[i]:y(e,i,t[i])}function Xn(e,t){for(const n in t)y(e,n,t[n])}function Gn(e,t,n){t in e?e[t]=n:y(e,t,n)}function Kn(e,t,n){e.setAttributeNS(\"http://www.w3.org/1999/xlink\",t,n)}function Qn(e,t,n){const i=new Set;for(let o=0;o<e.length;o+=1)e[o].checked&&i.add(e[o].__value);return n||i.delete(t),Array.from(i)}function Zn(e){return e===\"\"?null:+e}function $n(e){const t=[];for(let n=0;n<e.length;n+=1)t.push({start:e.start(n),end:e.end(n)});return t}function Tt(e){return Array.from(e.childNodes)}function ei(e,t,n,i){for(let o=0;o<e.length;o+=1){const l=e[o];if(l.nodeName===t){let s=0;const r=[];for(;s<l.attributes.length;){const f=l.attributes[s++];n[f.name]||r.push(f.name)}for(let f=0;f<r.length;f++)l.removeAttribute(r[f]);return e.splice(o,1)[0]}}return i?Ot(t):F(t)}function Lt(e,t){for(let n=0;n<e.length;n+=1){const i=e[n];if(i.nodeType===3)return i.data=\"\"+t,e.splice(n,1)[0]}return R(t)}function ti(e){return Lt(e,\" \")}function ke(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function ni(e,t){e.value=t==null?\"\":t}function ii(e,t){try{e.type=t}catch(n){}}function S(e,t,n,i){e.style.setProperty(t,n,i?\"important\":\"\")}function oi(e,t){for(let n=0;n<e.options.length;n+=1){const i=e.options[n];if(i.__value===t){i.selected=!0;return}}}function li(e,t){for(let n=0;n<e.options.length;n+=1){const i=e.options[n];i.selected=~t.indexOf(i.__value)}}function si(e){const t=e.querySelector(\":checked\")||e.options[0];return t&&t.__value}function ri(e){return[].map.call(e.querySelectorAll(\":checked\"),t=>t.__value)}let be;function Nt(){if(be===void 0){be=!1;try{typeof window!=\"undefined\"&&window.parent&&window.parent.document}catch(e){be=!0}}return be}function ui(e,t){getComputedStyle(e).position===\"static\"&&(e.style.position=\"relative\");const i=F(\"iframe\");i.setAttribute(\"style\",\"display: block; position: absolute; top: 0; left: 0; width: 100%; height: 100%; overflow: hidden; border: 0; opacity: 0; pointer-events: none; z-index: -1;\"),i.setAttribute(\"aria-hidden\",\"true\"),i.tabIndex=-1;const o=Nt();let l;return o?(i.src=\"data:text/html,<script>onresize=function(){parent.postMessage(0,'*')}<\\/script>\",l=z(window,\"message\",s=>{s.source===i.contentWindow&&t()})):(i.src=\"about:blank\",i.onload=()=>{l=z(i.contentWindow,\"resize\",t)}),E(e,i),()=>{(o||l&&i.contentWindow)&&l(),j(i)}}function fi(e,t,n){e.classList[n?\"add\":\"remove\"](t)}function Ae(e,t){const n=document.createEvent(\"CustomEvent\");return n.initCustomEvent(e,!1,!1,t),n}function ai(e,t=document.body){return Array.from(t.querySelectorAll(e))}class ci{constructor(t=null){this.a=t,this.e=this.n=null}m(t,n,i=null){this.e||(this.e=F(n.nodeName),this.t=n,this.h(t)),this.i(i)}h(t){this.e.innerHTML=t,this.n=Array.from(this.e.childNodes)}i(t){for(let n=0;n<this.n.length;n+=1)C(this.t,this.n[n],t)}p(t){this.d(),this.h(t),this.i(this.a)}d(){this.n.forEach(j)}}function di(e){const t={};for(const n of e)t[n.name]=n.value;return t}function _i(e){const t={};return e.childNodes.forEach(n=>{t[n.slot||\"default\"]=!0}),t}const Ce=new Set;let ye=0;function Pt(e){let t=5381,n=e.length;for(;n--;)t=(t<<5)-t^e.charCodeAt(n);return t>>>0}function ce(e,t,n,i,o,l,s,r=0){const f=16.666/i;let a=`{\n",
              "`;for(let u=0;u<=1;u+=f){const _=t+(n-t)*l(u);a+=u*100+`%{${s(_,1-_)}}\n",
              "`}const c=a+`100% {${s(n,1-n)}}\n",
              "}`,d=`__svelte_${Pt(c)}_${r}`,h=e.ownerDocument;Ce.add(h);const p=h.__svelte_stylesheet||(h.__svelte_stylesheet=h.head.appendChild(F(\"style\")).sheet),m=h.__svelte_rules||(h.__svelte_rules={});m[d]||(m[d]=!0,p.insertRule(`@keyframes ${d} ${c}`,p.cssRules.length));const g=e.style.animation||\"\";return e.style.animation=`${g?`${g}, `:\"\"}${d} ${i}ms linear ${o}ms 1 both`,ye+=1,d}function de(e,t){const n=(e.style.animation||\"\").split(\", \"),i=n.filter(t?l=>l.indexOf(t)<0:l=>l.indexOf(\"__svelte\")===-1),o=n.length-i.length;o&&(e.style.animation=i.join(\", \"),ye-=o,ye||Rt())}function Rt(){ge(()=>{ye||(Ce.forEach(e=>{const t=e.__svelte_stylesheet;let n=t.cssRules.length;for(;n--;)t.deleteRule(n);e.__svelte_rules={}}),Ce.clear())})}function hi(e,t,n,i){if(!t)return P;const o=e.getBoundingClientRect();if(t.left===o.left&&t.right===o.right&&t.top===o.top&&t.bottom===o.bottom)return P;const{delay:l=0,duration:s=300,easing:r=me,start:f=ae()+l,end:a=f+s,tick:c=P,css:d}=n(e,{from:t,to:o},i);let h=!0,p=!1,m;function g(){d&&(m=ce(e,0,1,s,l,r,d)),l||(p=!0)}function u(){d&&de(e,m),h=!1}return ve(_=>{if(!p&&_>=f&&(p=!0),p&&_>=a&&(c(1,0),u()),!h)return!1;if(p){const k=_-f,w=0+1*r(k/s);c(w,1-w)}return!0}),g(),c(0,1),u}function pi(e){const t=getComputedStyle(e);if(t.position!==\"absolute\"&&t.position!==\"fixed\"){const{width:n,height:i}=t,o=e.getBoundingClientRect();e.style.position=\"absolute\",e.style.width=n,e.style.height=i,Bt(e,o)}}function Bt(e,t){const n=e.getBoundingClientRect();if(t.left!==n.left||t.top!==n.top){const i=getComputedStyle(e),o=i.transform===\"none\"?\"\":i.transform;e.style.transform=`${o} translate(${t.left-n.left}px, ${t.top-n.top}px)`}}let _e;function I(e){_e=e}function U(){if(!_e)throw new Error(\"Function called outside component initialization\");return _e}function mi(e){U().$$.before_update.push(e)}function Ht(e){U().$$.on_mount.push(e)}function gi(e){U().$$.after_update.push(e)}function vi(e){U().$$.on_destroy.push(e)}function ki(){const e=U();return(t,n)=>{const i=e.$$.callbacks[t];if(i){const o=Ae(t,n);i.slice().forEach(l=>{l.call(e,o)})}}}function bi(e,t){U().$$.context.set(e,t)}function yi(e){return U().$$.context.get(e)}function wi(e){return U().$$.context.has(e)}function Fi(e,t){const n=e.$$.callbacks[t.type];n&&n.slice().forEach(i=>i(t))}const he=[],qi={enabled:!1},ne=[],we=[],De=[],nt=Promise.resolve();let Oe=!1;function it(){Oe||(Oe=!0,nt.then(Ne))}function Ei(){return it(),nt}function ie(e){we.push(e)}function ot(e){De.push(e)}let Te=!1;const Le=new Set;function Ne(){if(!Te){Te=!0;do{for(let e=0;e<he.length;e+=1){const t=he[e];I(t),xt(t.$$)}for(I(null),he.length=0;ne.length;)ne.pop()();for(let e=0;e<we.length;e+=1){const t=we[e];Le.has(t)||(Le.add(t),t())}we.length=0}while(he.length);for(;De.length;)De.pop()();Oe=!1,Te=!1,Le.clear()}}function xt(e){if(e.fragment!==null){e.update(),H(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(ie)}}let pe;function Pe(){return pe||(pe=Promise.resolve(),pe.then(()=>{pe=null})),pe}function Q(e,t,n){e.dispatchEvent(Ae(`${t?\"intro\":\"outro\"}${n}`))}const Fe=new Set;let V;function oe(){V={r:0,c:[],p:V}}function le(){V.r||H(V.c),V=V.p}function O(e,t){e&&e.i&&(Fe.delete(e),e.i(t))}function L(e,t,n,i){if(e&&e.o){if(Fe.has(e))return;Fe.add(e),V.c.push(()=>{Fe.delete(e),i&&(n&&e.d(1),i())}),e.o(t)}}const Re={duration:0};function Si(e,t,n){let i=t(e,n),o=!1,l,s,r=0;function f(){l&&de(e,l)}function a(){const{delay:d=0,duration:h=300,easing:p=me,tick:m=P,css:g}=i||Re;g&&(l=ce(e,0,1,h,d,p,g,r++)),m(0,1);const u=ae()+d,_=u+h;s&&s.abort(),o=!0,ie(()=>Q(e,!0,\"start\")),s=ve(k=>{if(o){if(k>=_)return m(1,0),Q(e,!0,\"end\"),f(),o=!1;if(k>=u){const w=p((k-u)/h);m(w,1-w)}}return o})}let c=!1;return{start(){c||(de(e),fe(i)?(i=i(),Pe().then(a)):a())},invalidate(){c=!1},end(){o&&(f(),o=!1)}}}function ji(e,t,n){let i=t(e,n),o=!0,l;const s=V;s.r+=1;function r(){const{delay:f=0,duration:a=300,easing:c=me,tick:d=P,css:h}=i||Re;h&&(l=ce(e,1,0,a,f,c,h));const p=ae()+f,m=p+a;ie(()=>Q(e,!1,\"start\")),ve(g=>{if(o){if(g>=m)return d(0,1),Q(e,!1,\"end\"),--s.r||H(s.c),!1;if(g>=p){const u=c((g-p)/a);d(1-u,u)}}return o})}return fe(i)?Pe().then(()=>{i=i(),r()}):r(),{end(f){f&&i.tick&&i.tick(1,0),o&&(l&&de(e,l),o=!1)}}}function Mi(e,t,n,i){let o=t(e,n),l=i?0:1,s=null,r=null,f=null;function a(){f&&de(e,f)}function c(h,p){const m=h.b-l;return p*=Math.abs(m),{a:l,b:h.b,d:m,duration:p,start:h.start,end:h.start+p,group:h.group}}function d(h){const{delay:p=0,duration:m=300,easing:g=me,tick:u=P,css:_}=o||Re,k={start:ae()+p,b:h};h||(k.group=V,V.r+=1),s||r?r=k:(_&&(a(),f=ce(e,l,h,m,p,g,_)),h&&u(0,1),s=c(k,m),ie(()=>Q(e,h,\"start\")),ve(w=>{if(r&&w>r.start&&(s=c(r,m),r=null,Q(e,s.b,\"start\"),_&&(a(),f=ce(e,l,s.b,s.duration,0,g,o.css))),s){if(w>=s.end)u(l=s.b,1-l),Q(e,s.b,\"end\"),r||(s.b?a():--s.group.r||H(s.group.c)),s=null;else if(w>=s.start){const M=w-s.start;l=s.a+s.d*g(M/s.duration),u(l,1-l)}}return!!(s||r)}))}return{run(h){fe(o)?Pe().then(()=>{o=o(),d(h)}):d(h)},end(){a(),s=r=null}}}function Ai(e,t){const n=t.token={};function i(o,l,s,r){if(t.token!==n)return;t.resolved=r;let f=t.ctx;s!==void 0&&(f=f.slice(),f[s]=r);const a=o&&(t.current=o)(f);let c=!1;t.block&&(t.blocks?t.blocks.forEach((d,h)=>{h!==l&&d&&(oe(),L(d,1,1,()=>{t.blocks[h]===d&&(t.blocks[h]=null)}),le())}):t.block.d(1),a.c(),O(a,1),a.m(t.mount(),t.anchor),c=!0),t.block=a,t.blocks&&(t.blocks[l]=a),c&&Ne()}if(Mt(e)){const o=U();if(e.then(l=>{I(o),i(t.then,1,t.value,l),I(null)},l=>{if(I(o),i(t.catch,2,t.error,l),I(null),!t.hasCatch)throw l}),t.current!==t.pending)return i(t.pending,0),!0}else{if(t.current!==t.then)return i(t.then,1,t.value,e),!0;t.resolved=e}}const Ci=typeof window!=\"undefined\"?window:typeof globalThis!=\"undefined\"?globalThis:global;function zt(e,t){e.d(1),t.delete(e.key)}function It(e,t){L(e,1,1,()=>{t.delete(e.key)})}function Di(e,t){e.f(),zt(e,t)}function Oi(e,t){e.f(),It(e,t)}function Ti(e,t,n,i,o,l,s,r,f,a,c,d){let h=e.length,p=l.length,m=h;const g={};for(;m--;)g[e[m].key]=m;const u=[],_=new Map,k=new Map;for(m=p;m--;){const b=d(o,l,m),v=n(b);let q=s.get(v);q?i&&q.p(b,t):(q=a(v,b),q.c()),_.set(v,u[m]=q),v in g&&k.set(v,Math.abs(m-g[v]))}const w=new Set,M=new Set;function N(b){O(b,1),b.m(r,c),s.set(b.key,b),c=b.first,p--}for(;h&&p;){const b=u[p-1],v=e[h-1],q=b.key,D=v.key;b===v?(c=b.first,h--,p--):_.has(D)?!s.has(q)||w.has(q)?N(b):M.has(D)?h--:k.get(q)>k.get(D)?(M.add(q),N(b)):(w.add(D),h--):(f(v,s),h--)}for(;h--;){const b=e[h];_.has(b.key)||f(b,s)}for(;p;)N(u[p-1]);return u}function Li(e,t,n,i){const o=new Set;for(let l=0;l<t.length;l++){const s=i(n(e,t,l));if(o.has(s))throw new Error(\"Cannot have duplicate keys in a keyed each\");o.add(s)}}function Ni(e,t){const n={},i={},o={$$scope:1};let l=e.length;for(;l--;){const s=e[l],r=t[l];if(r){for(const f in s)f in r||(i[f]=1);for(const f in r)o[f]||(n[f]=r[f],o[f]=1);e[l]=r}else for(const f in s)o[f]=1}for(const s in i)s in n||(n[s]=void 0);return n}function Pi(e){return typeof e==\"object\"&&e!==null?e:{}}const Vt=new Set([\"allowfullscreen\",\"allowpaymentrequest\",\"async\",\"autofocus\",\"autoplay\",\"checked\",\"controls\",\"default\",\"defer\",\"disabled\",\"formnovalidate\",\"hidden\",\"ismap\",\"loop\",\"multiple\",\"muted\",\"nomodule\",\"novalidate\",\"open\",\"playsinline\",\"readonly\",\"required\",\"reversed\",\"selected\"]),Wt=/[\\s'\">/=\\u{FDD0}-\\u{FDEF}\\u{FFFE}\\u{FFFF}\\u{1FFFE}\\u{1FFFF}\\u{2FFFE}\\u{2FFFF}\\u{3FFFE}\\u{3FFFF}\\u{4FFFE}\\u{4FFFF}\\u{5FFFE}\\u{5FFFF}\\u{6FFFE}\\u{6FFFF}\\u{7FFFE}\\u{7FFFF}\\u{8FFFE}\\u{8FFFF}\\u{9FFFE}\\u{9FFFF}\\u{AFFFE}\\u{AFFFF}\\u{BFFFE}\\u{BFFFF}\\u{CFFFE}\\u{CFFFF}\\u{DFFFE}\\u{DFFFF}\\u{EFFFE}\\u{EFFFF}\\u{FFFFE}\\u{FFFFF}\\u{10FFFE}\\u{10FFFF}]/u;function Ri(e,t){const n=Object.assign({},...e);t&&(n.class==null?n.class=t:n.class+=\" \"+t);let i=\"\";return Object.keys(n).forEach(o=>{if(Wt.test(o))return;const l=n[o];l===!0?i+=\" \"+o:Vt.has(o.toLowerCase())?l&&(i+=\" \"+o):l!=null&&(i+=` ${o}=\"${String(l).replace(/\"/g,\"&#34;\").replace(/'/g,\"&#39;\")}\"`)}),i}const Yt={'\"':\"&quot;\",\"'\":\"&#39;\",\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\"};function Ut(e){return String(e).replace(/[\"'&<>]/g,t=>Yt[t])}function Bi(e,t){let n=\"\";for(let i=0;i<e.length;i+=1)n+=t(e[i],i);return n}const Hi={$$render:()=>\"\"};function xi(e,t){if(!e||!e.$$render)throw t===\"svelte:component\"&&(t+=\" this={...}\"),new Error(`<${t}> is not a valid SSR component. You may need to review your build config to ensure that dependencies are compiled, rather than imported as pre-compiled modules`);return e}function zi(e,t,n,i){return console.log(`{@debug} ${e?e+\" \":\"\"}(${t}:${n})`),console.log(i),\"\"}let Be;function Ii(e){function t(n,i,o,l){const s=_e,r={on_destroy:Be,context:new Map(s?s.$$.context:[]),on_mount:[],before_update:[],after_update:[],callbacks:Se()};I({$$:r});const f=e(n,i,o,l);return I(s),f}return{render:(n={},i={})=>{Be=[];const o={title:\"\",head:\"\",css:new Set},l=t(o,n,{},i);return H(Be),{html:l,css:{code:Array.from(o.css).map(s=>s.code).join(`\n",
              "`),map:null},head:o.title+o.head}},$$render:t}}function Vi(e,t,n){return t==null||n&&!t?\"\":` ${e}${t===!0?\"\":`=${typeof t==\"string\"?JSON.stringify(Ut(t)):`\"${t}\"`}`}`}function Wi(e){return e?` class=\"${e}\"`:\"\"}function lt(e,t,n){const i=e.$$.props[t];i!==void 0&&(e.$$.bound[i]=n,n(e.$$.ctx[i]))}function se(e){e&&e.c()}function Yi(e,t){e&&e.l(t)}function Z(e,t,n){const{fragment:i,on_mount:o,on_destroy:l,after_update:s}=e.$$;i&&i.m(t,n),ie(()=>{const r=o.map(Ge).filter(fe);l?l.push(...r):H(r),e.$$.on_mount=[]}),s.forEach(ie)}function X(e,t){const n=e.$$;n.fragment!==null&&(H(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function Jt(e,t){e.$$.dirty[0]===-1&&(he.push(e),it(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function He(e,t,n,i,o,l,s=[-1]){const r=_e;I(e);const f=t.props||{},a=e.$$={fragment:null,ctx:null,props:l,update:P,not_equal:o,bound:Se(),on_mount:[],on_destroy:[],before_update:[],after_update:[],context:new Map(r?r.$$.context:[]),callbacks:Se(),dirty:s,skip_bound:!1};let c=!1;if(a.ctx=n?n(e,f,(d,h,...p)=>{const m=p.length?p[0]:h;return a.ctx&&o(a.ctx[d],a.ctx[d]=m)&&(!a.skip_bound&&a.bound[d]&&a.bound[d](m),c&&Jt(e,d)),h}):[],a.update(),c=!0,H(a.before_update),a.fragment=i?i(a.ctx):!1,t.target){if(t.hydrate){const d=Tt(t.target);a.fragment&&a.fragment.l(d),d.forEach(j)}else a.fragment&&a.fragment.c();t.intro&&O(e.$$.fragment),Z(e,t.target,t.anchor),Ne()}I(r)}let Xt;typeof HTMLElement==\"function\"&&(Xt=class extends HTMLElement{constructor(){super(),this.attachShadow({mode:\"open\"})}connectedCallback(){for(const e in this.$$.slotted)this.appendChild(this.$$.slotted[e])}attributeChangedCallback(e,t,n){this[e]=n}$destroy(){X(this,1),this.$destroy=P}$on(e,t){const n=this.$$.callbacks[e]||(this.$$.callbacks[e]=[]);return n.push(t),()=>{const i=n.indexOf(t);i!==-1&&n.splice(i,1)}}$set(e){this.$$set&&!Ke(e)&&(this.$$.skip_bound=!0,this.$$set(e),this.$$.skip_bound=!1)}});class xe{$destroy(){X(this,1),this.$destroy=P}$on(t,n){const i=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return i.push(n),()=>{const o=i.indexOf(n);o!==-1&&i.splice(o,1)}}$set(t){this.$$set&&!Ke(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}function W(e,t){document.dispatchEvent(Ae(e,Object.assign({version:\"3.31.2\"},t)))}function Ui(e,t){W(\"SvelteDOMInsert\",{target:e,node:t}),E(e,t)}function Ji(e,t,n){W(\"SvelteDOMInsert\",{target:e,node:t,anchor:n}),C(e,t,n)}function ze(e){W(\"SvelteDOMRemove\",{node:e}),j(e)}function Xi(e,t){for(;e.nextSibling&&e.nextSibling!==t;)ze(e.nextSibling)}function Gi(e){for(;e.previousSibling;)ze(e.previousSibling)}function Ki(e){for(;e.nextSibling;)ze(e.nextSibling)}function Qi(e,t,n,i,o,l){const s=i===!0?[\"capture\"]:i?Array.from(Object.keys(i)):[];o&&s.push(\"preventDefault\"),l&&s.push(\"stopPropagation\"),W(\"SvelteDOMAddEventListener\",{node:e,event:t,handler:n,modifiers:s});const r=z(e,t,n,i);return()=>{W(\"SvelteDOMRemoveEventListener\",{node:e,event:t,handler:n,modifiers:s}),r()}}function Zi(e,t,n){y(e,t,n),n==null?W(\"SvelteDOMRemoveAttribute\",{node:e,attribute:t}):W(\"SvelteDOMSetAttribute\",{node:e,attribute:t,value:n})}function $i(e,t,n){e[t]=n,W(\"SvelteDOMSetProperty\",{node:e,property:t,value:n})}function eo(e,t,n){e.dataset[t]=n,W(\"SvelteDOMSetDataset\",{node:e,property:t,value:n})}function to(e,t){t=\"\"+t,e.wholeText!==t&&(W(\"SvelteDOMSetData\",{node:e,data:t}),e.data=t)}function no(e){if(typeof e!=\"string\"&&!(e&&typeof e==\"object\"&&\"length\"in e)){let t=\"{#each} only iterates over array-like objects.\";throw typeof Symbol==\"function\"&&e&&Symbol.iterator in e&&(t+=\" You can use a spread to convert this iterable into an array.\"),new Error(t)}}function io(e,t,n){for(const i of Object.keys(t))~n.indexOf(i)||console.warn(`<${e}> received an unexpected slot \"${i}\".`)}class oo extends null{constructor(t){if(!t||!t.target&&!t.$$inline)throw new Error(\"'target' is a required option\");super()}$destroy(){super.$destroy(),this.$destroy=()=>{console.warn(\"Component was already destroyed\")}}$capture_state(){}$inject_state(){}}class lo extends null{constructor(t){super(t)}}function so(e){const t=Date.now();return()=>{if(Date.now()-t>e)throw new Error(\"Infinite loop detected\")}}function ro(e,t){return e.map((n,i)=>n+t[i])}function uo(e,t){return t.map(n=>e*n)}function Gt(e,t,n){return e.map((i,o)=>(1-n)*i+n*t[o])}function st(e,t=2){if(!(\"length\"in e))return Kt(e,t);for(var n=0,i=0;i<e.length;i++)n+=Math.pow(Math.abs(e[i]),t);return Math.pow(n,1/t)}function Kt(e,t=2){for(var n=0,i=0;i<e.shape[0];i++)n+=Math.pow(Math.abs(e.get(i)),t);return Math.pow(n,1/t)}function Ie(e,t=2){var n=st(e,t);return e.map(i=>i/(1e-4+n))}function Qt(e){for(var t=[[1,0,0],[1,1,0],[0,1,0],[0,1,1],[0,0,1],[1,0,1]].map(s=>Ie(s,1));e<0;)e+=360;e=e%360;var n=360/t.length,i=Math.floor(e/n),o=(e-i*n)/n,l=Gt(t[i],t[(i+1)%t.length],o);return l=Ie(l,1),l}const Ve=[];function Zt(e){if(e in Ve)return Ve[e];let t=[];for(let n=0;n<e;n++){const i=360*n/e;t.push(Qt(i))}return Ve[e]=t,t}function rt(e){return`rgb(${255*e[0]}, ${255*e[1]}, ${255*e[2]})`}function ut(e,t=[.98,.98,.98],n=void 0,i=void 0){const o=\"length\"in e?e.length:e.shape[0],l=\"length\"in e?h=>e[h]:h=>e.get(h);if(i==null&&(i=Zt(o)),console.log(\"Hues\",i),n==null){for(var s=[0,0,0],r=0;r<o;r++){const h=l(r);if(h!=0)for(var f=i[r],a=0;a<3;a++)s[a]+=h*f[a]}s=Ie(s,1);for(var c=st(e,2),c=Math.max(0,Math.min(1,c)),a=0;a<3;a++)s[a]=c*s[a]+(1-c)*t[a];return s}else{for(var r=n,d=i[r],s=[0,0,0],a=0;a<3;a++)s[a]=l(r)*d[a]+(1-l(r))*t[a];return s}}function We(e,t=[.98,.98,.98],n=void 0,i=void 0){var o=ut(e,t,n,i);return rt(o)}function $t(e,t=[.98,.98,.98]){if(e>=0)for(var n=[0,.7,0],i=[0,0,0],o=0;o<3;o++)i[o]=e*n[o]+(1-e)*t[o];else for(var n=[1,0,0],i=[0,0,0],o=0;o<3;o++)i[o]=-e*n[o]+(1+e)*t[o];return console.log(\"Neuron color\",e,i),i}function fo(e,t=[.98,.98,.98]){var n=$t(e,t);return rt(n)}function en(){var e=F(\"style\");e.id=\"svelte-1fjpmsy-style\",e.textContent=\".container.svelte-1fjpmsy.svelte-1fjpmsy{position:relative;border:1px solid #aaa}.container.svelte-1fjpmsy>.svelte-1fjpmsy{position:absolute}.container.svelte-1fjpmsy canvas.svelte-1fjpmsy{left:0px;top:0px;width:100%;height:100%;image-rendering:pixelated}.container.svelte-1fjpmsy .focus-top.svelte-1fjpmsy,.container.svelte-1fjpmsy .focus-bottom.svelte-1fjpmsy{left:0px;width:100%;background:#aaa;opacity:0.3}.container.svelte-1fjpmsy .focus-top.svelte-1fjpmsy{top:0px}.container.svelte-1fjpmsy .focus-bottom.svelte-1fjpmsy{bottom:0px}.container.svelte-1fjpmsy .focus-left.svelte-1fjpmsy,.container.svelte-1fjpmsy .focus-right.svelte-1fjpmsy{top:0px;height:100%;background:#aaa;opacity:0.3}.container.svelte-1fjpmsy .focus-left.svelte-1fjpmsy{left:0px}.container.svelte-1fjpmsy .focus-right.svelte-1fjpmsy{right:0px}\",E(document.head,e)}function ft(e){let t,n,i,o=e[3]!=null&&at(e);return{c(){t=F(\"div\"),n=F(\"canvas\"),i=T(),o&&o.c(),S(n,\"width\",e[1]+\"px\"),S(n,\"height\",e[2]+\"px\"),y(n,\"class\",\"svelte-1fjpmsy\"),y(t,\"class\",\"container svelte-1fjpmsy\"),S(t,\"width\",e[1]+\"px\"),S(t,\"height\",e[2]+\"px\")},m(l,s){C(l,t,s),E(t,n),e[9](n),E(t,i),o&&o.m(t,null)},p(l,s){s&2&&S(n,\"width\",l[1]+\"px\"),s&4&&S(n,\"height\",l[2]+\"px\"),l[3]!=null?o?o.p(l,s):(o=at(l),o.c(),o.m(t,null)):o&&(o.d(1),o=null),s&2&&S(t,\"width\",l[1]+\"px\"),s&4&&S(t,\"height\",l[2]+\"px\")},d(l){l&&j(t),e[9](null),o&&o.d()}}}function at(e){let t,n,i;return{c(){t=F(\"div\"),n=T(),i=F(\"div\"),y(t,\"class\",\"focus-top svelte-1fjpmsy\"),S(t,\"height\",e[2]*e[3]/e[0].shape[0]+\"px\"),y(i,\"class\",\"focus-bottom svelte-1fjpmsy\"),S(i,\"height\",e[2]*(1-(e[3]+1)/e[0].shape[0])+\"px\")},m(o,l){C(o,t,l),C(o,n,l),C(o,i,l)},p(o,l){l&13&&S(t,\"height\",o[2]*o[3]/o[0].shape[0]+\"px\"),l&13&&S(i,\"height\",o[2]*(1-(o[3]+1)/o[0].shape[0])+\"px\")},d(o){o&&j(t),o&&j(n),o&&j(i)}}}function ct(e){let t,n,i,o=e[3]!=null&&dt(e);return{c(){t=F(\"div\"),n=F(\"canvas\"),i=T(),o&&o.c(),S(n,\"width\",e[1]+\"px\"),S(n,\"height\",e[2]+\"px\"),y(n,\"class\",\"svelte-1fjpmsy\"),y(t,\"class\",\"container svelte-1fjpmsy\"),S(t,\"width\",e[1]+\"px\"),S(t,\"height\",e[2]+\"px\")},m(l,s){C(l,t,s),E(t,n),e[10](n),E(t,i),o&&o.m(t,null)},p(l,s){s&2&&S(n,\"width\",l[1]+\"px\"),s&4&&S(n,\"height\",l[2]+\"px\"),l[3]!=null?o?o.p(l,s):(o=dt(l),o.c(),o.m(t,null)):o&&(o.d(1),o=null),s&2&&S(t,\"width\",l[1]+\"px\"),s&4&&S(t,\"height\",l[2]+\"px\")},d(l){l&&j(t),e[10](null),o&&o.d()}}}function dt(e){let t,n,i;return{c(){t=F(\"div\"),n=T(),i=F(\"div\"),y(t,\"class\",\"focus-left svelte-1fjpmsy\"),S(t,\"width\",e[1]*e[3]/e[0].shape[1]+\"px\"),y(i,\"class\",\"focus-right svelte-1fjpmsy\"),S(i,\"width\",e[1]*(1-(e[3]+1)/e[0].shape[1])+\"px\")},m(o,l){C(o,t,l),C(o,n,l),C(o,i,l)},p(o,l){l&11&&S(t,\"width\",o[1]*o[3]/o[0].shape[1]+\"px\"),l&11&&S(i,\"width\",o[1]*(1-(o[3]+1)/o[0].shape[1])+\"px\")},d(o){o&&j(t),o&&j(n),o&&j(i)}}}function tn(e){let t,n,i=!e[4]&&ft(e),o=e[4]&&ct(e);return{c(){i&&i.c(),t=T(),o&&o.c(),n=tt()},m(l,s){i&&i.m(l,s),C(l,t,s),o&&o.m(l,s),C(l,n,s)},p(l,[s]){l[4]?i&&(i.d(1),i=null):i?i.p(l,s):(i=ft(l),i.c(),i.m(t.parentNode,t)),l[4]?o?o.p(l,s):(o=ct(l),o.c(),o.m(n.parentNode,n)):o&&(o.d(1),o=null)},i:P,o:P,d(l){i&&i.d(l),l&&j(t),o&&o.d(l),l&&j(n)}}}function nn(e,t,n){let{array:i}=t,{width:o}=t,{height:l}=t,{hues:s}=t,{focus_token:r}=t,{isolate_channel:f=void 0}=t,{hover_token_is_target:a=!1}=t,{color_map:c=ut}=t,d;function h(u,_,k,w=void 0,M=void 0){if(_<k)return[255,255,255];var N=u.pick(_,k,null),b=c(N,void 0,w,M);return b.map(v=>255*v)}function p(u,_,k=void 0,w=void 0){if(!(u==null||_==null)){u.width=_.shape[0],u.height=_.shape[1];for(var M=u.getContext(\"2d\"),N=M.getImageData(0,0,u.width,u.height),b=0;b<u.width;b++)for(var v=0;v<u.height;v++){for(var q=b*u.width+v,D=h(_,b,v,k,w=w),J=0;J<3;J++)N.data[4*q+J]=D[J];N.data[4*q+3]=255}M.putImageData(N,0,0)}}Ht(()=>p(d,i,f));function m(u){ne[u?\"unshift\":\"push\"](()=>{d=u,n(5,d)})}function g(u){ne[u?\"unshift\":\"push\"](()=>{d=u,n(5,d)})}return e.$$set=u=>{\"array\"in u&&n(0,i=u.array),\"width\"in u&&n(1,o=u.width),\"height\"in u&&n(2,l=u.height),\"hues\"in u&&n(6,s=u.hues),\"focus_token\"in u&&n(3,r=u.focus_token),\"isolate_channel\"in u&&n(7,f=u.isolate_channel),\"hover_token_is_target\"in u&&n(4,a=u.hover_token_is_target),\"color_map\"in u&&n(8,c=u.color_map)},e.$$.update=()=>{if(e.$$.dirty&225){e:p(d,i,f,s)}},[i,o,l,r,a,d,s,f,c,m,g]}class on extends xe{constructor(t){super(),document.getElementById(\"svelte-1fjpmsy-style\")||en(),He(this,t,nn,tn,je,{array:0,width:1,height:2,hues:6,focus_token:3,isolate_channel:7,hover_token_is_target:4,color_map:8})}}const qe=on;function _t(e,t){return e.mode==\"soft\"&&(e.value=t),e}function ln(e,t){if(e.mode==\"soft\")e.value=t,e.mode=\"hard\";else if(e.mode==\"hard\"&&e.value!=t)e.value=t;else return sn(e);return e}function sn(e){return e.value=void 0,e.mode=\"soft\",e}function rn(e){let t,n,i,o;const l=e[4].default,s=At(l,e,e[3],null);return{c(){t=F(\"div\"),s&&s.c(),y(t,\"style\",e[2])},m(r,f){C(r,t,f),s&&s.m(t,null),n=!0,i||(o=[z(t,\"mouseover\",e[5]),z(t,\"click\",e[6]),z(t,\"mouseout\",e[7])],i=!0)},p(r,[f]){s&&s.p&&f&8&&Ct(s,l,r,r[3],f,null,null),(!n||f&4)&&y(t,\"style\",r[2])},i(r){n||(O(s,r),n=!0)},o(r){L(s,r),n=!1},d(r){r&&j(t),s&&s.d(r),i=!1,H(o)}}}function un(e,t,n){let{$$slots:i={},$$scope:o}=t,{lock:l}=t,{set_value:s}=t,{style:r=\"\"}=t;const f=()=>{n(0,l=_t(l,s))},a=()=>{n(0,l=ln(l,s))},c=()=>{n(0,l=_t(l,void 0))};return e.$$set=d=>{\"lock\"in d&&n(0,l=d.lock),\"set_value\"in d&&n(1,s=d.set_value),\"style\"in d&&n(2,r=d.style),\"$$scope\"in d&&n(3,o=d.$$scope)},[l,s,r,o,i,f,a,c]}class fn extends xe{constructor(t){super(),He(this,t,un,rn,je,{lock:0,set_value:1,style:2})}}const ht=fn;function an(){var e=F(\"style\");e.id=\"svelte-xqk9oe-style\",e.textContent=\".attn-container.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[big-attn] min-content [heads] minmax(min-content, 624px);gap:12px}.figcaption.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{color:#888;grid-row:title;white-space:nowrap}.tokens-container.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[left] min-content [right] minmax(min-content, 800px) [end];gap:12px;margin-top:24px;color:white}.tokens.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{grid-row:main;grid-column-start:left;grid-column-end:end;cursor:pointer;height:min-content;line-height:110%}.tokens.svelte-xqk9oe .token.svelte-xqk9oe.svelte-xqk9oe{white-space:pre-wrap}.tokens.svelte-xqk9oe .selected.svelte-xqk9oe.svelte-xqk9oe{border:1px solid #999;z-index:10}.tokens.svelte-xqk9oe .token.svelte-xqk9oe.svelte-xqk9oe:not(.selected){z-index:0;padding:1px}.hover-mode.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.hover-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{color:#888;grid-row:title;grid-column:settings;cursor:pointer}.hover-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{margin-right:8px}.heads.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{grid-column:heads;grid-row:main;display:flex;flex-direction:row;flex-wrap:wrap;gap:6px;height:min-content}.heads.svelte-xqk9oe .head-icon.svelte-xqk9oe.svelte-xqk9oe{position:relative;width:62px;height:62px}.heads.svelte-xqk9oe .head-icon.svelte-xqk9oe>.svelte-xqk9oe{position:absolute;right:0px;top:0px}.heads.svelte-xqk9oe .head-icon .head-label.svelte-xqk9oe.svelte-xqk9oe{background:#333;color:#eee;font-size:65%;padding:1px;border-bottom-left-radius:2px;padding-left:4px;padding-right:2px;min-width:14px;opacity:0.75}\",E(document.head,e)}function pt(e,t,n){const i=e.slice();return i[32]=t[n],i[34]=n,i}function mt(e,t,n){const i=e.slice();return i[35]=t[n],i}function gt(e){let t,n=e[15][e[10]]+\"\",i,o;return{c(){t=R(\"(\"),i=R(n),o=R(\")\")},m(l,s){C(l,t,s),C(l,i,s),C(l,o,s)},p(l,s){s[0]&33792&&n!==(n=l[15][l[10]]+\"\")&&ke(i,n)},d(l){l&&j(t),l&&j(i),l&&j(o)}}}function vt(e){let t,n,i,o;return n=new qe({props:{array:e[7],width:\"200\",height:\"200\",focus_token:e[9],hover_token_is_target:e[2],isolate_channel:e[10]}}),{c(){t=F(\"div\"),se(n.$$.fragment),y(t,\"style\",i=\"grid-column: big-attn; grid-row: main; \"+(e[11]?\"\":\"display:none;\"))},m(l,s){C(l,t,s),Z(n,t,null),o=!0},p(l,s){const r={};s[0]&128&&(r.array=l[7]),s[0]&512&&(r.focus_token=l[9]),s[0]&4&&(r.hover_token_is_target=l[2]),s[0]&1024&&(r.isolate_channel=l[10]),n.$set(r),(!o||s[0]&2048&&i!==(i=\"grid-column: big-attn; grid-row: main; \"+(l[11]?\"\":\"display:none;\")))&&y(t,\"style\",i)},i(l){o||(O(n.$$.fragment,l),o=!0)},o(l){L(n.$$.fragment,l),o=!1},d(l){l&&j(t),X(n)}}}function kt(e){let t,n,i,o,l=re(e[12].shape[2]),s=[];for(let f=0;f<l.length;f+=1)s[f]=bt(mt(e,l,f));const r=f=>L(s[f],1,1,()=>{s[f]=null});return{c(){t=F(\"div\"),t.textContent=\"Attention Heads (hover to focus, click to lock)\",n=T(),i=F(\"div\");for(let f=0;f<s.length;f+=1)s[f].c();y(t,\"class\",\"figcaption svelte-xqk9oe\"),S(t,\"grid-column\",\"heads\"),y(i,\"class\",\"heads svelte-xqk9oe\")},m(f,a){C(f,t,a),C(f,n,a),C(f,i,a);for(let c=0;c<s.length;c+=1)s[c].m(i,null);o=!0},p(f,a){if(a[0]&122566){l=re(f[12].shape[2]);let c;for(c=0;c<l.length;c+=1){const d=mt(f,l,c);s[c]?(s[c].p(d,a),O(s[c],1)):(s[c]=bt(d),s[c].c(),O(s[c],1),s[c].m(i,null))}for(oe(),c=l.length;c<s.length;c+=1)r(c);le()}},i(f){if(!o){for(let a=0;a<l.length;a+=1)O(s[a]);o=!0}},o(f){s=s.filter(Boolean);for(let a=0;a<s.length;a+=1)L(s[a]);o=!1},d(f){f&&j(t),f&&j(n),f&&j(i),et(s,f)}}}function cn(e){let t,n,i,o,l=(e[15][e[35]]!=null?e[15][e[35]]:\"&nbsp\")+\"\",s,r,f,a,c,d,h=(e[15][e[35]]!=null?e[15][e[35]]:\"&nbsp\")+\"\",p,m,g;return n=new qe({props:{array:e[7],width:\"60\",height:\"60\",isolate_channel:e[35]}}),a=new qe({props:{array:e[6],width:\"60\",height:\"60\",isolate_channel:e[35]}}),{c(){t=F(\"div\"),se(n.$$.fragment),i=T(),o=F(\"div\"),r=T(),f=F(\"div\"),se(a.$$.fragment),c=T(),d=F(\"div\"),m=T(),y(o,\"class\",\"head-label svelte-xqk9oe\"),S(o,\"background\",e[14][e[35]]),y(t,\"class\",\"head-icon svelte-xqk9oe\"),y(t,\"style\",s=\"opacity: \"+(e[10]!=null&&e[10]!=e[35]?\"0.2\":e[16](e[35],e[9],e[2]))+`;\n",
              "                        `+(e[11]?\"\":\"display:none;\")),y(d,\"class\",\"head-label svelte-xqk9oe\"),S(d,\"background\",e[14][e[35]]),y(f,\"class\",\"head-icon svelte-xqk9oe\"),y(f,\"style\",p=\"opacity: \"+(e[10]!=null&&e[10]!=e[35]?\"0.2\":e[16](e[35],e[9],e[2]))+`;\n",
              "                        `+(e[11]?\"display:none;\":\"\"))},m(u,_){C(u,t,_),Z(n,t,null),E(t,i),E(t,o),o.innerHTML=l,C(u,r,_),C(u,f,_),Z(a,f,null),E(f,c),E(f,d),d.innerHTML=h,C(u,m,_),g=!0},p(u,_){const k={};_[0]&128&&(k.array=u[7]),_[0]&4096&&(k.isolate_channel=u[35]),n.$set(k),(!g||_[0]&36864)&&l!==(l=(u[15][u[35]]!=null?u[15][u[35]]:\"&nbsp\")+\"\")&&(o.innerHTML=l),(!g||_[0]&20480)&&S(o,\"background\",u[14][u[35]]),(!g||_[0]&7684&&s!==(s=\"opacity: \"+(u[10]!=null&&u[10]!=u[35]?\"0.2\":u[16](u[35],u[9],u[2]))+`;\n",
              "                        `+(u[11]?\"\":\"display:none;\")))&&y(t,\"style\",s);const w={};_[0]&64&&(w.array=u[6]),_[0]&4096&&(w.isolate_channel=u[35]),a.$set(w),(!g||_[0]&36864)&&h!==(h=(u[15][u[35]]!=null?u[15][u[35]]:\"&nbsp\")+\"\")&&(d.innerHTML=h),(!g||_[0]&20480)&&S(d,\"background\",u[14][u[35]]),(!g||_[0]&7684&&p!==(p=\"opacity: \"+(u[10]!=null&&u[10]!=u[35]?\"0.2\":u[16](u[35],u[9],u[2]))+`;\n",
              "                        `+(u[11]?\"display:none;\":\"\")))&&y(f,\"style\",p)},i(u){g||(O(n.$$.fragment,u),O(a.$$.fragment,u),g=!0)},o(u){L(n.$$.fragment,u),L(a.$$.fragment,u),g=!1},d(u){u&&j(t),X(n),u&&j(r),u&&j(f),X(a),u&&j(m)}}}function bt(e){let t,n,i;function o(s){e[22].call(null,s)}let l={set_value:e[35],$$slots:{default:[cn]},$$scope:{ctx:e}};return e[1]!==void 0&&(l.lock=e[1]),t=new ht({props:l}),ne.push(()=>lt(t,\"lock\",o)),{c(){se(t.$$.fragment)},m(s,r){Z(t,s,r),i=!0},p(s,r){const f={};r[0]&4096&&(f.set_value=s[35]),r[0]&57028|r[1]&128&&(f.$$scope={dirty:r,ctx:s}),!n&&r[0]&2&&(n=!0,f.lock=s[1],ot(()=>n=!1)),t.$set(f)},i(s){i||(O(t.$$.fragment,s),i=!0)},o(s){L(t.$$.fragment,s),i=!1},d(s){X(t,s)}}}function yt(e){let t,n,i,o,l,s,r,f,a,c,d,h,p=e[2]?\"target\":\"source\",m,g,u,_,k,w=e[5],M=[];for(let v=0;v<w.length;v+=1)M[v]=wt(pt(e,w,v));const N=v=>L(M[v],1,1,()=>{M[v]=null});let b=e[7]!==void 0&&Ft(e);return{c(){t=F(\"div\"),n=F(\"div\"),n.textContent=\"Tokens (hover to focus, click to lock)\",i=T(),o=F(\"div\");for(let v=0;v<M.length;v+=1)M[v].c();l=T(),s=F(\"div\"),r=F(\"nobr\"),f=F(\"input\"),a=T(),c=F(\"span\"),d=R(`Selected is\n",
              "            `),h=F(\"b\"),m=R(p),g=T(),b&&b.c(),y(n,\"class\",\"figcaption svelte-xqk9oe\"),S(n,\"grid-column\",\"left\"),y(o,\"class\",\"tokens svelte-xqk9oe\"),y(f,\"class\",\"hover-mode svelte-xqk9oe\"),y(f,\"type\",\"checkbox\"),y(c,\"class\",\"hover-mode-text svelte-xqk9oe\"),S(c,\"white-space\",\"nowrap\"),y(s,\"class\",\"toggle\"),y(t,\"class\",\"tokens-container svelte-xqk9oe\")},m(v,q){C(v,t,q),E(t,n),E(t,i),E(t,o);for(let D=0;D<M.length;D+=1)M[D].m(o,null);E(t,l),E(t,s),E(s,r),E(r,f),f.checked=e[2],E(r,a),E(r,c),E(c,d),E(c,h),E(h,m),E(r,g),b&&b.m(r,null),u=!0,_||(k=[z(f,\"change\",e[24]),z(c,\"click\",e[25])],_=!0)},p(v,q){if(q[0]&561){w=v[5];let D;for(D=0;D<w.length;D+=1){const J=pt(v,w,D);M[D]?(M[D].p(J,q),O(M[D],1)):(M[D]=wt(J),M[D].c(),O(M[D],1),M[D].m(o,null))}for(oe(),D=w.length;D<M.length;D+=1)N(D);le()}q[0]&4&&(f.checked=v[2]),(!u||q[0]&4)&&p!==(p=v[2]?\"target\":\"source\")&&ke(m,p),v[7]!==void 0?b?b.p(v,q):(b=Ft(v),b.c(),b.m(r,null)):b&&(b.d(1),b=null)},i(v){if(!u){for(let q=0;q<w.length;q+=1)O(M[q]);u=!0}},o(v){M=M.filter(Boolean);for(let q=0;q<M.length;q+=1)L(M[q]);u=!1},d(v){v&&j(t),et(M,v),b&&b.d(),_=!1,H(k)}}}function dn(e){let t,n=e[32]+\"\",i,o;return{c(){t=F(\"span\"),i=R(n),y(t,\"class\",o=\"token \"+(e[34]==e[9]?\"selected\":\"\")+\" svelte-xqk9oe\"),S(t,\"background\",e[4][e[34]])},m(l,s){C(l,t,s),E(t,i)},p(l,s){s[0]&32&&n!==(n=l[32]+\"\")&&ke(i,n),s[0]&512&&o!==(o=\"token \"+(l[34]==l[9]?\"selected\":\"\")+\" svelte-xqk9oe\")&&y(t,\"class\",o),s[0]&16&&S(t,\"background\",l[4][l[34]])},d(l){l&&j(t)}}}function wt(e){let t,n,i;function o(s){e[23].call(null,s)}let l={set_value:e[34],style:\"display: inline\",$$slots:{default:[dn]},$$scope:{ctx:e}};return e[0]!==void 0&&(l.lock=e[0]),t=new ht({props:l}),ne.push(()=>lt(t,\"lock\",o)),{c(){se(t.$$.fragment)},m(s,r){Z(t,s,r),i=!0},p(s,r){const f={};r[0]&560|r[1]&128&&(f.$$scope={dirty:r,ctx:s}),!n&&r[0]&1&&(n=!0,f.lock=s[0],ot(()=>n=!1)),t.$set(f)},i(s){i||(O(t.$$.fragment,s),i=!0)},o(s){L(t.$$.fragment,s),i=!1},d(s){X(t,s)}}}function Ft(e){let t,n,i,o,l,s=e[3]?\"info-weighted\":\"unmodified\",r,f,a;return{c(){t=F(\"input\"),n=T(),i=F(\"span\"),o=R(`Attention is\n",
              "            `),l=F(\"b\"),r=R(s),y(t,\"class\",\"info-mode svelte-xqk9oe\"),y(t,\"type\",\"checkbox\"),y(i,\"class\",\"info-mode-text svelte-xqk9oe\"),S(i,\"white-space\",\"nowrap\")},m(c,d){C(c,t,d),t.checked=e[3],C(c,n,d),C(c,i,d),E(i,o),E(i,l),E(l,r),f||(a=[z(t,\"change\",e[26]),z(i,\"click\",e[27])],f=!0)},p(c,d){d[0]&8&&(t.checked=c[3]),d[0]&8&&s!==(s=c[3]?\"info-weighted\":\"unmodified\")&&ke(r,s)},d(c){c&&j(t),c&&j(n),c&&j(i),f=!1,H(a)}}}function _n(e){let t,n,i,o,l,s,r,f,a,c,d,h,p=e[10]!=null&&gt(e),m=e[7]!==void 0&&vt(e);r=new qe({props:{array:e[6],width:\"200\",height:\"200\",focus_token:e[9],hover_token_is_target:e[2],isolate_channel:e[10]}});let g=e[13]>1&&kt(e),u=e[8]&&yt(e);return{c(){t=F(\"div\"),n=F(\"div\"),i=R(`Attention Pattern\n",
              "        `),p&&p.c(),o=T(),m&&m.c(),l=T(),s=F(\"div\"),se(r.$$.fragment),a=T(),g&&g.c(),c=T(),u&&u.c(),d=tt(),y(n,\"class\",\"figcaption svelte-xqk9oe\"),S(n,\"grid-column\",\"big-attn\"),y(s,\"style\",f=\"grid-column: big-attn; grid-row: main; \"+(e[11]?\"display:none\":\"\")),y(t,\"class\",\"attn-container svelte-xqk9oe\")},m(_,k){C(_,t,k),E(t,n),E(n,i),p&&p.m(n,null),E(t,o),m&&m.m(t,null),E(t,l),E(t,s),Z(r,s,null),E(t,a),g&&g.m(t,null),C(_,c,k),u&&u.m(_,k),C(_,d,k),h=!0},p(_,k){_[10]!=null?p?p.p(_,k):(p=gt(_),p.c(),p.m(n,null)):p&&(p.d(1),p=null),_[7]!==void 0?m?(m.p(_,k),k[0]&128&&O(m,1)):(m=vt(_),m.c(),O(m,1),m.m(t,l)):m&&(oe(),L(m,1,1,()=>{m=null}),le());const w={};k[0]&64&&(w.array=_[6]),k[0]&512&&(w.focus_token=_[9]),k[0]&4&&(w.hover_token_is_target=_[2]),k[0]&1024&&(w.isolate_channel=_[10]),r.$set(w),(!h||k[0]&2048&&f!==(f=\"grid-column: big-attn; grid-row: main; \"+(_[11]?\"display:none\":\"\")))&&y(s,\"style\",f),_[13]>1?g?(g.p(_,k),k[0]&8192&&O(g,1)):(g=kt(_),g.c(),O(g,1),g.m(t,null)):g&&(oe(),L(g,1,1,()=>{g=null}),le()),_[8]?u?(u.p(_,k),k[0]&256&&O(u,1)):(u=yt(_),u.c(),O(u,1),u.m(d.parentNode,d)):u&&(oe(),L(u,1,1,()=>{u=null}),le())},i(_){h||(O(m),O(r.$$.fragment,_),O(g),O(u),h=!0)},o(_){L(m),L(r.$$.fragment,_),L(g),L(u),h=!1},d(_){_&&j(t),p&&p.d(),m&&m.d(),X(r),g&&g.d(),_&&j(c),u&&u.d(_),_&&j(d)}}}function re(e){return[...Array(e).keys()]}function qt(e){if(e!==void 0){for(var t=[],n=0;n<e.shape[0];n++){t.push([]);for(var i=0;i<e.shape[2];i++){for(var o=0,l=0;l<e.shape[1];l++)o=Math.max(o,e.pick(n,l,i));t[n].push(o)}}return t}}function Et(e){if(e!==void 0){for(var t=[],n=0;n<e.shape[0];n++){t.push([]);for(var i=0;i<e.shape[2];i++){for(var o=0,l=0;l<e.shape[1];l++)o=Math.max(o,e.pick(l,n,i));t[n].push(o)}}return t}}function hn(e,t,n){let i,o,l,s,r,f,a,c,d,h,p,m,g,{tokens:u}=t,{attention:_}=t,{info_weighted:k}=t,{head_labels:w}=t,{show_tokens:M=!0}=t,{focus_token_lock:N={value:void 0,mode:\"soft\"}}=t,{focus_head_lock:b={value:void 0,mode:\"soft\"}}=t,{hover_token_is_target:v=!1}=t,{_show_info_weighted:q=!1}=t;function D(A,Y,G,$=void 0){if(Y<G)return\"#FFF\";var ue=A.pick(Y,G,null);return We(ue,void 0,$)}function J(A,Y,G){if(Y==null)var $=1;else var ue=G?h:d,$=Math.max(0,Math.min(1,ue[Y][A]));return\"\"+$}function gn(A,Y,G,$=void 0,ue){if(Y==null){var qn=ue?h:d;return We(qn[G],void 0,$)}let Ue,Je;ue?(Ue=G,Je=Y):(Ue=Y,Je=G);let Xe=D(A,Ue,Je,$);return Xe===\"#FFF\"&&(Xe=\"#DDD\"),Xe}let{all_token_colors:Ye}=t;function vn(A){b=A,n(1,b)}function kn(A){N=A,n(0,N)}function bn(){v=this.checked,n(2,v)}const yn=()=>n(2,v=v^!0);function wn(){q=this.checked,n(3,q)}const Fn=()=>n(3,q=q^!0);return e.$$set=A=>{\"tokens\"in A&&n(5,u=A.tokens),\"attention\"in A&&n(6,_=A.attention),\"info_weighted\"in A&&n(7,k=A.info_weighted),\"head_labels\"in A&&n(17,w=A.head_labels),\"show_tokens\"in A&&n(8,M=A.show_tokens),\"focus_token_lock\"in A&&n(0,N=A.focus_token_lock),\"focus_head_lock\"in A&&n(1,b=A.focus_head_lock),\"hover_token_is_target\"in A&&n(2,v=A.hover_token_is_target),\"_show_info_weighted\"in A&&n(3,q=A._show_info_weighted),\"all_token_colors\"in A&&n(4,Ye=A.all_token_colors)},e.$$.update=()=>{if(e.$$.dirty[0]&1){e:n(9,i=N.value)}if(e.$$.dirty[0]&2){e:n(10,o=b.value)}if(e.$$.dirty[0]&136){e:n(11,l=q&&k!==void 0)}if(e.$$.dirty[0]&2240){e:n(12,s=l?k:_)}if(e.$$.dirty[0]&4096){e:window.attention_show=s}if(e.$$.dirty[0]&64){e:n(18,r=qt(_))}if(e.$$.dirty[0]&64){e:n(19,f=Et(_))}if(e.$$.dirty[0]&128){e:n(20,a=qt(k))}if(e.$$.dirty[0]&128){e:n(21,c=Et(k))}if(e.$$.dirty[0]&1312768){e:d=l?a:r}if(e.$$.dirty[0]&2623488){e:h=l?c:f}if(e.$$.dirty[0]&64){e:n(13,p=_.shape[2])}if(e.$$.dirty[0]&8192){e:n(14,m=re(p).map(A=>We(re(p).map(Y=>1),void 0,A)))}if(e.$$.dirty[0]&139264){e:n(15,g=w!=null?w:re(p))}if(e.$$.dirty[0]&5668){e:n(4,Ye=re(u.length).map(A=>gn(s,i,A,o,v)))}},[N,b,v,q,Ye,u,_,k,M,i,o,l,s,p,m,g,J,w,r,f,a,c,vn,kn,bn,yn,wn,Fn]}class pn extends xe{constructor(t){super(),document.getElementById(\"svelte-xqk9oe-style\")||an(),He(this,t,hn,_n,je,{tokens:5,attention:6,info_weighted:7,head_labels:17,show_tokens:8,focus_token_lock:0,focus_head_lock:1,hover_token_is_target:2,_show_info_weighted:3,all_token_colors:4},[-1,-1])}}const mn=pn}},Ee={};function ee(x){if(Ee[x])return Ee[x].exports;var B=Ee[x]={exports:{}};return St[x](B,B.exports,ee),B.exports}return ee.d=(x,B)=>{for(var te in B)ee.o(B,te)&&!ee.o(x,te)&&Object.defineProperty(x,te,{enumerable:!0,get:B[te]})},ee.o=(x,B)=>Object.prototype.hasOwnProperty.call(x,B),ee(143)})().default;\n",
              "</script>\n",
              "<script>var loader;loader=(()=>{var Ze={907:k=>{\"use strict\";function I(E){for(var T=new Array(E),n=0;n<E;++n)T[n]=n;return T}k.exports=I},738:k=>{/*!\n",
              " * Determine if an object is a Buffer\n",
              " *\n",
              " * @author   Feross Aboukhadijeh <https://feross.org>\n",
              " * @license  MIT\n",
              " */k.exports=function(T){return T!=null&&(I(T)||E(T)||!!T._isBuffer)};function I(T){return!!T.constructor&&typeof T.constructor.isBuffer==\"function\"&&T.constructor.isBuffer(T)}function E(T){return typeof T.readFloatLE==\"function\"&&typeof T.slice==\"function\"&&I(T.slice(0,0))}},861:(k,I,E)=>{var T=E(907),n=E(738),g=typeof Float64Array!=\"undefined\";function s(l,h){return l[0]-h[0]}function m(){var l=this.stride,h=new Array(l.length),c;for(c=0;c<h.length;++c)h[c]=[Math.abs(l[c]),c];h.sort(s);var N=new Array(h.length);for(c=0;c<N.length;++c)N[c]=h[c][1];return N}function _(l,h){var c=[\"View\",h,\"d\",l].join(\"\");h<0&&(c=\"View_Nil\"+l);var N=l===\"generic\";if(h===-1){var f=\"function \"+c+\"(a){this.data=a;};var proto=\"+c+\".prototype;proto.dtype='\"+l+\"';proto.index=function(){return -1};proto.size=0;proto.dimension=-1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function(){return new \"+c+\"(this.data);};proto.get=proto.set=function(){};proto.pick=function(){return null};return function construct_\"+c+\"(a){return new \"+c+\"(a);}\",O=new Function(f);return O()}else if(h===0){var f=\"function \"+c+\"(a,d) {this.data = a;this.offset = d};var proto=\"+c+\".prototype;proto.dtype='\"+l+\"';proto.index=function(){return this.offset};proto.dimension=0;proto.size=1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function \"+c+\"_copy() {return new \"+c+\"(this.data,this.offset)};proto.pick=function \"+c+\"_pick(){return TrivialArray(this.data);};proto.valueOf=proto.get=function \"+c+\"_get(){return \"+(N?\"this.data.get(this.offset)\":\"this.data[this.offset]\")+\"};proto.set=function \"+c+\"_set(v){return \"+(N?\"this.data.set(this.offset,v)\":\"this.data[this.offset]=v\")+\"};return function construct_\"+c+\"(a,b,c,d){return new \"+c+\"(a,d)}\",O=new Function(\"TrivialArray\",f);return O(u[l][0])}var f=[\"'use strict'\"],d=T(h),M=d.map(function(p){return\"i\"+p}),L=\"this.offset+\"+d.map(function(p){return\"this.stride[\"+p+\"]*i\"+p}).join(\"+\"),j=d.map(function(p){return\"b\"+p}).join(\",\"),D=d.map(function(p){return\"c\"+p}).join(\",\");f.push(\"function \"+c+\"(a,\"+j+\",\"+D+\",d){this.data=a\",\"this.shape=[\"+j+\"]\",\"this.stride=[\"+D+\"]\",\"this.offset=d|0}\",\"var proto=\"+c+\".prototype\",\"proto.dtype='\"+l+\"'\",\"proto.dimension=\"+h),f.push(\"Object.defineProperty(proto,'size',{get:function \"+c+\"_size(){return \"+d.map(function(p){return\"this.shape[\"+p+\"]\"}).join(\"*\"),\"}})\"),h===1?f.push(\"proto.order=[0]\"):(f.push(\"Object.defineProperty(proto,'order',{get:\"),h<4?(f.push(\"function \"+c+\"_order(){\"),h===2?f.push(\"return (Math.abs(this.stride[0])>Math.abs(this.stride[1]))?[1,0]:[0,1]}})\"):h===3&&f.push(\"var s0=Math.abs(this.stride[0]),s1=Math.abs(this.stride[1]),s2=Math.abs(this.stride[2]);if(s0>s1){if(s1>s2){return [2,1,0];}else if(s0>s2){return [1,2,0];}else{return [1,0,2];}}else if(s0>s2){return [2,0,1];}else if(s2>s1){return [0,1,2];}else{return [0,2,1];}}})\")):f.push(\"ORDER})\")),f.push(\"proto.set=function \"+c+\"_set(\"+M.join(\",\")+\",v){\"),N?f.push(\"return this.data.set(\"+L+\",v)}\"):f.push(\"return this.data[\"+L+\"]=v}\"),f.push(\"proto.get=function \"+c+\"_get(\"+M.join(\",\")+\"){\"),N?f.push(\"return this.data.get(\"+L+\")}\"):f.push(\"return this.data[\"+L+\"]}\"),f.push(\"proto.index=function \"+c+\"_index(\",M.join(),\"){return \"+L+\"}\"),f.push(\"proto.hi=function \"+c+\"_hi(\"+M.join(\",\")+\"){return new \"+c+\"(this.data,\"+d.map(function(p){return[\"(typeof i\",p,\"!=='number'||i\",p,\"<0)?this.shape[\",p,\"]:i\",p,\"|0\"].join(\"\")}).join(\",\")+\",\"+d.map(function(p){return\"this.stride[\"+p+\"]\"}).join(\",\")+\",this.offset)}\");var A=d.map(function(p){return\"a\"+p+\"=this.shape[\"+p+\"]\"}),o=d.map(function(p){return\"c\"+p+\"=this.stride[\"+p+\"]\"});f.push(\"proto.lo=function \"+c+\"_lo(\"+M.join(\",\")+\"){var b=this.offset,d=0,\"+A.join(\",\")+\",\"+o.join(\",\"));for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){d=i\"+i+\"|0;b+=c\"+i+\"*d;a\"+i+\"-=d}\");f.push(\"return new \"+c+\"(this.data,\"+d.map(function(p){return\"a\"+p}).join(\",\")+\",\"+d.map(function(p){return\"c\"+p}).join(\",\")+\",b)}\"),f.push(\"proto.step=function \"+c+\"_step(\"+M.join(\",\")+\"){var \"+d.map(function(p){return\"a\"+p+\"=this.shape[\"+p+\"]\"}).join(\",\")+\",\"+d.map(function(p){return\"b\"+p+\"=this.stride[\"+p+\"]\"}).join(\",\")+\",c=this.offset,d=0,ceil=Math.ceil\");for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'){d=i\"+i+\"|0;if(d<0){c+=b\"+i+\"*(a\"+i+\"-1);a\"+i+\"=ceil(-a\"+i+\"/d)}else{a\"+i+\"=ceil(a\"+i+\"/d)}b\"+i+\"*=d}\");f.push(\"return new \"+c+\"(this.data,\"+d.map(function(p){return\"a\"+p}).join(\",\")+\",\"+d.map(function(p){return\"b\"+p}).join(\",\")+\",c)}\");for(var Z=new Array(h),R=new Array(h),i=0;i<h;++i)Z[i]=\"a[i\"+i+\"]\",R[i]=\"b[i\"+i+\"]\";f.push(\"proto.transpose=function \"+c+\"_transpose(\"+M+\"){\"+M.map(function(p,U){return p+\"=(\"+p+\"===undefined?\"+U+\":\"+p+\"|0)\"}).join(\";\"),\"var a=this.shape,b=this.stride;return new \"+c+\"(this.data,\"+Z.join(\",\")+\",\"+R.join(\",\")+\",this.offset)}\"),f.push(\"proto.pick=function \"+c+\"_pick(\"+M+\"){var a=[],b=[],c=this.offset\");for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){c=(c+this.stride[\"+i+\"]*i\"+i+\")|0}else{a.push(this.shape[\"+i+\"]);b.push(this.stride[\"+i+\"])}\");f.push(\"var ctor=CTOR_LIST[a.length+1];return ctor(this.data,a,b,c)}\"),f.push(\"return function construct_\"+c+\"(data,shape,stride,offset){return new \"+c+\"(data,\"+d.map(function(p){return\"shape[\"+p+\"]\"}).join(\",\")+\",\"+d.map(function(p){return\"stride[\"+p+\"]\"}).join(\",\")+\",offset)}\");var O=new Function(\"CTOR_LIST\",\"ORDER\",f.join(`\n",
              "`));return O(u[l],m)}function C(l){if(n(l))return\"buffer\";if(g)switch(Object.prototype.toString.call(l)){case\"[object Float64Array]\":return\"float64\";case\"[object Float32Array]\":return\"float32\";case\"[object Int8Array]\":return\"int8\";case\"[object Int16Array]\":return\"int16\";case\"[object Int32Array]\":return\"int32\";case\"[object Uint8Array]\":return\"uint8\";case\"[object Uint16Array]\":return\"uint16\";case\"[object Uint32Array]\":return\"uint32\";case\"[object Uint8ClampedArray]\":return\"uint8_clamped\";case\"[object BigInt64Array]\":return\"bigint64\";case\"[object BigUint64Array]\":return\"biguint64\"}return Array.isArray(l)?\"array\":\"generic\"}var u={float32:[],float64:[],int8:[],int16:[],int32:[],uint8:[],uint16:[],uint32:[],array:[],uint8_clamped:[],bigint64:[],biguint64:[],buffer:[],generic:[]};function v(l,h,c,N){if(l===void 0){var D=u.array[0];return D([])}else typeof l==\"number\"&&(l=[l]);h===void 0&&(h=[l.length]);var f=h.length;if(c===void 0){c=new Array(f);for(var d=f-1,M=1;d>=0;--d)c[d]=M,M*=h[d]}if(N===void 0){N=0;for(var d=0;d<f;++d)c[d]<0&&(N-=(h[d]-1)*c[d])}for(var L=C(l),j=u[L];j.length<=f+1;)j.push(_(L,j.length-1));var D=j[f+1];return D(l,h,c,N)}k.exports=v},829:(k,I)=>{\"use strict\";var E;E={value:!0},I.g=m;function T(u,v){if(!(u instanceof v))throw new TypeError(\"Cannot call a class as a function\")}function n(u,v){for(var l,h=0;h<v.length;h++)l=v[h],l.enumerable=l.enumerable||!1,l.configurable=!0,\"value\"in l&&(l.writable=!0),Object.defineProperty(u,l.key,l)}function g(u,v,l){return v&&n(u.prototype,v),l&&n(u,l),u}var s=function(){function u(v){T(this,u),v instanceof DataView?this.dataView=v:v instanceof ArrayBuffer&&(this.dataView=new DataView(v)),this.offset=0}return g(u,[{key:\"readBytes\",value:function(l){var h=new DataView(this.dataView.buffer,this.offset,l);return this.offset+=l,h}},{key:\"readAndASCIIDecodeBytes\",value:function(l){var h=new Uint8Array(this.dataView.buffer,this.offset,l);return this.offset+=l,this._decodeASCIIByteArray(h)}},{key:\"readUint8\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint8(this.offset,l);return this.offset+=Uint8Array.BYTES_PER_ELEMENT,h}},{key:\"readUint16\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint16(this.offset,l);return this.offset+=Uint16Array.BYTES_PER_ELEMENT,h}},{key:\"readUint32\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint32(this.offset,l);return this.offset+=Uint32Array.BYTES_PER_ELEMENT,h}},{key:\"_decodeASCIIByteArray\",value:function(l){var h=String.fromCharCode,c=[],N=!0,f=!1,d=void 0;try{for(var M,L=l[Symbol.iterator]();!(N=(M=L.next()).done);N=!0){var j=M.value,D=h(j);c.push(D)}}catch(A){f=!0,d=A}finally{try{N||L.return==null||L.return()}finally{if(f)throw d}}return c.join(\"\")}}]),u}();function m(u){if(!u instanceof ArrayBuffer)throw new Error(\"Argument must be an ArrayBuffer.\");var v=new s(u),l=v.readUint8(),h=v.readAndASCIIDecodeBytes(5);if(l!=147||h!=\"NUMPY\")throw new Error('unknown file type: \"'.concat(l).concat(h,'\"'));var c,N=v.readUint8(),f=v.readUint8();c=1>=N?v.readUint16(!0):v.readUint32(!0);var d=10+c;d%16!=0&&console.warn(\"NPY file header is incorrectly padded. (\".concat(d,\" is not evenly divisible by 16.)\"));var M=v.readAndASCIIDecodeBytes(c),L=_(M);if(L.fortran_order)throw new Error(\"NPY file is written in Fortran byte order, support for this byte order is not yet implemented.\");var j=C(L.descr),D=new j(u,v.offset);return{data:D,shape:L.shape}}function _(u){var v=u.toLowerCase().replace(\"(\",\"[\").replace(\"),\",\"]\").replace(\"[,\",\"[1,]\").replace(\",]\",\",1]\").replace(/'/g,'\"');return JSON.parse(v)}function C(u){switch(u){case\"|u1\":return Uint8Array;case\"<u2\":return Uint16Array;case\"<u4\":return Uint32Array;case\"<u8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit unsigned integer values, support for this dtype is not yet implemented.\");case\"|i1\":return Int8Array;case\"<i2\":return Int16Array;case\"<i4\":return Int32Array;case\"<i8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit integer values, support for this dtype is not yet implemented.\");case\"<f2\":throw new Error(\"Because JavaScript doesn't currently include standard support for 16-bit floating point values, support for this dtype is not yet implemented.\");case\"<f4\":return Float32Array;case\"<f8\":return Float64Array;default:throw new Error(\"Unknown or not yet implemented numpy dtype description: \"+dtype)}}},843:(k,I,E)=>{\"use strict\";var T;const n=E(948),g=E(236),s=E(373),m=E(898),_=E(292),C=E(401),u=Object.prototype.toString,{Z_NO_FLUSH:v,Z_FINISH:l,Z_OK:h,Z_STREAM_END:c,Z_NEED_DICT:N,Z_STREAM_ERROR:f,Z_DATA_ERROR:d,Z_MEM_ERROR:M}=E(619);function L(A){this.options=g.assign({chunkSize:65536,windowBits:15,to:\"\"},A||{});const o=this.options;o.raw&&o.windowBits>=0&&o.windowBits<16&&(o.windowBits=-o.windowBits,o.windowBits===0&&(o.windowBits=-15)),o.windowBits>=0&&o.windowBits<16&&!(A&&A.windowBits)&&(o.windowBits+=32),o.windowBits>15&&o.windowBits<48&&(o.windowBits&15)===0&&(o.windowBits|=15),this.err=0,this.msg=\"\",this.ended=!1,this.chunks=[],this.strm=new _,this.strm.avail_out=0;let i=n.inflateInit2(this.strm,o.windowBits);if(i!==h)throw new Error(m[i]);if(this.header=new C,n.inflateGetHeader(this.strm,this.header),o.dictionary&&(typeof o.dictionary==\"string\"?o.dictionary=s.string2buf(o.dictionary):u.call(o.dictionary)===\"[object ArrayBuffer]\"&&(o.dictionary=new Uint8Array(o.dictionary)),o.raw&&(i=n.inflateSetDictionary(this.strm,o.dictionary),i!==h)))throw new Error(m[i])}L.prototype.push=function(A,o){const i=this.strm,Z=this.options.chunkSize,R=this.options.dictionary;let O,p,U;if(this.ended)return!1;for(o===~~o?p=o:p=o===!0?l:v,u.call(A)===\"[object ArrayBuffer]\"?i.input=new Uint8Array(A):i.input=A,i.next_in=0,i.avail_in=i.input.length;;){for(i.avail_out===0&&(i.output=new Uint8Array(Z),i.next_out=0,i.avail_out=Z),O=n.inflate(i,p),O===N&&R&&(O=n.inflateSetDictionary(i,R),O===h?O=n.inflate(i,p):O===d&&(O=N));i.avail_in>0&&O===c&&i.state.wrap>0&&A[i.next_in]!==0;)n.inflateReset(i),O=n.inflate(i,p);switch(O){case f:case d:case N:case M:return this.onEnd(O),this.ended=!0,!1}if(U=i.avail_out,i.next_out&&(i.avail_out===0||O===c))if(this.options.to===\"string\"){let B=s.utf8border(i.output,i.next_out),K=i.next_out-B,V=s.buf2string(i.output,B);i.next_out=K,i.avail_out=Z-K,K&&i.output.set(i.output.subarray(B,B+K),0),this.onData(V)}else this.onData(i.output.length===i.next_out?i.output:i.output.subarray(0,i.next_out));if(!(O===h&&U===0)){if(O===c)return O=n.inflateEnd(this.strm),this.onEnd(O),this.ended=!0,!0;if(i.avail_in===0)break}}return!0},L.prototype.onData=function(A){this.chunks.push(A)},L.prototype.onEnd=function(A){A===h&&(this.options.to===\"string\"?this.result=this.chunks.join(\"\"):this.result=g.flattenChunks(this.chunks)),this.chunks=[],this.err=A,this.msg=this.strm.msg};function j(A,o){const i=new L(o);if(i.push(A),i.err)throw i.msg||m[i.err];return i.result}function D(A,o){return o=o||{},o.raw=!0,j(A,o)}T=L,k.exports.rr=j,T=D,T=j,E(619)},236:k=>{\"use strict\";const I=(E,T)=>Object.prototype.hasOwnProperty.call(E,T);k.exports.assign=function(E){const T=Array.prototype.slice.call(arguments,1);for(;T.length;){const n=T.shift();if(!!n){if(typeof n!=\"object\")throw new TypeError(n+\"must be non-object\");for(const g in n)I(n,g)&&(E[g]=n[g])}}return E},k.exports.flattenChunks=E=>{let T=0;for(let g=0,s=E.length;g<s;g++)T+=E[g].length;const n=new Uint8Array(T);for(let g=0,s=0,m=E.length;g<m;g++){let _=E[g];n.set(_,s),s+=_.length}return n}},373:k=>{\"use strict\";let I=!0;try{String.fromCharCode.apply(null,new Uint8Array(1))}catch(n){I=!1}const E=new Uint8Array(256);for(let n=0;n<256;n++)E[n]=n>=252?6:n>=248?5:n>=240?4:n>=224?3:n>=192?2:1;E[254]=E[254]=1,k.exports.string2buf=n=>{let g,s,m,_,C,u=n.length,v=0;for(_=0;_<u;_++)s=n.charCodeAt(_),(s&64512)===55296&&_+1<u&&(m=n.charCodeAt(_+1),(m&64512)===56320&&(s=65536+(s-55296<<10)+(m-56320),_++)),v+=s<128?1:s<2048?2:s<65536?3:4;for(g=new Uint8Array(v),C=0,_=0;C<v;_++)s=n.charCodeAt(_),(s&64512)===55296&&_+1<u&&(m=n.charCodeAt(_+1),(m&64512)===56320&&(s=65536+(s-55296<<10)+(m-56320),_++)),s<128?g[C++]=s:s<2048?(g[C++]=192|s>>>6,g[C++]=128|s&63):s<65536?(g[C++]=224|s>>>12,g[C++]=128|s>>>6&63,g[C++]=128|s&63):(g[C++]=240|s>>>18,g[C++]=128|s>>>12&63,g[C++]=128|s>>>6&63,g[C++]=128|s&63);return g};const T=(n,g)=>{if(g<65534&&n.subarray&&I)return String.fromCharCode.apply(null,n.length===g?n:n.subarray(0,g));let s=\"\";for(let m=0;m<g;m++)s+=String.fromCharCode(n[m]);return s};k.exports.buf2string=(n,g)=>{let s,m;const _=g||n.length,C=new Array(_*2);for(m=0,s=0;s<_;){let u=n[s++];if(u<128){C[m++]=u;continue}let v=E[u];if(v>4){C[m++]=65533,s+=v-1;continue}for(u&=v===2?31:v===3?15:7;v>1&&s<_;)u=u<<6|n[s++]&63,v--;if(v>1){C[m++]=65533;continue}u<65536?C[m++]=u:(u-=65536,C[m++]=55296|u>>10&1023,C[m++]=56320|u&1023)}return T(C,m)},k.exports.utf8border=(n,g)=>{g=g||n.length,g>n.length&&(g=n.length);let s=g-1;for(;s>=0&&(n[s]&192)===128;)s--;return s<0||s===0?g:s+E[n[s]]>g?s:g}},69:k=>{\"use strict\";const I=(E,T,n,g)=>{let s=E&65535|0,m=E>>>16&65535|0,_=0;for(;n!==0;){_=n>2e3?2e3:n,n-=_;do s=s+T[g++]|0,m=m+s|0;while(--_);s%=65521,m%=65521}return s|m<<16|0};k.exports=I},619:k=>{\"use strict\";k.exports={Z_NO_FLUSH:0,Z_PARTIAL_FLUSH:1,Z_SYNC_FLUSH:2,Z_FULL_FLUSH:3,Z_FINISH:4,Z_BLOCK:5,Z_TREES:6,Z_OK:0,Z_STREAM_END:1,Z_NEED_DICT:2,Z_ERRNO:-1,Z_STREAM_ERROR:-2,Z_DATA_ERROR:-3,Z_MEM_ERROR:-4,Z_BUF_ERROR:-5,Z_NO_COMPRESSION:0,Z_BEST_SPEED:1,Z_BEST_COMPRESSION:9,Z_DEFAULT_COMPRESSION:-1,Z_FILTERED:1,Z_HUFFMAN_ONLY:2,Z_RLE:3,Z_FIXED:4,Z_DEFAULT_STRATEGY:0,Z_BINARY:0,Z_TEXT:1,Z_UNKNOWN:2,Z_DEFLATED:8}},869:k=>{\"use strict\";const I=()=>{let n,g=[];for(var s=0;s<256;s++){n=s;for(var m=0;m<8;m++)n=n&1?3988292384^n>>>1:n>>>1;g[s]=n}return g},E=new Uint32Array(I()),T=(n,g,s,m)=>{const _=E,C=m+s;n^=-1;for(let u=m;u<C;u++)n=n>>>8^_[(n^g[u])&255];return n^-1};k.exports=T},401:k=>{\"use strict\";function I(){this.text=0,this.time=0,this.xflags=0,this.os=0,this.extra=null,this.extra_len=0,this.name=\"\",this.comment=\"\",this.hcrc=0,this.done=!1}k.exports=I},264:k=>{\"use strict\";k.exports=function(n,g){let s,m,_,C,u,v,l,h,c,N,f,d,M,L,j,D,A,o,i,Z,R,O,p,U;const B=n.state;s=n.next_in,p=n.input,m=s+(n.avail_in-5),_=n.next_out,U=n.output,C=_-(g-n.avail_out),u=_+(n.avail_out-257),v=B.dmax,l=B.wsize,h=B.whave,c=B.wnext,N=B.window,f=B.hold,d=B.bits,M=B.lencode,L=B.distcode,j=(1<<B.lenbits)-1,D=(1<<B.distbits)-1;e:do{d<15&&(f+=p[s++]<<d,d+=8,f+=p[s++]<<d,d+=8),A=M[f&j];t:for(;;){if(o=A>>>24,f>>>=o,d-=o,o=A>>>16&255,o===0)U[_++]=A&65535;else if(o&16){i=A&65535,o&=15,o&&(d<o&&(f+=p[s++]<<d,d+=8),i+=f&(1<<o)-1,f>>>=o,d-=o),d<15&&(f+=p[s++]<<d,d+=8,f+=p[s++]<<d,d+=8),A=L[f&D];i:for(;;){if(o=A>>>24,f>>>=o,d-=o,o=A>>>16&255,o&16){if(Z=A&65535,o&=15,d<o&&(f+=p[s++]<<d,d+=8,d<o&&(f+=p[s++]<<d,d+=8)),Z+=f&(1<<o)-1,Z>v){n.msg=\"invalid distance too far back\",B.mode=30;break e}if(f>>>=o,d-=o,o=_-C,Z>o){if(o=Z-o,o>h&&B.sane){n.msg=\"invalid distance too far back\",B.mode=30;break e}if(R=0,O=N,c===0){if(R+=l-o,o<i){i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}}else if(c<o){if(R+=l+c-o,o-=c,o<i){i-=o;do U[_++]=N[R++];while(--o);if(R=0,c<i){o=c,i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}}}else if(R+=c-o,o<i){i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}for(;i>2;)U[_++]=O[R++],U[_++]=O[R++],U[_++]=O[R++],i-=3;i&&(U[_++]=O[R++],i>1&&(U[_++]=O[R++]))}else{R=_-Z;do U[_++]=U[R++],U[_++]=U[R++],U[_++]=U[R++],i-=3;while(i>2);i&&(U[_++]=U[R++],i>1&&(U[_++]=U[R++]))}}else if((o&64)===0){A=L[(A&65535)+(f&(1<<o)-1)];continue i}else{n.msg=\"invalid distance code\",B.mode=30;break e}break}}else if((o&64)===0){A=M[(A&65535)+(f&(1<<o)-1)];continue t}else if(o&32){B.mode=12;break e}else{n.msg=\"invalid literal/length code\",B.mode=30;break e}break}}while(s<m&&_<u);i=d>>3,s-=i,d-=i<<3,f&=(1<<d)-1,n.next_in=s,n.next_out=_,n.avail_in=s<m?5+(m-s):5-(s-m),n.avail_out=_<u?257+(u-_):257-(_-u),B.hold=f,B.bits=d}},948:(k,I,E)=>{\"use strict\";const T=E(69),n=E(869),g=E(264),s=E(241),m=0,_=1,C=2,{Z_FINISH:u,Z_BLOCK:v,Z_TREES:l,Z_OK:h,Z_STREAM_END:c,Z_NEED_DICT:N,Z_STREAM_ERROR:f,Z_DATA_ERROR:d,Z_MEM_ERROR:M,Z_BUF_ERROR:L,Z_DEFLATED:j}=E(619),D=1,A=2,o=3,i=4,Z=5,R=6,O=7,p=8,U=9,B=10,K=11,V=12,fe=13,de=14,ne=15,ce=16,pe=17,le=18,te=19,re=20,ae=21,we=22,_e=23,ue=24,he=25,Te=26,ke=27,Oe=28,De=29,F=30,Ee=31,Pe=32,Fe=852,je=592,He=15,Re=t=>(t>>>24&255)+(t>>>8&65280)+((t&65280)<<8)+((t&255)<<24);function ze(){this.mode=0,this.last=!1,this.wrap=0,this.havedict=!1,this.flags=0,this.dmax=0,this.check=0,this.total=0,this.head=null,this.wbits=0,this.wsize=0,this.whave=0,this.wnext=0,this.window=null,this.hold=0,this.bits=0,this.length=0,this.offset=0,this.extra=0,this.lencode=null,this.distcode=null,this.lenbits=0,this.distbits=0,this.ncode=0,this.nlen=0,this.ndist=0,this.have=0,this.next=null,this.lens=new Uint16Array(320),this.work=new Uint16Array(288),this.lendyn=null,this.distdyn=null,this.sane=0,this.back=0,this.was=0}const Ie=t=>{if(!t||!t.state)return f;const x=t.state;return t.total_in=t.total_out=x.total=0,t.msg=\"\",x.wrap&&(t.adler=x.wrap&1),x.mode=D,x.last=0,x.havedict=0,x.dmax=32768,x.head=null,x.hold=0,x.bits=0,x.lencode=x.lendyn=new Int32Array(Fe),x.distcode=x.distdyn=new Int32Array(je),x.sane=1,x.back=-1,h},Ue=t=>{if(!t||!t.state)return f;const x=t.state;return x.wsize=0,x.whave=0,x.wnext=0,Ie(t)},Ce=(t,x)=>{let e;if(!t||!t.state)return f;const y=t.state;return x<0?(e=0,x=-x):(e=(x>>4)+1,x<48&&(x&=15)),x&&(x<8||x>15)?f:(y.window!==null&&y.wbits!==x&&(y.window=null),y.wrap=e,y.wbits=x,Ue(t))},Ne=(t,x)=>{if(!t)return f;const e=new ze;t.state=e,e.window=null;const y=Ce(t,x);return y!==h&&(t.state=null),y},Ye=t=>Ne(t,He);let Be=!0,Ae,Se;const Ge=t=>{if(Be){Ae=new Int32Array(512),Se=new Int32Array(32);let x=0;for(;x<144;)t.lens[x++]=8;for(;x<256;)t.lens[x++]=9;for(;x<280;)t.lens[x++]=7;for(;x<288;)t.lens[x++]=8;for(s(_,t.lens,0,288,Ae,0,t.work,{bits:9}),x=0;x<32;)t.lens[x++]=5;s(C,t.lens,0,32,Se,0,t.work,{bits:5}),Be=!1}t.lencode=Ae,t.lenbits=9,t.distcode=Se,t.distbits=5},Me=(t,x,e,y)=>{let H;const w=t.state;return w.window===null&&(w.wsize=1<<w.wbits,w.wnext=0,w.whave=0,w.window=new Uint8Array(w.wsize)),y>=w.wsize?(w.window.set(x.subarray(e-w.wsize,e),0),w.wnext=0,w.whave=w.wsize):(H=w.wsize-w.wnext,H>y&&(H=y),w.window.set(x.subarray(e-y,e-y+H),w.wnext),y-=H,y?(w.window.set(x.subarray(e-y,e),0),w.wnext=y,w.whave=w.wsize):(w.wnext+=H,w.wnext===w.wsize&&(w.wnext=0),w.whave<w.wsize&&(w.whave+=H))),0},Xe=(t,x)=>{let e,y,H,w,q,b,G,a,r,xe,z,S,be,me,Y=0,P,J,$,Q,ve,ge,X,ee;const W=new Uint8Array(4);let oe,ie;const Le=new Uint8Array([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]);if(!t||!t.state||!t.output||!t.input&&t.avail_in!==0)return f;e=t.state,e.mode===V&&(e.mode=fe),q=t.next_out,H=t.output,G=t.avail_out,w=t.next_in,y=t.input,b=t.avail_in,a=e.hold,r=e.bits,xe=b,z=G,ee=h;e:for(;;)switch(e.mode){case D:if(e.wrap===0){e.mode=fe;break}for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.wrap&2&&a===35615){e.check=0,W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0),a=0,r=0,e.mode=A;break}if(e.flags=0,e.head&&(e.head.done=!1),!(e.wrap&1)||(((a&255)<<8)+(a>>8))%31){t.msg=\"incorrect header check\",e.mode=F;break}if((a&15)!==j){t.msg=\"unknown compression method\",e.mode=F;break}if(a>>>=4,r-=4,X=(a&15)+8,e.wbits===0)e.wbits=X;else if(X>e.wbits){t.msg=\"invalid window size\",e.mode=F;break}e.dmax=1<<e.wbits,t.adler=e.check=1,e.mode=a&512?B:V,a=0,r=0;break;case A:for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.flags=a,(e.flags&255)!==j){t.msg=\"unknown compression method\",e.mode=F;break}if(e.flags&57344){t.msg=\"unknown header flags set\",e.mode=F;break}e.head&&(e.head.text=a>>8&1),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0,e.mode=o;case o:for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.head&&(e.head.time=a),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,W[2]=a>>>16&255,W[3]=a>>>24&255,e.check=n(e.check,W,4,0)),a=0,r=0,e.mode=i;case i:for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.head&&(e.head.xflags=a&255,e.head.os=a>>8),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0,e.mode=Z;case Z:if(e.flags&1024){for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.length=a,e.head&&(e.head.extra_len=a),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0}else e.head&&(e.head.extra=null);e.mode=R;case R:if(e.flags&1024&&(S=e.length,S>b&&(S=b),S&&(e.head&&(X=e.head.extra_len-e.length,e.head.extra||(e.head.extra=new Uint8Array(e.head.extra_len)),e.head.extra.set(y.subarray(w,w+S),X)),e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,e.length-=S),e.length))break e;e.length=0,e.mode=O;case O:if(e.flags&2048){if(b===0)break e;S=0;do X=y[w+S++],e.head&&X&&e.length<65536&&(e.head.name+=String.fromCharCode(X));while(X&&S<b);if(e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,X)break e}else e.head&&(e.head.name=null);e.length=0,e.mode=p;case p:if(e.flags&4096){if(b===0)break e;S=0;do X=y[w+S++],e.head&&X&&e.length<65536&&(e.head.comment+=String.fromCharCode(X));while(X&&S<b);if(e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,X)break e}else e.head&&(e.head.comment=null);e.mode=U;case U:if(e.flags&512){for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a!==(e.check&65535)){t.msg=\"header crc mismatch\",e.mode=F;break}a=0,r=0}e.head&&(e.head.hcrc=e.flags>>9&1,e.head.done=!0),t.adler=e.check=0,e.mode=V;break;case B:for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}t.adler=e.check=Re(a),a=0,r=0,e.mode=K;case K:if(e.havedict===0)return t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,N;t.adler=e.check=1,e.mode=V;case V:if(x===v||x===l)break e;case fe:if(e.last){a>>>=r&7,r-=r&7,e.mode=ke;break}for(;r<3;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}switch(e.last=a&1,a>>>=1,r-=1,a&3){case 0:e.mode=de;break;case 1:if(Ge(e),e.mode=re,x===l){a>>>=2,r-=2;break e}break;case 2:e.mode=pe;break;case 3:t.msg=\"invalid block type\",e.mode=F}a>>>=2,r-=2;break;case de:for(a>>>=r&7,r-=r&7;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if((a&65535)!==(a>>>16^65535)){t.msg=\"invalid stored block lengths\",e.mode=F;break}if(e.length=a&65535,a=0,r=0,e.mode=ne,x===l)break e;case ne:e.mode=ce;case ce:if(S=e.length,S){if(S>b&&(S=b),S>G&&(S=G),S===0)break e;H.set(y.subarray(w,w+S),q),b-=S,w+=S,G-=S,q+=S,e.length-=S;break}e.mode=V;break;case pe:for(;r<14;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.nlen=(a&31)+257,a>>>=5,r-=5,e.ndist=(a&31)+1,a>>>=5,r-=5,e.ncode=(a&15)+4,a>>>=4,r-=4,e.nlen>286||e.ndist>30){t.msg=\"too many length or distance symbols\",e.mode=F;break}e.have=0,e.mode=le;case le:for(;e.have<e.ncode;){for(;r<3;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.lens[Le[e.have++]]=a&7,a>>>=3,r-=3}for(;e.have<19;)e.lens[Le[e.have++]]=0;if(e.lencode=e.lendyn,e.lenbits=7,oe={bits:e.lenbits},ee=s(m,e.lens,0,19,e.lencode,0,e.work,oe),e.lenbits=oe.bits,ee){t.msg=\"invalid code lengths set\",e.mode=F;break}e.have=0,e.mode=te;case te:for(;e.have<e.nlen+e.ndist;){for(;Y=e.lencode[a&(1<<e.lenbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if($<16)a>>>=P,r-=P,e.lens[e.have++]=$;else{if($===16){for(ie=P+2;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a>>>=P,r-=P,e.have===0){t.msg=\"invalid bit length repeat\",e.mode=F;break}X=e.lens[e.have-1],S=3+(a&3),a>>>=2,r-=2}else if($===17){for(ie=P+3;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=P,r-=P,X=0,S=3+(a&7),a>>>=3,r-=3}else{for(ie=P+7;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=P,r-=P,X=0,S=11+(a&127),a>>>=7,r-=7}if(e.have+S>e.nlen+e.ndist){t.msg=\"invalid bit length repeat\",e.mode=F;break}for(;S--;)e.lens[e.have++]=X}}if(e.mode===F)break;if(e.lens[256]===0){t.msg=\"invalid code -- missing end-of-block\",e.mode=F;break}if(e.lenbits=9,oe={bits:e.lenbits},ee=s(_,e.lens,0,e.nlen,e.lencode,0,e.work,oe),e.lenbits=oe.bits,ee){t.msg=\"invalid literal/lengths set\",e.mode=F;break}if(e.distbits=6,e.distcode=e.distdyn,oe={bits:e.distbits},ee=s(C,e.lens,e.nlen,e.ndist,e.distcode,0,e.work,oe),e.distbits=oe.bits,ee){t.msg=\"invalid distances set\",e.mode=F;break}if(e.mode=re,x===l)break e;case re:e.mode=ae;case ae:if(b>=6&&G>=258){t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,g(t,z),q=t.next_out,H=t.output,G=t.avail_out,w=t.next_in,y=t.input,b=t.avail_in,a=e.hold,r=e.bits,e.mode===V&&(e.back=-1);break}for(e.back=0;Y=e.lencode[a&(1<<e.lenbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(J&&(J&240)===0){for(Q=P,ve=J,ge=$;Y=e.lencode[ge+((a&(1<<Q+ve)-1)>>Q)],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(Q+P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=Q,r-=Q,e.back+=Q}if(a>>>=P,r-=P,e.back+=P,e.length=$,J===0){e.mode=Te;break}if(J&32){e.back=-1,e.mode=V;break}if(J&64){t.msg=\"invalid literal/length code\",e.mode=F;break}e.extra=J&15,e.mode=we;case we:if(e.extra){for(ie=e.extra;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.length+=a&(1<<e.extra)-1,a>>>=e.extra,r-=e.extra,e.back+=e.extra}e.was=e.length,e.mode=_e;case _e:for(;Y=e.distcode[a&(1<<e.distbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if((J&240)===0){for(Q=P,ve=J,ge=$;Y=e.distcode[ge+((a&(1<<Q+ve)-1)>>Q)],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(Q+P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=Q,r-=Q,e.back+=Q}if(a>>>=P,r-=P,e.back+=P,J&64){t.msg=\"invalid distance code\",e.mode=F;break}e.offset=$,e.extra=J&15,e.mode=ue;case ue:if(e.extra){for(ie=e.extra;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.offset+=a&(1<<e.extra)-1,a>>>=e.extra,r-=e.extra,e.back+=e.extra}if(e.offset>e.dmax){t.msg=\"invalid distance too far back\",e.mode=F;break}e.mode=he;case he:if(G===0)break e;if(S=z-G,e.offset>S){if(S=e.offset-S,S>e.whave&&e.sane){t.msg=\"invalid distance too far back\",e.mode=F;break}S>e.wnext?(S-=e.wnext,be=e.wsize-S):be=e.wnext-S,S>e.length&&(S=e.length),me=e.window}else me=H,be=q-e.offset,S=e.length;S>G&&(S=G),G-=S,e.length-=S;do H[q++]=me[be++];while(--S);e.length===0&&(e.mode=ae);break;case Te:if(G===0)break e;H[q++]=e.length,G--,e.mode=ae;break;case ke:if(e.wrap){for(;r<32;){if(b===0)break e;b--,a|=y[w++]<<r,r+=8}if(z-=G,t.total_out+=z,e.total+=z,z&&(t.adler=e.check=e.flags?n(e.check,H,z,q-z):T(e.check,H,z,q-z)),z=G,(e.flags?a:Re(a))!==e.check){t.msg=\"incorrect data check\",e.mode=F;break}a=0,r=0}e.mode=Oe;case Oe:if(e.wrap&&e.flags){for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a!==(e.total&4294967295)){t.msg=\"incorrect length check\",e.mode=F;break}a=0,r=0}e.mode=De;case De:ee=c;break e;case F:ee=d;break e;case Ee:return M;case Pe:default:return f}return t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,(e.wsize||z!==t.avail_out&&e.mode<F&&(e.mode<ke||x!==u))&&Me(t,t.output,t.next_out,z-t.avail_out)?(e.mode=Ee,M):(xe-=t.avail_in,z-=t.avail_out,t.total_in+=xe,t.total_out+=z,e.total+=z,e.wrap&&z&&(t.adler=e.check=e.flags?n(e.check,H,z,t.next_out-z):T(e.check,H,z,t.next_out-z)),t.data_type=e.bits+(e.last?64:0)+(e.mode===V?128:0)+(e.mode===re||e.mode===ne?256:0),(xe===0&&z===0||x===u)&&ee===h&&(ee=L),ee)},Ke=t=>{if(!t||!t.state)return f;let x=t.state;return x.window&&(x.window=null),t.state=null,h},Ve=(t,x)=>{if(!t||!t.state)return f;const e=t.state;return(e.wrap&2)===0?f:(e.head=x,x.done=!1,h)},We=(t,x)=>{const e=x.length;let y,H,w;return!t||!t.state||(y=t.state,y.wrap!==0&&y.mode!==K)?f:y.mode===K&&(H=1,H=T(H,x,e,0),H!==y.check)?d:(w=Me(t,x,e,e),w?(y.mode=Ee,M):(y.havedict=1,h))};k.exports.inflateReset=Ue,k.exports.inflateReset2=Ce,k.exports.inflateResetKeep=Ie,k.exports.inflateInit=Ye,k.exports.inflateInit2=Ne,k.exports.inflate=Xe,k.exports.inflateEnd=Ke,k.exports.inflateGetHeader=Ve,k.exports.inflateSetDictionary=We,k.exports.inflateInfo=\"pako inflate (from Nodeca project)\"},241:k=>{\"use strict\";const m=new Uint16Array([3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,0,0]),_=new Uint8Array([16,16,16,16,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,16,72,78]),C=new Uint16Array([1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577,0,0]),u=new Uint8Array([16,16,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,64,64]),v=(l,h,c,N,f,d,M,L)=>{const j=L.bits;let D=0,A=0,o=0,i=0,Z=0,R=0,O=0,p=0,U=0,B=0,K,V,fe,de,ne,ce=null,pe=0,le;const te=new Uint16Array(15+1),re=new Uint16Array(15+1);let ae=null,we=0,_e,ue,he;for(D=0;D<=15;D++)te[D]=0;for(A=0;A<N;A++)te[h[c+A]]++;for(Z=j,i=15;i>=1&&te[i]===0;i--);if(Z>i&&(Z=i),i===0)return f[d++]=1<<24|64<<16|0,f[d++]=1<<24|64<<16|0,L.bits=1,0;for(o=1;o<i&&te[o]===0;o++);for(Z<o&&(Z=o),p=1,D=1;D<=15;D++)if(p<<=1,p-=te[D],p<0)return-1;if(p>0&&(l===0||i!==1))return-1;for(re[1]=0,D=1;D<15;D++)re[D+1]=re[D]+te[D];for(A=0;A<N;A++)h[c+A]!==0&&(M[re[h[c+A]]++]=A);if(l===0?(ce=ae=M,le=19):l===1?(ce=m,pe-=257,ae=_,we-=257,le=256):(ce=C,ae=u,le=-1),B=0,A=0,D=o,ne=d,R=Z,O=0,fe=-1,U=1<<Z,de=U-1,l===1&&U>852||l===2&&U>592)return 1;for(;;){_e=D-O,M[A]<le?(ue=0,he=M[A]):M[A]>le?(ue=ae[we+M[A]],he=ce[pe+M[A]]):(ue=32+64,he=0),K=1<<D-O,V=1<<R,o=V;do V-=K,f[ne+(B>>O)+V]=_e<<24|ue<<16|he|0;while(V!==0);for(K=1<<D-1;B&K;)K>>=1;if(K!==0?(B&=K-1,B+=K):B=0,A++,--te[D]===0){if(D===i)break;D=h[c+M[A]]}if(D>Z&&(B&de)!==fe){for(O===0&&(O=Z),ne+=o,R=D-O,p=1<<R;R+O<i&&(p-=te[R+O],!(p<=0));)R++,p<<=1;if(U+=1<<R,l===1&&U>852||l===2&&U>592)return 1;fe=B&de,f[fe]=Z<<24|R<<16|ne-d|0}}return B!==0&&(f[ne+B]=D-O<<24|64<<16|0),L.bits=Z,0};k.exports=v},898:k=>{\"use strict\";k.exports={2:\"need dictionary\",1:\"stream end\",0:\"\",\"-1\":\"file error\",\"-2\":\"stream error\",\"-3\":\"data error\",\"-4\":\"insufficient memory\",\"-5\":\"buffer error\",\"-6\":\"incompatible version\"}},292:k=>{\"use strict\";function I(){this.input=null,this.next_in=0,this.avail_in=0,this.total_in=0,this.output=null,this.next_out=0,this.avail_out=0,this.total_out=0,this.msg=\"\",this.state=null,this.data_type=2,this.adler=0}k.exports=I},330:(k,I,E)=>{\"use strict\";E.d(I,{default:()=>C});var T=E(829),n=E(861),g=E.n(n),s=E(843);function m(u){if(u.__type__==\"npy\"){var v;if(window.obj=u,u.hasOwnProperty(\"zdata\")){const f=Uint8Array.from(window.atob(u.zdata),d=>d.charCodeAt(0));v=(0,s.rr)(f)}else v=Uint8Array.from(window.atob(u.data),f=>f.charCodeAt(0));var l=(0,T.g)(v.buffer);if(l=n(l.data,l.shape),u.hasOwnProperty(\"min\")){let f=l.dtype===\"uint8\"?255:65535;for(var h=1,c=0;c<l.shape.length;c++)h=h*l.shape[c];for(var N=n(new Float32Array(h),l.shape),c=0;c<l.data.length;c++)N.data[c]=u.min+(u.max-u.min)*l.data[c]/f;return N}else return l}else return{}}function _(u){if(Array.isArray(u)){var v=[];for(var l of u)v.push(_(l));return v}else if(u instanceof Object){if(u.hasOwnProperty(\"__type__\"))return m(u);var v={};for(var h of Object.keys(u))v[h]=_(u[h]);return v}else return u}const C=loader={unpack_obj:_}}},ye={};function se(k){if(ye[k])return ye[k].exports;var I=ye[k]={exports:{}};return Ze[k](I,I.exports,se),I.exports}return se.n=k=>{var I=k&&k.__esModule?()=>k.default:()=>k;return se.d(I,{a:I}),I},se.d=(k,I)=>{for(var E in I)se.o(I,E)&&!se.o(k,E)&&Object.defineProperty(k,E,{enumerable:!0,get:I[E]})},se.o=(k,I)=>Object.prototype.hasOwnProperty.call(k,I),se(330)})().default;\n",
              "</script>\n",
              "        \n",
              "        <div id=\"AttentionMulti_362035c\"></div>\n",
              "        <script>\n",
              "        ( () => {\n",
              "            var data = {\n",
              "\"tokens\": [\n",
              "\"<|endoftext|>\",\n",
              "\"I\",\n",
              "\" am\",\n",
              "\" an\",\n",
              "\" amazing\",\n",
              "\" aut\",\n",
              "\"ore\",\n",
              "\"gressive\",\n",
              "\",\",\n",
              "\" dec\",\n",
              "\"oder\",\n",
              "\"-\",\n",
              "\"only\",\n",
              "\",\",\n",
              "\" G\",\n",
              "\"PT\",\n",
              "\"-\",\n",
              "\"2\",\n",
              "\" style\",\n",
              "\" transformer\",\n",
              "\".\",\n",
              "\" One\",\n",
              "\" day\",\n",
              "\" I\",\n",
              "\" will\",\n",
              "\" exceed\",\n",
              "\" human\",\n",
              "\" level\",\n",
              "\" intelligence\",\n",
              "\" and\",\n",
              "\" take\",\n",
              "\" over\",\n",
              "\" the\",\n",
              "\" world\",\n",
              "\"!\"\n",
              "],\n",
              "\"attention\": {\n",
              "\"__type__\": \"npy\",\n",
              "\"zdata\": \"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\",\n",
              "\"min\": 0.0,\n",
              "\"max\": 1.0\n",
              "}\n",
              "};\n",
              "            data = loader.unpack_obj(data);\n",
              "            window.AttentionMulti_data = data;\n",
              "            var AttentionMulti_inst = new AttentionMulti({\n",
              "                \"target\": document.getElementById(\"AttentionMulti_362035c\"),\n",
              "                \"props\": data\n",
              "                });\n",
              "        })();\n",
              "        </script>\n",
              "        \n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pysvelte\n",
        "pysvelte.AttentionMulti(tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache['blocks.0.attn.hook_attn'][0].permute(1, 2, 0)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCSNJu227Jzu",
        "outputId": "a128ea85-b5d4-407b-8530-bfc4fa51d458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 7.9663e-01,  1.6985e-02,  3.4781e-02,  ...,  3.3120e-02,\n",
              "          -2.3129e-02,  1.8103e-01],\n",
              "         [ 1.3165e-03,  1.5750e-01, -1.4059e-01,  ..., -8.1997e-03,\n",
              "           5.3075e-03,  1.3511e-01],\n",
              "         [ 8.9738e-02, -7.2411e-01, -6.9866e-01,  ...,  5.5321e-02,\n",
              "           2.7959e-03,  9.0785e-02],\n",
              "         ...,\n",
              "         [-3.0286e-01,  4.9638e-02, -6.0990e-01,  ..., -3.7084e-02,\n",
              "          -4.9522e-04, -8.6007e-03],\n",
              "         [-1.0844e+00, -6.1457e-02,  2.2966e-01,  ..., -2.6688e-02,\n",
              "          -1.4368e-02,  3.3245e-02],\n",
              "         [ 3.7947e-01, -4.9886e-01,  2.6434e-01,  ..., -2.7894e-02,\n",
              "          -8.9028e-03,  4.8796e-02]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "from datasets.download.download_manager import BASE_KNOWN_EXTENSIONS\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cuda\"))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        Qs = einsum(\"batch Q_pos d_model, n_heads d_model h_dim -> batch Q_pos n_heads h_dim\", normalized_resid_pre, self.W_Q)+self.b_Q\n",
        "        Ks = einsum(\"batch k_pos d_model, n_heads d_model h_dim -> batch k_pos n_heads h_dim\", normalized_resid_pre, self.W_K)+self.b_K\n",
        "        scores = einsum(\"batch Q_pos n_heads h_dim, batch k_pos n_heads h_dim -> batch n_heads Q_pos k_pos\", Qs, Ks)\n",
        "        mask_scores = self.apply_causal_mask(scores)\n",
        "        mask_scores = mask_scores / math.sqrt(self.cfg.d_head)\n",
        "        mask_scores = mask_scores.softmax(dim = -1)\n",
        "\n",
        "        Vs = einsum(\"batch Q_pos d_model, n_heads d_model h_dim -> batch Q_pos n_heads h_dim\", normalized_resid_pre, self.W_V)+self.b_V\n",
        "        Vs = einsum(\"batch n_heads Q_pos k_pos, batch k_pos n_heads h_dim-> batch Q_pos n_heads h_dim\", mask_scores, Vs)\n",
        "        ans = einsum(\"batch Q_pos n_heads h_dim, n_heads h_dim d_model -> batch Q_pos d_model\", Vs, self.W_O)+self.b_O\n",
        "        return ans\n",
        "\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        mask = torch.triu(torch.ones_like(attn_scores), diagonal = 1)\n",
        "        mask*=-1000000\n",
        "        ans = attn_scores+mask\n",
        "        return ans\n",
        "\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.triu(torch.ones((4,5)))\n",
        "print(a[2,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quhSmZc33uNM",
        "outputId": "968dd715-610c-4ec4-9b91-a076b79521bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPlFIUG17Jzu"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN3pWKqd7Jzu",
        "outputId": "c9924cb0-774b-428f-bc76-2d0fd4be8323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4380,  0.3624,  0.5117,  ...,  1.7227,  1.5761,  0.0368],\n",
              "         [-1.0766, -0.0438,  0.3276,  ..., -0.5437,  0.4033,  0.3717],\n",
              "         [-1.2182, -1.5481, -0.9702,  ...,  1.0737,  0.7199,  0.5080],\n",
              "         ...,\n",
              "         [-0.4004,  0.8475,  0.2047,  ...,  0.3789,  0.0455, -0.4744],\n",
              "         [-0.0862,  0.7839,  0.9046,  ..., -0.2175, -0.5953,  0.8555],\n",
              "         [ 0.8448, -0.3743,  1.0397,  ...,  0.0296,  0.3405,  0.3585]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        midputs = einsum(\"b p d_model, d_model d_mlp -> b p d_mlp \", normalized_resid_mid, self.W_in)+self.b_in\n",
        "        midputs = torch.nn.functional.gelu(midputs, approximate = \"tanh\")\n",
        "        outputs = einsum(\"b p d_mlp, d_mlp d_model -> b p d_model \", midputs, self.W_out)+self.b_out\n",
        "        return outputs\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzKjK8I77Jzv"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYEaAWWI7Jzv",
        "outputId": "6b41c673-a5eb-466e-8ba2-967457378500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "98.46% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3911,  0.1543,  0.6005,  ...,  1.7198,  1.7365,  0.3930],\n",
              "         [-0.9040, -0.0359,  0.2350,  ..., -0.4148,  0.3562,  0.3937],\n",
              "         [-0.9647, -2.4819, -1.4996,  ...,  1.4046,  0.7616,  0.5919],\n",
              "         ...,\n",
              "         [-0.7422,  0.9252, -0.3218,  ...,  0.2921,  0.1097, -0.5344],\n",
              "         [-1.3220,  0.8960,  1.1797,  ..., -0.5545, -0.4072,  0.9255],\n",
              "         [ 1.1209, -0.8917,  1.3739,  ..., -0.1355,  0.3433,  0.4517]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        normalized_resid_pre = self.ln1(resid_pre)\n",
        "        attn_out = self.attn(normalized_resid_pre)\n",
        "        resid_mid = resid_pre + attn_out\n",
        "\n",
        "        normalized_resid_mid = self.ln2(resid_mid)\n",
        "        mlp_out = self.mlp(normalized_resid_mid)\n",
        "        resid_post = resid_mid + mlp_out\n",
        "        return resid_post\n",
        "\n",
        "        norm_resid_pre_attn = self.ln1(resid_pre)\n",
        "        unnorm_resid_post_attn = resid_pre + self.attn(norm_resid_pre_attn)\n",
        "        norm_resid_post_attn = self.ln2(unnorm_resid_post_attn)\n",
        "        ans = unnorm_resid_post_attn + self.mlp(norm_resid_post_attn)\n",
        "        #if torch.equal(normalized_resid_pre,norm_resid_pre_attn): print(\"pass 1\")\n",
        "        #if torch.equal(resid_mid, unnorm_resid_post_attn): print(\"pass 2\")\n",
        "        #if torch.equal(resid_post, ans): print(\"pass 3\")\n",
        "        return ans\n",
        "\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEmS2nRA7Jzv"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwk07WzJ7Jzv",
        "outputId": "d400e99c-f99f-4647-f847-7c6cf61706ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7011,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7750, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from binascii import b2a_uu\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        ans = einsum(\"b p d, d d_v -> b p d_v\", normalized_resid_final, self.W_U)+self.b_U\n",
        "        return ans\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmkKmv827Jzv"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVJzGZR47Jzv",
        "outputId": "3e416727-d2e5-40f4-d6ca-03eb4a01b94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "tensor([[783, 323, 919, 769],\n",
            "        [239, 992, 386, 879]], device='cuda:0')\n",
            "torch.Size([2, 4])\n",
            "torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]], device='cuda:0')\n",
            "torch.Size([1, 35])\n",
            "torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
              "           -42.3644],\n",
              "         [-128.0382, -127.9926, -130.7000,  ..., -136.7109, -129.9250,\n",
              "          -129.3953],\n",
              "         [-119.8520, -121.0063, -123.8819,  ..., -128.5178, -126.6025,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9806, -112.7740, -117.0623,  ..., -121.2902, -117.6562,\n",
              "          -114.4995],\n",
              "         [ -98.6731, -104.4896, -108.7366,  ..., -118.3556, -113.8770,\n",
              "          -106.3610],\n",
              "         [-126.8277, -128.9589, -128.3934,  ..., -140.1959, -138.5870,\n",
              "          -122.3691]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "\n",
        "        pos_embedded_tokens = self.pos_embed(tokens) + self.embed(tokens)\n",
        "        transformed = pos_embedded_tokens\n",
        "        for block in self.blocks:\n",
        "            transformed = block(transformed)\n",
        "        #transformed = self.blocks(pos_embedded_tokens)\n",
        "        norm_transformed = self.ln_final(transformed)\n",
        "        return self.unembed(norm_transformed)\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaae00RV7Jzv"
      },
      "source": [
        "# Try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGce2H-17Jzv",
        "outputId": "1aca42e1-b048-422d-d019-8170c2cc0670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "demo_gpt2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwQl6xGQ7Jzw"
      },
      "source": [
        "Take a test string - the intro paragraph of today's featured Wikipedia article. Let's calculate the loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYE8atCU7Jzw"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Mini scule is a species of microhylid frog endemic to Madagascar that was described in 2019. The scientific name of the species refers to its size, being a pun on the word minuscule. It is very small, measuring only 8.4 to 10.8 mm (0.33 to 0.43 in) in snout–vent length. It has bronze underparts with a brown groin and back of the thigh, cream upperparts with brown flecking, a dark brown side of the head, and a red iris. On the hind feet, the first toe is absent and the second and fifth toes are strongly reduced. The frog is known only from the Sainte Luce Reserve, where it inhabits areas with deep leaf litter near semi-permanent water bodies. Specimens of frogs from Mandena, the Vohimena mountains, the southern Anosy Mountains, and Tsitongambarika may also be of this species. Along with Mini mum and Mini ature, the other two species in its genus, it received media attention when first described due to the wordplay in its scientific name. (Full article...)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eopwqBN7Jzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640e886d-49d1-4b97-bff1-5224713aa7e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 39234,   629,  2261,   318,   257,  4693,   286,  4580,    71,\n",
            "          2645,   312, 21264, 42560,   284, 46694,   326,   373,  3417,   287,\n",
            "         13130,    13,   383,  5654,  1438,   286,   262,  4693, 10229,   284,\n",
            "           663,  2546,    11,   852,   257,  4000,   319,   262,  1573,   949,\n",
            "         16241,  2261,    13,   632,   318,   845,  1402,    11, 15964,   691,\n",
            "           807,    13,    19,   284,   838,    13,    23,  8085,   357,    15,\n",
            "            13,  2091,   284,   657,    13,  3559,   287,     8,   287,  3013,\n",
            "           448,  1906,  1151,  4129,    13,   632,   468, 22101,   739, 42632,\n",
            "           351,   257,  7586, 42247,   290,   736,   286,   262, 19341,    11,\n",
            "          8566,  6727, 42632,   351,  7586,  5104, 44377,    11,   257,  3223,\n",
            "          7586,  1735,   286,   262,  1182,    11,   290,   257,  2266,  4173,\n",
            "           271,    13,  1550,   262, 16222,  3625,    11,   262,   717, 21189,\n",
            "           318, 13717,   290,   262,  1218,   290,  8150, 23932,   389,  7634,\n",
            "          5322,    13,   383, 21264,   318,  1900,   691,   422,   262,   311,\n",
            "           391,   660,  6026,   344, 12224,    11,   810,   340, 11381,   896,\n",
            "          3006,   351,  2769, 12835, 25359,  1474, 10663,    12,   525, 44172,\n",
            "          1660,  5920,    13, 18291, 12117,   286, 37475,   422, 13314,  8107,\n",
            "            11,   262,   569,  1219,   320,  8107, 12269,    11,   262,  8372,\n",
            "          1052,   418,    88, 21124,    11,   290, 13146,   270,   506,  4131,\n",
            "           283,  9232,   743,   635,   307,   286,   428,  4693,    13, 17159,\n",
            "           351, 12558, 25682,   290, 12558,   379,   495,    11,   262,   584,\n",
            "           734,  4693,   287,   663, 34306,    11,   340,  2722,  2056,  3241,\n",
            "           618,   717,  3417,  2233,   284,   262,  1573,  1759,   287,   663,\n",
            "          5654,  1438,    13,   357, 13295,  2708, 23029]], device='cuda:0')\n",
            "torch.Size([1, 237])\n",
            "torch.Size([1, 237, 768])\n"
          ]
        }
      ],
      "source": [
        "test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "demo_logits = demo_gpt2(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u516qFDo7Jzw",
        "outputId": "ed265fc0-946d-40fb-f82f-fa8f3d95a42a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.7187, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(41.2088, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Measure next token loss\n",
        "    # Logits have shape [batch, position, d_vocab]\n",
        "    # Tokens have shape [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob\", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWSFrrAG7Jzw"
      },
      "source": [
        "We can also greedily generate text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puxIsZpS7Jzw",
        "outputId": "7494b9a0-fa9c-438e-9d09-f47576a2a6e2",
        "colab": {
          "referenced_widgets": [
            "9923328fb94543dfa84e74e74d9deeb3",
            "30bb7c1e945f46bb853190c5246284f6",
            "5065866f0a0a4b7fbbd654786b7bc589",
            "62b5b2758f624b6e93b126baf95bdf1b",
            "a3e1eaa2a8304815bbc4566be63446a5",
            "6d614ef7fac44d6190061515f54beb34",
            "a2cdd9fe080445bc889174b8b030663e",
            "980baaacbcbf4c0bb28a8728e331eb5a",
            "530eb000fef64444a7a5ace0fcdd8f40",
            "a20d91b872e746dc98a17f0c2618a415",
            "73b57cebf7ce42069376f773a3e55c2a"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9923328fb94543dfa84e74e74d9deeb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319]], device='cuda:0')\n",
            "torch.Size([1, 105])\n",
            "torch.Size([1, 105, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321]], device='cuda:0')\n",
            "torch.Size([1, 106])\n",
            "torch.Size([1, 106, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13]], device='cuda:0')\n",
            "torch.Size([1, 107])\n",
            "torch.Size([1, 107, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   198]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 108])\n",
            "torch.Size([1, 108, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 108])\n",
            "torch.Size([1, 108, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 109])\n",
            "torch.Size([1, 109, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 110])\n",
            "torch.Size([1, 110, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097]], device='cuda:0')\n",
            "torch.Size([1, 111])\n",
            "torch.Size([1, 111, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286]], device='cuda:0')\n",
            "torch.Size([1, 112])\n",
            "torch.Size([1, 112, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132]], device='cuda:0')\n",
            "torch.Size([1, 113])\n",
            "torch.Size([1, 113, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318]], device='cuda:0')\n",
            "torch.Size([1, 114])\n",
            "torch.Size([1, 114, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938]], device='cuda:0')\n",
            "torch.Size([1, 115])\n",
            "torch.Size([1, 115, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284]], device='cuda:0')\n",
            "torch.Size([1, 116])\n",
            "torch.Size([1, 116, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015]], device='cuda:0')\n",
            "torch.Size([1, 117])\n",
            "torch.Size([1, 117, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 118])\n",
            "torch.Size([1, 118, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 119])\n",
            "torch.Size([1, 119, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 120])\n",
            "torch.Size([1, 120, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286]], device='cuda:0')\n",
            "torch.Size([1, 121])\n",
            "torch.Size([1, 121, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992]], device='cuda:0')\n",
            "torch.Size([1, 122])\n",
            "torch.Size([1, 122, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301]], device='cuda:0')\n",
            "torch.Size([1, 123])\n",
            "torch.Size([1, 123, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319]], device='cuda:0')\n",
            "torch.Size([1, 124])\n",
            "torch.Size([1, 124, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431]], device='cuda:0')\n",
            "torch.Size([1, 125])\n",
            "torch.Size([1, 125, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13]], device='cuda:0')\n",
            "torch.Size([1, 126])\n",
            "torch.Size([1, 126, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   198]], device='cuda:0')\n",
            "torch.Size([1, 127])\n",
            "torch.Size([1, 127, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628]], device='cuda:0')\n",
            "torch.Size([1, 127])\n",
            "torch.Size([1, 127, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 128])\n",
            "torch.Size([1, 128, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 129])\n",
            "torch.Size([1, 129, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 130])\n",
            "torch.Size([1, 130, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286]], device='cuda:0')\n",
            "torch.Size([1, 131])\n",
            "torch.Size([1, 131, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132]], device='cuda:0')\n",
            "torch.Size([1, 132])\n",
            "torch.Size([1, 132, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318]], device='cuda:0')\n",
            "torch.Size([1, 133])\n",
            "torch.Size([1, 133, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938]], device='cuda:0')\n",
            "torch.Size([1, 134])\n",
            "torch.Size([1, 134, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284]], device='cuda:0')\n",
            "torch.Size([1, 135])\n",
            "torch.Size([1, 135, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015]], device='cuda:0')\n",
            "torch.Size([1, 136])\n",
            "torch.Size([1, 136, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319]], device='cuda:0')\n",
            "torch.Size([1, 137])\n",
            "torch.Size([1, 137, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 138])\n",
            "torch.Size([1, 138, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 139])\n",
            "torch.Size([1, 139, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 140])\n",
            "torch.Size([1, 140, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992]], device='cuda:0')\n",
            "torch.Size([1, 141])\n",
            "torch.Size([1, 141, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301]], device='cuda:0')\n",
            "torch.Size([1, 142])\n",
            "torch.Size([1, 142, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319]], device='cuda:0')\n",
            "torch.Size([1, 143])\n",
            "torch.Size([1, 143, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431]], device='cuda:0')\n",
            "torch.Size([1, 144])\n",
            "torch.Size([1, 144, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13]], device='cuda:0')\n",
            "torch.Size([1, 145])\n",
            "torch.Size([1, 145, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   198]], device='cuda:0')\n",
            "torch.Size([1, 146])\n",
            "torch.Size([1, 146, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628]], device='cuda:0')\n",
            "torch.Size([1, 146])\n",
            "torch.Size([1, 146, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198]], device='cuda:0')\n",
            "torch.Size([1, 147])\n",
            "torch.Size([1, 147, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 148])\n",
            "torch.Size([1, 148, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 149])\n",
            "torch.Size([1, 149, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 150])\n",
            "torch.Size([1, 150, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938]], device='cuda:0')\n",
            "torch.Size([1, 151])\n",
            "torch.Size([1, 151, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284]], device='cuda:0')\n",
            "torch.Size([1, 152])\n",
            "torch.Size([1, 152, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221]], device='cuda:0')\n",
            "torch.Size([1, 153])\n",
            "torch.Size([1, 153, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262]], device='cuda:0')\n",
            "torch.Size([1, 154])\n",
            "torch.Size([1, 154, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473]], device='cuda:0')\n",
            "torch.Size([1, 155])\n",
            "torch.Size([1, 155, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319]], device='cuda:0')\n",
            "torch.Size([1, 156])\n",
            "torch.Size([1, 156, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321]], device='cuda:0')\n",
            "torch.Size([1, 157])\n",
            "torch.Size([1, 157, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 158])\n",
            "torch.Size([1, 158, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 159])\n",
            "torch.Size([1, 159, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 160])\n",
            "torch.Size([1, 160, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464]], device='cuda:0')\n",
            "torch.Size([1, 161])\n",
            "torch.Size([1, 161, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097]], device='cuda:0')\n",
            "torch.Size([1, 162])\n",
            "torch.Size([1, 162, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286]], device='cuda:0')\n",
            "torch.Size([1, 163])\n",
            "torch.Size([1, 163, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132]], device='cuda:0')\n",
            "torch.Size([1, 164])\n",
            "torch.Size([1, 164, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318]], device='cuda:0')\n",
            "torch.Size([1, 165])\n",
            "torch.Size([1, 165, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938]], device='cuda:0')\n",
            "torch.Size([1, 166])\n",
            "torch.Size([1, 166, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284]], device='cuda:0')\n",
            "torch.Size([1, 167])\n",
            "torch.Size([1, 167, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 168])\n",
            "torch.Size([1, 168, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 169])\n",
            "torch.Size([1, 169, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 170])\n",
            "torch.Size([1, 170, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258]], device='cuda:0')\n",
            "torch.Size([1, 171])\n",
            "torch.Size([1, 171, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286]], device='cuda:0')\n",
            "torch.Size([1, 172])\n",
            "torch.Size([1, 172, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992]], device='cuda:0')\n",
            "torch.Size([1, 173])\n",
            "torch.Size([1, 173, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301]], device='cuda:0')\n",
            "torch.Size([1, 174])\n",
            "torch.Size([1, 174, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319]], device='cuda:0')\n",
            "torch.Size([1, 175])\n",
            "torch.Size([1, 175, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431]], device='cuda:0')\n",
            "torch.Size([1, 176])\n",
            "torch.Size([1, 176, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13]], device='cuda:0')\n",
            "torch.Size([1, 177])\n",
            "torch.Size([1, 177, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 178])\n",
            "torch.Size([1, 178, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 179])\n",
            "torch.Size([1, 179, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 180])\n",
            "torch.Size([1, 180, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845]], device='cuda:0')\n",
            "torch.Size([1, 181])\n",
            "torch.Size([1, 181, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318]], device='cuda:0')\n",
            "torch.Size([1, 182])\n",
            "torch.Size([1, 182, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938]], device='cuda:0')\n",
            "torch.Size([1, 183])\n",
            "torch.Size([1, 183, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284]], device='cuda:0')\n",
            "torch.Size([1, 184])\n",
            "torch.Size([1, 184, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221]], device='cuda:0')\n",
            "torch.Size([1, 185])\n",
            "torch.Size([1, 185, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262]], device='cuda:0')\n",
            "torch.Size([1, 186])\n",
            "torch.Size([1, 186, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473]], device='cuda:0')\n",
            "torch.Size([1, 187])\n",
            "torch.Size([1, 187, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 188])\n",
            "torch.Size([1, 188, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 189])\n",
            "torch.Size([1, 189, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 190])\n",
            "torch.Size([1, 190, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628]], device='cuda:0')\n",
            "torch.Size([1, 191])\n",
            "torch.Size([1, 191, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198]], device='cuda:0')\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464]], device='cuda:0')\n",
            "torch.Size([1, 193])\n",
            "torch.Size([1, 193, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097]], device='cuda:0')\n",
            "torch.Size([1, 194])\n",
            "torch.Size([1, 194, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286]], device='cuda:0')\n",
            "torch.Size([1, 195])\n",
            "torch.Size([1, 195, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132]], device='cuda:0')\n",
            "torch.Size([1, 196])\n",
            "torch.Size([1, 196, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132,   318]], device='cuda:0')\n",
            "torch.Size([1, 197])\n",
            "torch.Size([1, 197, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132,   318,  2938]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 198])\n",
            "torch.Size([1, 198, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132,   318,  2938,   284]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 199])\n",
            "torch.Size([1, 199, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132,   318,  2938,   284,  3015]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 200])\n",
            "torch.Size([1, 200, 768])\n",
            "tensor([[50256, 29449,  3000,    25,  1992,  1301,   468,   587, 18516,  2317,\n",
            "           416,   262,  2097,   286, 17132,   329,  5076,   286,  1176,   290,\n",
            "         28118,   286,  3162,    13,   383,  3015,   373, 18395,   284, 29903,\n",
            "            11,   351,   838,  4734,  9679,   477,  4956,   287,  6709,   284,\n",
            "         18516,   620,    13,   383,  1893,   318,   783,   691,   262,  2368,\n",
            "           287,  1605,  2106,   284,   307, 18516,  2317,    11,   290,   262,\n",
            "           717,   284,   307, 18516,  2317,  5403,    13,   383,  2097,   481,\n",
            "           783,  3758,   262,  6685,   286, 30258,   284,   262,  3845,    11,\n",
            "           810,   257,  4473,   481,   307,  2714,   284,  5004,  1771,   284,\n",
            "          4781,   262,  1893,   422,  2607,    13,   383,  3845,   318,  2938,\n",
            "           284,  2221,   262,  4473,   319,  3321,    13,   628,   198,   464,\n",
            "          2097,   286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,\n",
            "           286,  1992,  1301,   319,  3431,    13,   628,   198,   464,  2097,\n",
            "           286, 17132,   318,  2938,   284,  3015,   319,   262, 30258,   286,\n",
            "          1992,  1301,   319,  3431,    13,   628,   198,   464,  3845,   318,\n",
            "          2938,   284,  2221,   262,  4473,   319,  3321,    13,   628,   198,\n",
            "           464,  2097,   286, 17132,   318,  2938,   284,  3015,   319,   262,\n",
            "         30258,   286,  1992,  1301,   319,  3431,    13,   628,   198,   464,\n",
            "          3845,   318,  2938,   284,  2221,   262,  4473,   319,  3321,    13,\n",
            "           628,   198,   464,  2097,   286, 17132,   318,  2938,   284,  3015,\n",
            "           319]], device='cuda:0')\n",
            "torch.Size([1, 201])\n",
            "torch.Size([1, 201, 768])\n",
            "Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the\n"
          ]
        }
      ],
      "source": [
        "test_string = \"Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on\"\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ftSWwW7Jzw"
      },
      "source": [
        "# Training a Model!\n",
        "\n",
        "This is a lightweight demonstration of how you can actually train your own GPT-2 with this code! Here we train a tiny model on a tiny dataset, but it's fundamentally the same code for training a larger/more real model (though you'll need beefier GPUs and data parallelism to do it remotely efficiently, and fancier parallelism for much bigger ones).\n",
        "\n",
        "For our purposes, we'll train 2L 4 heads per layer model, with context length 256, for 1000 steps of batch size 8, just to show what it looks like (and so the notebook doesn't melt your colab lol)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LunEcpBb7Jzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc37fb23-bc8c-4d3d-864d-6a20d57520e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    %pip install datasets\n",
        "    %pip install transformers\n",
        "import datasets\n",
        "import transformers\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5V5oXoj7Jzw"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLhtR-8u7Jzw"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "num_epochs = 1\n",
        "max_steps = 1000\n",
        "log_every = 10\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-2\n",
        "model_cfg = Config(debug=False, d_model=256, n_heads=4, d_head=64, d_mlp=1024, n_layers=2, n_ctx=256, d_vocab=reference_gpt2.cfg.d_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50HaPaRk7Jzx"
      },
      "source": [
        "\n",
        "## Create Data\n",
        "\n",
        "We load in a tiny dataset I made, with the first 10K entries in the Pile (inspired by Stas' version for OpenWebText!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAVenZ547Jzx",
        "outputId": "3e701e63-94b2-4963-fed2-e01ac109e8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "a100131cd0ff4eb594f019bc64731897",
            "8df534a71d4a45e3ac4cdbabc7216161",
            "9ee36679a49c49ecb71adb137b09a5f2",
            "3e0beb0637db4fc2a13bd56fefc1c18a",
            "d9a2b96c4d56494393e7afee8f2dd903",
            "4760e3d486204495a6d880043e7e038c",
            "1ab76bdf66c54fc18d127855e192b88d",
            "62faa33ab67846308000c578f0bed0b0",
            "b14439f9f66f4866b64d6ef0e9e9f9e7",
            "4bc999af42e34ff5bceb95fcf005d122",
            "1d22a3e662fd45e7861526fc590d55ac",
            "db1215247d6549708f5882a8e3e0e06b",
            "a6705ae3aba84ef0a4be3d2af71b76fe",
            "7cec327169d5459ba34c51ec9be96958",
            "b5be4aa6309144a9bee4c3b097a651b0",
            "d213fca3d962414398363b8d80302de2",
            "f1a270754e3546e0984b45318cd21e68",
            "452c61deeca44e8fa8bca082e21228d1",
            "9b5e387680b64eec8ee11dc041187636",
            "7c458efe2eff4d76befbcae0d37edcae",
            "6df4066eb1e540a2a3f1d7d2cd8048d5",
            "8d752366d6cd4eb6b30fe924c87740a6",
            "3803cfba463142bebb7441dffdaa2806",
            "0f748dc13e89464a88012a1982ddc431",
            "70982a3c2bc0419e8c9bee58d5b473d5",
            "e4a3d98fb49447e6b0c3ecd6fbb07c23",
            "80b5a4ef3ab848a1a9a8bc4a5cdd2d3f",
            "d0f1a09199f24f3491380a7a8009796c",
            "67736dc2643641fe926a3ef2b4c05cbe",
            "6a10f7ed9f0e48538655181c7147527c",
            "3e31bfabdbb941e89d29de305e8b5637",
            "926839e4b4874bbe85af07bf388f5c51",
            "5a8a3d5f19fe43c1967d273099ab8a91",
            "0e6ed4d42f37411fae03083593d989d5",
            "9644eff4a8f34e12b119e7b331dad4e9",
            "afc49a7d6c0543b1b89ea5278e53be10",
            "d79e20b348be48a29ef82e3b9c695c4a",
            "ed19cdc8239647dfafa7c8e8ce2e32b3",
            "15bed864ded34a17af5ad12b1ee4c4ff",
            "e96fca33515f44f497e8c75f5ccf1264",
            "cb19b8f159e0426aa8db16907218dfd3",
            "1b1ca04e4aa4408380be2a9590de237b",
            "0d9d77493f234160a7f8e73806172261",
            "009f88400ad540d5930ae175cf2c8108",
            "86ce34e018dc41daa7d129623f525ecb",
            "e4d007e00d5a4c3f9a36eb739534be4e",
            "e5024993af2144d0a9fa68259c5ecbdb",
            "f0a86f3b41c64bc380c7920efea263c3",
            "21b7fde6a0d14c5aa578a864ac7e5b71",
            "64b87a1d181749488af9eb23f46024fe",
            "760b4881e36c463f911beb6769ee6588",
            "979b55d6ba1c41e8a7e2cecb49a0fd14",
            "6a04c000acd94b57be04f67a5b26965a",
            "4e5412f556fa44d6910d174c8e2584b9",
            "0a8298c3b7114facb717e483b5d2990c",
            "a9b839666962421fbc05fc3c725efcc5",
            "4f6a45cb311f47c4a1c33872f84f2184",
            "5cb1e7ab42ad47a3ba176697c6e22a9d",
            "928fd5fb25a14c3680c10673800c8e07",
            "733860a1dac84b0da259257dda9d930e",
            "03d6026014544469b5d0bcf87df18e90",
            "9c2334857ac6459796ba973e006a4780",
            "9124343056a54a2e9df1e2791731c211",
            "daa3ab2f405640d3beff9b3c99a47151",
            "af85fa56cbaf40ab81281b1e65adac7f",
            "156968a3a726473f87b578cd95e92e9a",
            "89aa711acba34ad29ea3b76445be0eec",
            "e9f6c36bb0cf42738d4c68330040793c",
            "d3c7a665864245eabea0940f29d1109b",
            "c7098c24e0504908b3c7baa0f55207ce",
            "18e2b180f6714da487dd351d56ec6a9e",
            "18b8a262ce52446b90b86e4d2c652a29",
            "c317547da3f347229884b8468ab59879",
            "9daf7d7cf3744c07a6f64bc4b8b0db6f",
            "23c0ec9c27434a54b05dadb9c38abc31",
            "ebdfb6b9614647e2bc235b209b57e488",
            "7dc2ecb44a5d4e86bd2d7b4ba245dc85"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a100131cd0ff4eb594f019bc64731897"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db1215247d6549708f5882a8e3e0e06b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset None/None (download: 31.72 MiB, generated: 58.43 MiB, post-processed: Unknown size, total: 90.15 MiB) to /root/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3803cfba463142bebb7441dffdaa2806"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e6ed4d42f37411fae03083593d989d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86ce34e018dc41daa7d129623f525ecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9b839666962421fbc05fc3c725efcc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
            "Dataset({\n",
            "    features: ['text', 'meta'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89aa711acba34ad29ea3b76445be0eec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (80023 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (101051 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (155995 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
        "print(dataset)\n",
        "print(dataset[0]['text'][:100])\n",
        "tokens_dataset = tokenize_and_concatenate(dataset, reference_gpt2.tokenizer, streaming=False, max_length=model_cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
        "data_loader = torch.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3guwbwn7Jzx"
      },
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJbZYoRE7Jzx",
        "outputId": "844bbea3-956f-40b6-d9dd-8c3f8ea9c4d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0-1): 2 x TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "model = DemoTransformer(model_cfg)\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg8wNaxd7Jzx"
      },
      "source": [
        "## Create Optimizer\n",
        "We use AdamW - it's a pretty standard optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dsJp6No7Jzx"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L94lCHIU7Jzx"
      },
      "source": [
        "## Run Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMTsU4CT7Jzx",
        "outputId": "ba934126-4d59-4cba-cf6f-a37ef17c3a82",
        "colab": {
          "referenced_widgets": [
            "af870668ef7d4c94abcdc65087917741",
            "fe0ce69f38c44cb5964bd00b2b0ebbda",
            "652ba460eebb4f77b2791d7e5f9b44c0",
            "d814d827344541988d08ff013b23e816",
            "9b6c3e466e8b448fb084a0c4977f96f3",
            "d0df624074bc465db646d8b00aa3a8c3",
            "9579ac7250654b81a2410db981559492",
            "70e27fc7ec674b7f96528974d8c3f45f",
            "82b149c803d741f0a15e55036e441068",
            "3a0b6caf8cdb45858adfbca54605510b",
            "76b556a7f2ca4f77b556e7801385c933"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches: 8506\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af870668ef7d4c94abcdc65087917741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [50256,  4689,  1658,  ...,  4533,   401,    78],\n",
            "        [50256, 13557, 18224,  ...,   357,  5661,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14240,   905,  ..., 16134,   319,  7489],\n",
            "        [50256,   198,     7,  ...,   618,  8215,   389],\n",
            "        [50256, 24682,    72,  ...,   379,   262, 32339],\n",
            "        ...,\n",
            "        [50256,  7723,   290,  ...,  4029,   256,  2899],\n",
            "        [50256,  1690,  1760,  ...,  3763,    11,   484],\n",
            "        [50256,   685,    31,  ...,  7003, 21919,  4890]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   329,  5252,  ...,    25,   198,   198],\n",
            "        [50256,  1043,   284,  ...,  8739,  1912,   319],\n",
            "        [50256,   220,   220,  ...,  6599,    19,     8],\n",
            "        ...,\n",
            "        [50256,  9419,    37,  ...,  1114,   749,  4959],\n",
            "        [50256,    87,    62,  ...,    87,  2162,    80],\n",
            "        [50256,   717,  2067,  ...,   523,   881,   526]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2031,   318,  ...,  4381,   326,  7095],\n",
            "        [50256,   338, 22645,  ...,   416, 17826,    11],\n",
            "        [50256,  2420,    62,  ...,  1828,    13,  1065],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ..., 10778,   220,   220],\n",
            "        [50256,    93,    11,  ..., 32353,   415,   373],\n",
            "        [50256, 13769,   257,  ...,   262, 10816,  9912]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   329,   262,  ...,   766,   262,   661],\n",
            "        [50256, 15193,   220,  ...,    13,   220, 24550],\n",
            "        [50256,   352,   457,  ...,  1222, 13655,    26],\n",
            "        ...,\n",
            "        [50256, 13412,  3617,  ...,    62,   853,    62],\n",
            "        [50256,  1686,   441,  ...,   351,   663, 17670],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  2724,  ...,    19,    50,   293],\n",
            "        [50256,   290,   376,  ...,  1440,  1450,    11],\n",
            "        [50256,  6097,    13,  ...,    12,    23, 22710],\n",
            "        ...,\n",
            "        [50256, 50044,    12,  ...,    11,  8148,    11],\n",
            "        [50256,   198, 32069,  ...,  4394,    11,  2592],\n",
            "        [50256, 20249,    11,  ...,   526,  1776,  8460]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 40829, 28014,  ...,  9419,  2623,    60],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    17,   198,  ...,   262,  2368,  2835],\n",
            "        ...,\n",
            "        [50256,  3108,   823,  ...,   554,   371,    13],\n",
            "        [50256,   416,   262,  ..., 47253,   628,   220],\n",
            "        [50256,   878,    11,  ...,  1622,   351,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   241,   464,  ...,   263, 21079,  2241],\n",
            "        [50256,   262,  6678,  ...,  4554,    13,  2617],\n",
            "        [50256,   198, 19351,  ..., 19180, 11927, 15879],\n",
            "        ...,\n",
            "        [50256,  7758, 10671,  ...,   276,   334,    67],\n",
            "        [50256,  1073,  5853,  ...,  4188,   393, 12075],\n",
            "        [50256,   350,  5791,  ..., 31279,   470,  2652]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7229,   373,  ..., 30109,    31,    49],\n",
            "        [50256,   447,   247,  ...,    13,   198,   198],\n",
            "        [50256,  9574,    13,  ...,    83,  7944,    82],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ..., 10305,   393, 14340],\n",
            "        [50256,     8,     3,  ...,    59,    71,  3524],\n",
            "        [50256,    13,   314,  ...,  3612,   284, 10303]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 460, Loss: 5.7134\n",
            "tensor([[50256, 18849, 16843,  ...,   110, 21727, 16843],\n",
            "        [50256,   220,   220,  ..., 17752,  3712,  8906],\n",
            "        [50256,   326,   423,  ...,   345,  1053,  1100],\n",
            "        ...,\n",
            "        [50256,   259,  4288,  ..., 27344,   418,    88],\n",
            "        [50256,   198,   220,  ...,  6624, 34534, 48082],\n",
            "        [50256,   220,   220,  ...,   366, 12957,    62]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    72, 38325,  ...,  2877,   287, 32526],\n",
            "        [50256,  9228, 11312,  ...,  1525,    12,  1169],\n",
            "        [50256,  1238,   220,  ...,    25,   198,   198],\n",
            "        ...,\n",
            "        [50256,  5626,   530,  ...,   198,  3347,   550],\n",
            "        [50256,   467, 13251,  ...,   351,   257, 12314],\n",
            "        [50256,   286,   340,  ...,    11,  2446,  1146]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    89, 23330,  ...,    92, 13702,   290],\n",
            "        [50256,   374,   907,  ...,   220,   220,   720],\n",
            "        [50256,    49, 10234,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   397, 13415,  ..., 10866,   618,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 30751,    13,  ...,    62,  1324, 12360],\n",
            "        [50256,   900,   510,  ...,  2440,  1393,  2494],\n",
            "        [50256,    11,  2813,  ...,  3052,   550,   257],\n",
            "        ...,\n",
            "        [50256,    11,   262,  ...,  1466,   290, 39320],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2800,   514,  ...,  1378,  2503,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,  1279,  ...,   220,   220,   220],\n",
            "        [50256,  1507,    13,  ...,  8511,   321,   468],\n",
            "        [50256, 28710,    62,  ...,   220,  5045, 27823],\n",
            "        ...,\n",
            "        [50256,  1892,   540,  ...,   547,   407,  1944],\n",
            "        [50256,   128,   108,  ..., 28560,    13, 48365],\n",
            "        [50256,   284,  3092,  ...,  2625,  5647, 25719]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    69, 10557,  ...,  2293, 18139,  4321],\n",
            "        [50256,  2561, 19712,  ...,  1040,  9268,    11],\n",
            "        [50256,    14, 10374,  ...,  2990,   389,   973],\n",
            "        ...,\n",
            "        [50256,  1440, 20283,  ...,  2776,   284,   257],\n",
            "        [50256,   379,   262,  ...,  1661,   351,   309],\n",
            "        [50256,  9449,   286,  ...,  6731,   290,   670]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    82,  3249,  ...,   314,   900,   314],\n",
            "        [50256, 34074, 19972,  ...,  2302,  5736,  1330],\n",
            "        [50256,   364,   326,  ...,   780,   484,   760],\n",
            "        ...,\n",
            "        [50256,     2,    37,  ...,   362,    33, 16151],\n",
            "        [50256,     8,   198,  ...,   198,    32, 12429],\n",
            "        [50256,   717,  8060,  ...,   262,   995,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   319,  5387,  ...,  2472,   954,   286],\n",
            "        [50256,    25,  5219,  ...,    12,  1941, 11162],\n",
            "        [50256,  3431,   481,  ...,   617,   649,  1808],\n",
            "        ...,\n",
            "        [50256, 16566,   351,  ...,   284,   467,   651],\n",
            "        [50256,   470,   326,  ...,   262,  1633,    13],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 17802,   284,  ...,     7,   198,   220],\n",
            "        [50256,  3142,   329,  ...,   423,   198,   220],\n",
            "        [50256,   584,   796,  ...,    82,   737,   314],\n",
            "        ...,\n",
            "        [50256,   250,   464,  ...,   836,   447,   247],\n",
            "        [50256,   461, 35560,  ...,   318, 13294,  1252],\n",
            "        [50256,   683,   290,  ...,  5216, 26261, 40837]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,     8,   284,  ...,   220,   289,  6357],\n",
            "        [50256,   466,   340,  ...,  6655,   611,   339],\n",
            "        [50256,   257,  3518,  ...,   318,   257, 10356],\n",
            "        ...,\n",
            "        [50256,    11,   612,  ...,  4432,    64,  7381],\n",
            "        [50256,   532,    18,  ...,  2124,   796,   532],\n",
            "        [50256,    11, 19613,  ...,     8,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 470, Loss: 6.4383\n",
            "tensor([[50256,   393, 48152,  ..., 47455,   351,   257],\n",
            "        [50256,  4621,   286,  ...,   220,   220,   220],\n",
            "        [50256,   261,    11,  ...,   449,    13,    50],\n",
            "        ...,\n",
            "        [50256,     7,    13,  ..., 27208,  1609,    75],\n",
            "        [50256,  4473,  2184,  ..., 18506,   329,   777],\n",
            "        [50256,    12, 23922,  ...,   338,  4939,    12]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 27571,   284,  ..., 24751,   286,  5871],\n",
            "        [50256,   197, 13912,  ...,  9218,    11, 45144],\n",
            "        [50256,   281,  2223,  ...,   780,   484,   460],\n",
            "        ...,\n",
            "        [50256,  3837, 30102,  ...,  1198,  1058,  4064],\n",
            "        [50256,  3344,    13,  ...,   290,   416,  4395],\n",
            "        [50256,  7942,     1,  ...,    12,    75,    70]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   319,   339,  ..., 23737,  1877,   736],\n",
            "        [50256,  5202, 20431,  ...,   262, 11812,  7822],\n",
            "        [50256,   389,   355,  ...,  6494,    13,  4246],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  1141,   262,  1175],\n",
            "        [50256,    13, 16263,  ...,  1462,  3465,   326],\n",
            "        [50256, 36796,     7,  ..., 30420, 14656,    44]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6290,   750,  ...,    11, 18959,   470],\n",
            "        [50256,  5756,   264,  ...,  1218, 27255,   286],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   260,  2391,  ...,  2756,  2496,   286],\n",
            "        [50256,   198,    32,  ...,  1110,    13,  8227],\n",
            "        [50256,    33,  2598,  ...,   341, 12737, 10759]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   264,     9,  ..., 32590,  1065, 19427],\n",
            "        [50256,   356,   547,  ...,   743,   307, 14702],\n",
            "        [50256,    38,     7,  ...,  1676,    67, 23330],\n",
            "        ...,\n",
            "        [50256,     8,   290,  ...,  1238,    12,  1828],\n",
            "        [50256,  4504,   351,  ...,   867,  3625,   287],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198, 22133,  ...,  2383,  3315,  7476],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   521,  2302,  ...,   220,   220, 10330],\n",
            "        ...,\n",
            "        [50256, 18480,  2700,  ..., 35944, 17635,    90],\n",
            "        [50256, 25142,   257,  ..., 22073, 28451,    37],\n",
            "        [50256,    11,   262,  ...,  3467, 30109,    31]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   350,     7,  ...,   362,    11,   513],\n",
            "        [50256,   543,   661,  ...,   460, 33695,  4474],\n",
            "        [50256,     8,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  3583,   546,  ...,   447,   247,    82],\n",
            "        [50256, 17909,   737,  ..., 14506,  1359,  4325],\n",
            "        [50256,  1148, 21950,  ..., 17062,  9783,   201]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    26,   807,  ..., 26582,    11, 43610],\n",
            "        [50256,    15,    11,  ...,    70,    62,    17],\n",
            "        [50256,  8625,    62,  ..., 14269,  1438,  2625],\n",
            "        ...,\n",
            "        [50256,    58,    25,  ...,  4981,   287,  3446],\n",
            "        [50256,   547,   645,  ...,  1219,   396, 32864],\n",
            "        [50256,  5637,  1029,  ..., 25857,  2494, 39280]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    22,    11,  ...,    19,    59,  3256],\n",
            "        [50256,    13,  2079,  ...,   389,   262, 19794],\n",
            "        [50256,    33,   940,  ...,   460,  1085,   284],\n",
            "        ...,\n",
            "        [50256,  1114,  1672,  ...,    13,  2312,  9984],\n",
            "        [50256,    82,   329,  ...,  3667,   547,  4438],\n",
            "        [50256, 19922, 41358,  ..., 10391,   357, 40965]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   532, 25540,  ..., 17501,  1270,  5892],\n",
            "        [50256,  1176,  1141,  ...,   262,  1766,    12],\n",
            "        [50256,    13,   628,  ...,  6827, 10893,   815],\n",
            "        ...,\n",
            "        [50256,   262,  4252,  ...,  1439,   262,   835],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2162,   220,  ...,  6339,  1022,  3719]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 480, Loss: 5.8021\n",
            "tensor([[50256,   198,   198,  ...,    59, 16345, 23330],\n",
            "        [50256, 18971,  5454,  ...,  6508, 30560,  9493],\n",
            "        [50256,    54,  2389,  ...,  1961,     7,    50],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 35307, 11399,  ..., 39280, 14415, 35307],\n",
            "        [50256, 30816,   284,  ...,   423,  4054,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   444,    13,  ...,   284,  7373,   777],\n",
            "        [50256,    58,   400,  ...,  1370, 31478, 28015],\n",
            "        [50256, 11498, 21069,  ...,  4886,  7460,   326],\n",
            "        ...,\n",
            "        [50256, 25370,   122,  ..., 29090,    81, 25357],\n",
            "        [50256,   357,    35,  ..., 41253,    11,  7724],\n",
            "        [50256, 13705,    11,  ..., 38504, 27930,   318]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  5654,  ...,   262,  4856,   286],\n",
            "        [50256,   262,  1097,  ...,   376,   620,    26],\n",
            "        [50256,   220,   220,  ...,    26,   198,   329],\n",
            "        ...,\n",
            "        [50256,   481,   307,  ...,  6030,    28, 40492],\n",
            "        [50256,  6371,    82,  ...,   339,    83,   390],\n",
            "        [50256,  1504,    14,  ...,   286,  2975,  5983]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 19927,   220,  ...,  3620,    56,  7788],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   466,  1551,  ...,    11, 47603,    11],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,   198,  ...,    11,  8987,    11],\n",
            "        [50256,   247,    82,  ..., 16787,  5081,   326]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12, 11215,  ..., 10394,    28,  1911],\n",
            "        [50256,   423, 32382,  ..., 29992,  2361,    61],\n",
            "        [50256,    61,  7461,  ...,   743,  2987,   262],\n",
            "        ...,\n",
            "        [50256,   286,  1115,  ...,   389,  6241,  8384],\n",
            "        [50256,  1612,   319,  ...,   447,   247,    67],\n",
            "        [50256,     9,    64,  ..., 27493,    71,     9]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6601,     7,  ...,   198,   198, 46471],\n",
            "        [50256,    14,  4310,  ...,   511, 25000,   393],\n",
            "        [50256, 16764,   198,  ...,   405,    25,  1157],\n",
            "        ...,\n",
            "        [50256,   360,    11,  ...,   284,   262,  4511],\n",
            "        [50256,   262,  2126,  ...,   561,   910,    13],\n",
            "        [50256, 12765,   286,  ...,   198,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   324,  6548,  ...,    12,  7635,  4675],\n",
            "        [50256, 38508,   198,  ...,    13, 20763,   312],\n",
            "        [50256,  4169,  6184,  ...,  1062,   965,  1304],\n",
            "        ...,\n",
            "        [50256,  1299,   422,  ...,   345,    13, 10880],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,   198,  ...,  1157,  9114,   357]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    59,  4357,  ...,  2144, 18970,   516],\n",
            "        [50256,   220,   220,  ...,   105,    95, 32573],\n",
            "        [50256,   416,  1957,  ..., 45262,  7777,   287],\n",
            "        ...,\n",
            "        [50256, 40211,   313,  ..., 17080,    14, 16886],\n",
            "        [50256,  6674,   477,  ...,   526,   198,   198],\n",
            "        [50256,   198,   198,  ...,   198,   198, 14581]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 46678,     6,  ...,    11,   257, 33408],\n",
            "        [50256,  4983, 26033,  ...,   867,  7612,   553],\n",
            "        [50256,  4887,   284,  ..., 47751,   379,   262],\n",
            "        ...,\n",
            "        [50256,    11,   543,  ..., 29763,   590,   290],\n",
            "        [50256,    12, 30547,  ...,  1366,   389,   691],\n",
            "        [50256,   198, 15979,  ...,   796,   532,  1157]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    59,  1662,  ...,    59, 26591,  1782],\n",
            "        [50256,    38,  1099,  ...,   318,   262,  1306],\n",
            "        [50256,   307,   262,  ...,   347,  1371,   343],\n",
            "        ...,\n",
            "        [50256,   329,  4554,  ...,   198, 27007,    59],\n",
            "        [50256,  2159,  3000,  ...,  1315,    12, 11374],\n",
            "        [50256, 14402,     7,  ...,  9288,  7571, 36674]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 490, Loss: 5.9090\n",
            "tensor([[50256,   198, 15211,  ...,  1100,   262,  5964],\n",
            "        [50256,   290,   262,  ...,   532,  3467, 31944],\n",
            "        [50256,    11, 21738,  ...,    28, 47582, 32417],\n",
            "        ...,\n",
            "        [50256, 16151,     2,  ...,  5408,   286, 47354],\n",
            "        [50256,  7917, 11799,  ...,  1271,   286,  1353],\n",
            "        [50256,  1912,   319,  ...,   543,  3177,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1521,   407,  ...,  3751,  6991,   287],\n",
            "        [50256,   262,   968,  ...,   379,   257,  1568],\n",
            "        [50256,  3326,   439,  ..., 29943, 18042,  5674],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  1312,   796,   657],\n",
            "        [50256, 32329,    11,  ...,    12, 27979,    26],\n",
            "        [50256,     5,    33,  ...,  9410,  4248,  1065]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3656,    11,  ..., 10332,   444,     8],\n",
            "        [50256,   765,   606,  ...,  9408,   656, 24083],\n",
            "        [50256,  2695, 16294,  ...,   198,  1212,   318],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  3402,   287,  ..., 10871,   406,  8905],\n",
            "        [50256,  1205, 20411,  ...,    13,  2293,  3269]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   284,  ...,  3442,  2014,   198],\n",
            "        [50256,   318,  5969,  ...,    28,   447,   232],\n",
            "        [50256,  5841,  7483,  ..., 15341,   198,   220],\n",
            "        ...,\n",
            "        [50256,  3108,  6644,  ...,   357, 17394,     8],\n",
            "        [50256,   329,  2440,  ...,   262, 27254,    40],\n",
            "        [50256,   925,  2328,  ...,  8851,  6636,  1634]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    59,  4083,  ...,  1635,    34,    55],\n",
            "        [50256,   290, 25416,  ..., 35627,   290, 32198],\n",
            "        ...,\n",
            "        [50256, 36361,    82,  ..., 11808,  5861,   994],\n",
            "        [50256,   460, 13096,  ..., 21969,  2577,   801],\n",
            "        [50256,   517,   284,  ...,   447,   247,    82]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5878,    13,  ...,  5472,    13,   198],\n",
            "        [50256,  2666,  2263,  ...,   673,   373,   407],\n",
            "        [50256, 25922,   198,  ...,    50,  6981,  1797],\n",
            "        ...,\n",
            "        [50256,  1539, 47782,  ...,   329,  1811,  1933],\n",
            "        [50256,    13,  1024,  ...,   404,  5719,  2774],\n",
            "        [50256, 14792, 12429,  ...,  1141,   262,  3594]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6266,   286,  ...,  4419,    30,  1374],\n",
            "        [50256,  9162,    11,  ...,   955,  1443,  5982],\n",
            "        [50256,   220,   220,  ...,  2625, 15390,    13],\n",
            "        ...,\n",
            "        [50256,  1720,   286,  ...,    13,    23,  3695],\n",
            "        [50256,   532,   290,  ...,  6698,    13,   366],\n",
            "        [50256,   867,  3999,  ..., 43093,   262, 16846]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 17608,    13,  ...,  2119,   373, 12591],\n",
            "        [50256,   326,   428,  ...,   326,  5465,   502],\n",
            "        [50256,   286,  5242,  ...,  4796,  2732,  6853],\n",
            "        ...,\n",
            "        [50256,   462,  4908,  ...,  2078,    13,  1129],\n",
            "        [50256, 43277,   410,  ...,   220,   352,   198],\n",
            "        [50256,   447,   251,  ..., 16716, 22336,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   543, 10975,  ...,  1041, 28793,  2860],\n",
            "        [50256,   198,  2953,  ..., 11589,  3068,   617],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  1616,     3,  ...,  2611,  3467,   259],\n",
            "        [50256,   262,   350,  ...,  7771,   198,   198],\n",
            "        [50256,    23,    10,  ...,    62, 20867, 41907]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   314,   373,  ...,   355,   257,  1724],\n",
            "        [50256,    13,    34,  ...,   886,   510,   351],\n",
            "        [50256,   220,   220,  ...,   198,   220,   220],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,    92,  ...,  1462,   584, 19182],\n",
            "        [50256,  4188,  2802,  ...,   345,  6364,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 500, Loss: 6.0193\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   406, 18420,  ..., 16630,  9598,   834],\n",
            "        [50256,   519, 20996,  ...,   648,  1732,     1],\n",
            "        ...,\n",
            "        [50256,   348,  3541,  ..., 36542,   767,    25],\n",
            "        [50256,  2577,   801,  ...,  1176,   329,  2272],\n",
            "        [50256,   198,   198,  ...,   220,   220, 18248]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  2154,  ...,  1596,  2579,    13],\n",
            "        [50256,   922,   503,  ..., 12347,  5112,    12],\n",
            "        [50256, 10548,   902,  ...,   475,  2245,  1790],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 10064,   389,  ...,  2411,  8040,    11],\n",
            "        [50256,   357,    16,  ...,  5852,     8,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2440,   287,  ...,   326,  7579,  3185],\n",
            "        [50256,    11,   379,  ...,  1628,   523,  1290],\n",
            "        [50256,    78,    14,  ...,    31,  9782,    11],\n",
            "        ...,\n",
            "        [50256,  2485, 45855,  ...,   262, 44799, 16472],\n",
            "        [50256,   220,   220,  ...,   220,   220,  2546],\n",
            "        [50256,   286, 25051,  ...,   262,  5761,   340]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14667,  5504,  ...,   355,   867, 18190],\n",
            "        [50256, 39280,   535,  ...,   262,  2029,  1729],\n",
            "        [50256,   220,   705,  ..., 23574,   546,   262],\n",
            "        ...,\n",
            "        [50256, 30610,    12,  ...,    14,  9410,  4248],\n",
            "        [50256,  4645,   351,  ..., 31669,    12,    32],\n",
            "        [50256,  3314,    11,  ..., 13931,   318,  2048]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   287,   616,  ...,   262,   640,  1748],\n",
            "        [50256,  5411,    11,  ...,   768,    13,   383],\n",
            "        [50256,  5922,  4678,  ...,  6459,   287,   366],\n",
            "        ...,\n",
            "        [50256,  6164,   290,  ...,  9144,   340,    13],\n",
            "        [50256,   788,   618,  ...,  3556,  7146,    29],\n",
            "        [50256,   326,   389,  ...,  5304,   828,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262, 29673,  ...,     2, 27975, 38162],\n",
            "        [50256,   262, 17293,  ...,  3155,   286,  3621],\n",
            "        [50256,  1081,  2974,  ...,  2235, 45624,  6375],\n",
            "        ...,\n",
            "        [50256,   734,  2745,  ...,  6631,    13,   198],\n",
            "        [50256, 17427, 13470,  ...,   220,   220,   220],\n",
            "        [50256, 15690,  8053,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   385,   256,  ..., 11033,   447,   251],\n",
            "        [50256,    71,  3974,  ...,   442,  1934,   296],\n",
            "        [50256, 26488, 22065,  ...,    13, 13344, 11537],\n",
            "        ...,\n",
            "        [50256,   262,  1708,  ...,   198,   198,  4711],\n",
            "        [50256,  1402,  2033,  ...,  1262,   691,   530],\n",
            "        [50256, 16362,  4478,  ...,   523,   355,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4575,   282,  ...,   383,  4511, 26789],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    29,   198,  ...,   220,  2170, 12453],\n",
            "        ...,\n",
            "        [50256,   270, 22940,  ...,   263,  2123, 29868],\n",
            "        [50256,   284,  3234,  ...,   503,   379,  4751],\n",
            "        [50256,   509, 12115,  ...,  6894,  7972,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,  1279, 26745],\n",
            "        [50256,  6101,  1635,  ...,   220,   220,   220],\n",
            "        [50256,  3915,  6580,  ..., 11063,    79, 21241],\n",
            "        ...,\n",
            "        [50256,   543,   561,  ...,  9030,   286,  2223],\n",
            "        [50256,   504,  2456,  ..., 25246,    25,   262],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   540,  1776,  ...,    11, 15349,   311],\n",
            "        [50256,   220,   220,  ...,   262, 39280, 34846],\n",
            "        ...,\n",
            "        [50256,  3357,  1088,  ...,   470, 14177,   257],\n",
            "        [50256,   314,   423,  ...,  1135,   423, 11829],\n",
            "        [50256,   108,   128,  ...,  1987,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 510, Loss: 6.0100\n",
            "tensor([[50256,   340,   318,  ..., 27422,   770,  2208],\n",
            "        [50256,    12, 17618,  ..., 14751,    59,    62],\n",
            "        [50256,   796,   657,  ...,   220,  3373,   878],\n",
            "        ...,\n",
            "        [50256,  1366,  2393,  ...,   198, 29238,   287],\n",
            "        [50256,    12,    17,  ...,     7,    18,   737],\n",
            "        [50256,    92, 36796,  ...,  2488, 22609,  1040]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   373,   407,  ..., 37782,   355,   257],\n",
            "        [50256,  9539,    13,  ...,  2280,    11,   777],\n",
            "        [50256,   220,   366,  ...,  1833,  1521,   340],\n",
            "        ...,\n",
            "        [50256, 26867, 25244,  ...,    32,  1983,  1507],\n",
            "        [50256,   220,   220,  ...,   198,   220,   220],\n",
            "        [50256,   511,  3277,  ...,    29,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   345,   691,  ...,   262,  9313,   366],\n",
            "        [50256,   307,  6464,  ...,   198,   198,  6307],\n",
            "        [50256, 11291,  3467,  ...,    85,    28,    17],\n",
            "        ...,\n",
            "        [50256,   198,   220,  ...,   262,  1353,    12],\n",
            "        [50256,   257,  2219,  ...,   858,   621,  2687],\n",
            "        [50256,  1983, 47113,  ..., 16215,   511,  3815]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5279,    11,  ...,  1641,  2888,    11],\n",
            "        [50256,   561,   314,  ...,  7319, 24780,   284],\n",
            "        [50256,    13,  2670,  ...,  2233,   284,   262],\n",
            "        ...,\n",
            "        [50256,   481,   910,  ..., 17226, 19590,   550],\n",
            "        [50256,   220,   220,  ...,  2014,  1776, 30596],\n",
            "        [50256,    11, 24894,  ...,   416,    11,  5946]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,     8,   468,  ...,   428, 45262,  1499],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2430,     9,  ...,  1782,   198,    48],\n",
            "        ...,\n",
            "        [50256, 36096,   502,  ...,  1739,   287,   284],\n",
            "        [50256, 12453, 23853,  ...,   220,   220,   220],\n",
            "        [50256,  7532,    11,  ...,  5800,    11, 25264]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1903,   640,  ...,  6333,   920,   648],\n",
            "        [50256,  2428, 10411,  ...,  5155,   338,  2643],\n",
            "        [50256,   247,    82,  ...,   481, 10403,  1716],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   447,   247,  ...,   481,   307,  5421],\n",
            "        [50256,    49,   788,  ...,   410,     1,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 26700,   198,  ...,   220,   220,   220],\n",
            "        [50256,   460,   772,  ...,  6100,   345,  2641],\n",
            "        [50256, 18872,   245,  ...,   198, 13702,  6852],\n",
            "        ...,\n",
            "        [50256,   339,  2227,  ...,   546,   607,  6621],\n",
            "        [50256, 10394,  2625,  ...,   331,  2625,    15],\n",
            "        [50256,   287,   257,  ...,   584,  4813,   503]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5839,   281,  ...,  1119,  2107,   739],\n",
            "        [50256,   262,  2589,  ...,   198,  5195, 38742],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,    13,   410,  ...,    11,   407,   355],\n",
            "        [50256, 15915,   788,  ..., 21387,  4091,  9406],\n",
            "        [50256,   314,   550,  ...,  5586,  1306,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    62, 12888,  ...,    62,  4862,    62],\n",
            "        [50256,  9569,   422,  ...,  1146, 17070, 17910],\n",
            "        [50256,  4047,  1398,  ...,   540, 18345,   960],\n",
            "        ...,\n",
            "        [50256,  4172,  1064,  ...,    13,   775,  2897],\n",
            "        [50256,   284,  2962,  ...,  1893,  8404,   284],\n",
            "        [50256,   357,   220,  ...,   286, 47043,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2625, 15699,  ...,     1,   198,   220],\n",
            "        [50256,   765,   284,  ...,   550,   262,   976],\n",
            "        [50256,  9109,   416,  ...,   286,   661,   508],\n",
            "        ...,\n",
            "        [50256,   416,   262,  ...,   410,    13, 18358],\n",
            "        [50256,  4810, 14114,  ...,   198,   198, 10449],\n",
            "        [50256,  1255,   287,  ...,   850, 11883,  1671]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 520, Loss: 6.5600\n",
            "tensor([[50256,  5408,   286,  ...,  4093, 44678, 17765],\n",
            "        [50256,    11, 12432,  ...,    11,   314,   423],\n",
            "        [50256,  7955,   422,  ...,  3335,   460,   307],\n",
            "        ...,\n",
            "        [50256,   329,   357,  ...,    12,  1659,    12],\n",
            "        [50256,   198,   198,  ...,    13,   775,   481],\n",
            "        [50256,  1210, 10016,  ...,   777,  5212,  7686]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   616,  ...,  1318,   318,  2147],\n",
            "        [50256,  1022,   262,  ...,   272,  5451,   290],\n",
            "        [50256, 24529,   828,  ...,   597,   286,   777],\n",
            "        ...,\n",
            "        [50256,   198,  3886,  ...,   329, 11963, 42541],\n",
            "        [50256,   262,   938,  ...,  5189,    32,     5],\n",
            "        [50256,  4056,   284,  ...,  5257,   284,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   329,  1757,  ...,   317,  1821,  2791],\n",
            "        [50256,    13,  1314,  ...,   666, 46972,  1582],\n",
            "        [50256,  2793,  5584,  ...,   198,   198,  1212],\n",
            "        ...,\n",
            "        [50256,   628,   220,  ...,   220,   220,   220],\n",
            "        [50256, 17768,   447,  ..., 28449,    11,   351],\n",
            "        [50256,  3511,   422,  ...,   465,  2479,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   287,  1502,  ...,   307,  6848,   290],\n",
            "        [50256,  1902,  8369,  ..., 24761,   318,   257],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 13926,   605,  ...,  2191,  6303,    13],\n",
            "        [50256,  6759,  2052,  ...,    28, 35175,  2919],\n",
            "        [50256,   777, 10812,  ...,  4890,  2685,  3951]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   611,   262,  ..., 47082, 34507,  6329],\n",
            "        [50256,   329,   502,  ...,  3719,  8101,  5733],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   257,   649,  ...,   198, 47231,   919],\n",
            "        [50256,    33, 11159,  ...,    26,   198,   197],\n",
            "        [50256,  1811,  1661,  ...,   290,   625, 15077]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ...,  2174,    13,   198],\n",
            "        [50256,   220,   220,  ...,     0,    58, 16151],\n",
            "        [50256,   503,   287,  ...,   290, 43092,  2044],\n",
            "        ...,\n",
            "        [50256,     3,   884,  ...,  3849,   447,   247],\n",
            "        [50256, 14379,   220,  ...,   290, 12946,  6289],\n",
            "        [50256,   416,  3463,  ...,   357,    34,     8]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5346,   364,  ...,   564,   250,   272],\n",
            "        [50256,   326,   428,  ...,    58,    61,  6852],\n",
            "        [50256, 12752, 10582,  ...,  1064, 11529,   319],\n",
            "        ...,\n",
            "        [50256, 22778,  8881,  ..., 18989,  1497,   262],\n",
            "        [50256,  5804,   262,  ...,  6464,   281, 25519],\n",
            "        [50256,    13,  3862,  ..., 37330,    16, 19953]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 36117,    11,  ...,   220, 47424, 19667],\n",
            "        [50256,   508, 21318,  ...,    11,  1282,   319],\n",
            "        [50256, 27354,   220,  ...,   505,    12,    74],\n",
            "        ...,\n",
            "        [50256,   340,   290,  ...,    62,  6369,  2943],\n",
            "        [50256,   399,    65,  ...,    14,    75,  4075],\n",
            "        [50256, 43673,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   611,  ...,  9242,  1776,   198],\n",
            "        [50256,  1074,  4478,  ..., 21170,  5013,  1459],\n",
            "        [50256,    25,  4353,  ...,    11, 12716,    11],\n",
            "        ...,\n",
            "        [50256,   607,    11,  ...,    25, 21617, 29668],\n",
            "        [50256, 17489,   705,  ...,  4426,  1222,   718],\n",
            "        [50256, 43386,   326,  ...,   318,  7223,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   220,  ...,   220,   220,  7359],\n",
            "        [50256, 17810,   286,  ...,  6066,   290,  9109],\n",
            "        [50256,  1339,    11,  ...,    11,   287, 21647],\n",
            "        ...,\n",
            "        [50256, 21421,  2055,  ...,  3499,  2173,    13],\n",
            "        [50256,   262,  8390,  ...,   290,   340,   338],\n",
            "        [50256,  3048,   286,  ...,  5716,   351,  9529]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 530, Loss: 5.9863\n",
            "tensor([[50256, 19267,  2482,  ...,   290,  6954,  2637],\n",
            "        [50256,   554,  3426,  ...,    12,    22,    13],\n",
            "        [50256,   257,  1336,  ...,   287,  2031,  1201],\n",
            "        ...,\n",
            "        [50256, 29757,  9015,  ...,    26,   285,  1299],\n",
            "        [50256,    71,     9,  ...,    73,     9,   290],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 37773, 10267,  ...,   588, 10453,    11],\n",
            "        [50256,    12, 30214,  ...,    38,  2538, 34645],\n",
            "        [50256,   447,   247,  ..., 11620,    13,   311],\n",
            "        ...,\n",
            "        [50256,    15,    13,  ...,   220,   220,   220],\n",
            "        [50256,   412,    12,  ...,   260,   488,   279],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   717,   734,  ...,   447,   247,  2489],\n",
            "        [50256,  8554,   257,  ...,    11,   556,   283],\n",
            "        [50256,  2940,   290,  ...,    11,   484,  2222],\n",
            "        ...,\n",
            "        [50256,   281,  1175,  ...,  3199,   287, 10362],\n",
            "        [50256,   220,   220,  ...,   220,   366,    67],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 11455, 11343,  ...,    82,  4281,   286],\n",
            "        [50256,   262, 11847,  ...,    11,   290,   673],\n",
            "        [50256,  1549,   198,  ...,  1366,   905,   262],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 34949,   198,  ...,  1267,    30,   220],\n",
            "        [50256,  6957,     4,  ...,  5999,  4407,  7040]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    37,    62,  ...,    23,  1635,   259],\n",
            "        [50256,   319,   262,  ...,   262,  2526,   286],\n",
            "        [50256,    25,   532,  ...,  3064,    14,    24],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,     8,   796,   532],\n",
            "        [50256,   284,   779,  ...,  5145,    84,     0],\n",
            "        [50256,   828, 22183,  ...,    11,   262,  2059]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,   262,  ...,  1549,   345,   466],\n",
            "        [50256,   262,  1271,  ...,   604,    13,   198],\n",
            "        [50256,   201,   198,  ...,   220,   220,  1635],\n",
            "        ...,\n",
            "        [50256,  1174,    11,  ...,   838,    61,   438],\n",
            "        [50256,   307,  3177,  ...,   554,   465,  4459],\n",
            "        [50256,  1026,   338,  ...,  3673,   379,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 30300,     7,  ...,  2959,   357,  5539],\n",
            "        [50256,  7404,    13,  ..., 25654,   338, 12296],\n",
            "        [50256,    13, 35854,  ...,   198,    89,  1174],\n",
            "        ...,\n",
            "        [50256,  4577,   284,  ..., 14126,   352,     1],\n",
            "        [50256,    13,  1983,  ...,   220,   220,   220],\n",
            "        [50256,  2482,    11,  ...,    39,     9, 14687]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   871,  3688,  ..., 19953,  5420,    12],\n",
            "        [50256, 10451,   284,  ...,   683,    13,   679],\n",
            "        [50256,   287,  2795,  ...,    64,    11,  6997],\n",
            "        ...,\n",
            "        [50256,   198,  1507,  ...,    13, 39200,   532],\n",
            "        [50256,   198,  7085,  ...,   329,   262,  3513],\n",
            "        [50256,  5374,   563,  ...,   198,   198,  4242]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3781,    13,  ...,   718,     3,    59],\n",
            "        [50256,    80,    13,  ..., 13731,   399,    59],\n",
            "        [50256,    12,  4906,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   220,  2077,  ...,  1676,  4593,  5958],\n",
            "        [50256,    11,  8060,  ...,  1416,  5773,    13],\n",
            "        [50256,  4778,    11,  ..., 18307,   284,   606]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   262,  ...,  2568,    13,   198],\n",
            "        [50256, 15437,   198,  ...,   220,   220,  1309],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  4873,   355,  ...,   262, 26969,  9150],\n",
            "        [50256, 19144,  2000,  ...,   287,   257,  8011],\n",
            "        [50256, 17034, 31478,  ...,    16, 18477,    17]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 540, Loss: 5.5629\n",
            "tensor([[50256,   198,   198,  ...,   318,   852, 18419],\n",
            "        [50256,  6163,   290,  ...,   262, 10152,   351],\n",
            "        [50256,   257, 16096,  ..., 31439, 13523,   423],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  3393,  4050,  ...,    11, 30218,    13],\n",
            "        [50256,   415,  3450,  ..., 19185, 15055,  4633]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ...,    12, 43617,  1525],\n",
            "        [50256, 25860,    11,  ...,   198,  6425,    25],\n",
            "        [50256,    11,  1688,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  7229,    11,  ..., 25985,   284,   543],\n",
            "        [50256, 28869, 11413,  ...,  6890,    14, 43776],\n",
            "        [50256,   356,   466,  ...,   198, 13702,  6852]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   812,    13,  ...,   262,  6101,    36],\n",
            "        [50256, 11234,    30,  ...,   345,    11,  1545],\n",
            "        [50256,   198,    16,  ...,  1511,  6420,   290],\n",
            "        ...,\n",
            "        [50256,     8,   198,  ...,  1097,   313,   312],\n",
            "        [50256,   287,   530,  ..., 31453,   257,  2563],\n",
            "        [50256,   262,  1902,  ...,   819, 23466,  7002]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   683,    11,  ...,   655,  1804,  9313],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,     7, 28611,  ...,    13, 17172,  9869],\n",
            "        ...,\n",
            "        [50256,   836,   470,  ...,    88,    48,   198],\n",
            "        [50256,   346,  7509,  ...,  6147,  3513, 11742],\n",
            "        [50256,  8468, 19896,  ...,  1964,  6130,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 46661,   265,  ...,    65,  1174,     8],\n",
            "        [50256, 31478, 19881,  ...,    90,  7890,    12],\n",
            "        [50256,   534,  1848,  ...,  6490,    11, 11886],\n",
            "        ...,\n",
            "        [50256,   197,    49,  ...,   220,   220,   220],\n",
            "        [50256,   250,  1544,  ...,   292,  1257,    13],\n",
            "        [50256,   220,   220,  ..., 23004,     7, 26209]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    58,    36,  ...,  5372, 13829,    11],\n",
            "        [50256,  4565, 26520,  ...,   290,  9902,  2563],\n",
            "        [50256,   220,   220,  ...,    93, 10563,    10],\n",
            "        ...,\n",
            "        [50256,   284,   262,  ...,   290,  2457,  2665],\n",
            "        [50256,   355,   257,  ...,    12, 17899, 38342],\n",
            "        [50256,  1635, 34703,  ...,    77, 46582,     9]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9536,   266,  ...,    73,   280,   263],\n",
            "        [50256, 14900,    14,  ...,   257,  1227,    13],\n",
            "        [50256,  4044,    14,  ...,   684,   290, 16420],\n",
            "        ...,\n",
            "        [50256,   938,  5041,  ...,   588,  2039,    78],\n",
            "        [50256,  1035,  8306,  ...,    12, 10724,  1068],\n",
            "        [50256,   970,     0,  ...,   986, 28998,   345]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 34385, 17668,  ...,    11,   955,  1443],\n",
            "        ...,\n",
            "        [50256, 27307,   329,  ...,  1672,    13,  3082],\n",
            "        [50256,   286,  8067,  ...,   676,  1039,  9426],\n",
            "        [50256,   258, 27798,  ...,   284,  2952,  7716]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 28462,   290,  ...,    11,    59,     4],\n",
            "        [50256,    67,   807,  ...,   286, 32631,   286],\n",
            "        [50256, 47499,   257,  ...,   287,   262, 11662],\n",
            "        ...,\n",
            "        [50256,     1, 11037,  ...,  7359,    79,    29],\n",
            "        [50256,    11,    87,  ...,  4739,   197,    87],\n",
            "        [50256,   532,   383,  ...,    11, 17490, 15514]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3281,  9128,  ..., 24344,   379,   440],\n",
            "        [50256,   818,  3090,  ..., 18327,   393, 10569],\n",
            "        [50256,   612,    13,  ..., 43108,   220, 21727],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   669,   526,  ...,   550,  6793,   257],\n",
            "        [50256,   379,  1551,  ...,  1065,    13,   632]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 550, Loss: 5.0053\n",
            "tensor([[50256,   657,    87,  ...,   272,  1600,   198],\n",
            "        [50256,  6772, 17445,  ...,    12, 38142, 25585],\n",
            "        [50256,  2026,   812,  ...,   807,  2167,    26],\n",
            "        ...,\n",
            "        [50256,  6161,    11,  ...,   286,   777,  5050],\n",
            "        [50256,   383, 21964,  ...,   355, 47013,    38],\n",
            "        [50256, 20736, 20849,  ...,    12, 46650, 43064]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   625,   262,  ...,   655,   326,    11],\n",
            "        [50256,  5103,   290,  ...,  2891,   351,   257],\n",
            "        [50256,   790,   530,  ...,    13,  1881,  1517],\n",
            "        ...,\n",
            "        [50256, 21504, 42336,  ...,   326,  1635,    50],\n",
            "        [50256,   308, 17237,  ...,   734, 11621,    11],\n",
            "        [50256,  7008,   357,  ...,   309,  2685,  1363]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3354,   286,  ...,   526,  5094, 26319],\n",
            "        [50256,   220,   220,  ...,   628,   220,   220],\n",
            "        [50256,     3,   290,  ..., 31478, 35505,  1782],\n",
            "        ...,\n",
            "        [50256,   825,    11,  ...,   220,  1309, 11007],\n",
            "        [50256, 14095,    17,  ...,  1849,   940,    61],\n",
            "        [50256,  2460,   286,  ...,   351,   262, 32722]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3556,    79,  ..., 21858, 11505,     1],\n",
            "        [50256,  4645,   393,  ...,  3335,   743,  4361],\n",
            "        [50256,   198,  9360,  ...,   318, 37692, 19767],\n",
            "        ...,\n",
            "        [50256,  2356,    13,  ...,   198,   198,    40],\n",
            "        [50256,   468,   284,  ...,    72,   290,   399],\n",
            "        [50256,    11,  7722,  ..., 35944,  9375,  2674]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   338, 35911,  ...,   262,  3052,   393],\n",
            "        [50256,   326,   318,  ...,   863,   616,  2104],\n",
            "        [50256,    13,   314,  ...,   220,  1782,   198],\n",
            "        ...,\n",
            "        [50256,    11,   290,  ...,  8694,  1074,   329],\n",
            "        [50256,    11,   262,  ...,   198,   198,    32],\n",
            "        [50256, 23988, 11053,  ...,   317,   290,   347]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   318,   287,  ...,   257,  6268,   284],\n",
            "        [50256,   290,   262,  ...,  1565, 41576,     8],\n",
            "        [50256, 16654,   329,  ...,    12, 40773,  1366],\n",
            "        ...,\n",
            "        [50256,   632,   338,  ...,    11,   340,   857],\n",
            "        [50256,  1388,  1906,  ...,   198, 10265,   286],\n",
            "        [50256,   198,   197,  ...,  2943, 20940,  3698]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,  4738,  ...,    13,   383,   564],\n",
            "        [50256,   284,   262,  ...,     8,  1871,   262],\n",
            "        [50256, 12673,    61,  ..., 14651,   367, 14082],\n",
            "        ...,\n",
            "        [50256,    13,  1375,  ...,   611,   262, 17746],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   286,  3785,  ...,     3,   355,  1813]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   319,   257,  ...,   262,  4220, 13043],\n",
            "        [50256,    26,   198,  ...,   262,  3548,   262],\n",
            "        [50256,  3199,  6702,  ..., 21072,    11,   290],\n",
            "        ...,\n",
            "        [50256,   644,   318,  ..., 20561,   198,   198],\n",
            "        [50256, 25374,  3705,  ...,   220,   220,   220],\n",
            "        [50256,  2859,  3780,  ...,  9235,    13,  1849]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   968,  1605,  ...,  4608,    13,   770],\n",
            "        [50256,   284,   779,  ...,   373, 21846,    13],\n",
            "        [50256,  1870,  1464,  ...,   766,   262, 20073],\n",
            "        ...,\n",
            "        [50256,  6621,   338,  ...,  1023,    13,   770],\n",
            "        [50256, 12429,   853,  ...,   220,   220,   220],\n",
            "        [50256,  2074,   257,  ...,    47,   931,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    96, 34932,  ...,   122,   220, 20375],\n",
            "        [50256,   505,    12,  ...,   262,   734,  2663],\n",
            "        [50256,     1,  1640,  ...,  4270,   506,  9319],\n",
            "        ...,\n",
            "        [50256,   197,   197,  ...,   198,    92,   198],\n",
            "        [50256, 42759,    30,  ...,  1731,   486,  4761],\n",
            "        [50256,   866,   262,  ...,   198,   447,   250]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 560, Loss: 6.1206\n",
            "tensor([[50256,   734, 19051,  ..., 17779,  9216,  5091],\n",
            "        [50256,  1568,   812,  ...,   945,  4901,   326],\n",
            "        [50256,  1528,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   351, 43399,  ..., 12280, 24503,  1042],\n",
            "        [50256,  3357,  2910,  ...,  1339,   625,   262],\n",
            "        [50256,  4564,   286,  ...,    11,  5701,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 10645,   313,  ...,   284,  1635,    67],\n",
            "        [50256, 49492,  4633,  ...,   830,    18,    92],\n",
            "        [50256, 11119,   329,  ...,  4277,  8492,    13],\n",
            "        ...,\n",
            "        [50256, 37737,   350,  ..., 10720,  4849,   771],\n",
            "        [50256,   318,  1884,  ...,    62,    83,    27],\n",
            "        [50256,   220,   220,  ...,   319,   262, 21182]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12,  3245,  ...,   547,  2098,   422],\n",
            "        [50256,  4163,   340,  ..., 12102,  3419,  1267],\n",
            "        [50256,  9484,   532,  ...,     6,  9030,    11],\n",
            "        ...,\n",
            "        [50256,   318,  1813,  ...,    59, 31944,    90],\n",
            "        [50256,   319,   262,  ...,  2776,    11,   447],\n",
            "        [50256,  2099,   286,  ...,  1635,  7156, 10913]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,  2029,  5423,   290],\n",
            "        [50256,  4765,  1271,  ...,  1495,  6822,   262],\n",
            "        [50256,   286,   262,  ...,   318,   257,  4274],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    13,  4550,  ...,   220,   220,   220],\n",
            "        [50256,    85,    19,  ..., 22269, 11528,   314]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 47676, 25174,  ...,  1542,  7200,    34],\n",
            "        [50256,   362,   304,  ...,  4203, 13999,   284],\n",
            "        [50256,    62, 17015,  ...,  2430, 15588,    62],\n",
            "        ...,\n",
            "        [50256,   311,  1352,  ..., 15440,   290,  4049],\n",
            "        [50256,  7126,   379,  ...,  1062,   660, 19958],\n",
            "        [50256,   286,   625,  ...,   561, 33570,  2717]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   284,  1826,  ...,   345,   290,   534],\n",
            "        [50256,  4518, 10096,  ...,  6706,   577,   532],\n",
            "        [50256, 18432,   262,  ...,   890,   587,   635],\n",
            "        ...,\n",
            "        [50256,  9021, 17624,  ..., 13960,    11,  1141],\n",
            "        [50256,   379,  4974,  ...,   805, 32751,    72],\n",
            "        [50256,   284, 13388,  ..., 34910,  2331,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1064,  2346,  ...,    13,   198,   198],\n",
            "        [50256, 15325,  1122,  ..., 17769,  2700,   618],\n",
            "        [50256,   379,   340,  ...,   373,  1804,   262],\n",
            "        ...,\n",
            "        [50256,   262,  6483,  ...,    25,  4287,  7346],\n",
            "        [50256,  9967,    56,  ...,    13, 31279,   447],\n",
            "        [50256,   616,  4756,  ...,  2646,   526,   366]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  8475,  ...,   262,   350,  7998],\n",
            "        [50256,   198,  1870,  ..., 26159, 10329,  5095],\n",
            "        [50256, 15490,   290,  ...,    56,  7938,     0],\n",
            "        ...,\n",
            "        [50256,  1282,   736,  ...,  9032,    26,   198],\n",
            "        [50256,  5079,  1812,  ...,  4193, 46418,   262],\n",
            "        [50256,  2157,   262,  ...,   198,   447,   250]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    61,    17,  ...,    81,    10,    73],\n",
            "        [50256,   220,   220,  ...,    13, 22579,   220],\n",
            "        [50256,  4783,  2184,  ...,   517,    11,   262],\n",
            "        ...,\n",
            "        [50256,    72,   760,  ...,  1339,   287, 25768],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,     7,  ...,    12, 35902, 43678]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 31936,  9019,  ...,   220,   220,  1303],\n",
            "        [50256,  2725,    72,  ...,   286,  1006,    82],\n",
            "        [50256,   171,   120,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  8632,   287,  ...,  4789, 31631, 20151],\n",
            "        [50256,   220,   220,  ...,   796,   275,    58],\n",
            "        [50256, 46541,    29,  ..., 23588,   874,     7]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 570, Loss: 5.0524\n",
            "tensor([[50256,    92,    91,  ...,  3693,  2231, 16151],\n",
            "        [50256,   517,  6409,  ...,   871,   389,   645],\n",
            "        [50256,    64,    13,  ...,   583,  2836,    30],\n",
            "        ...,\n",
            "        [50256,   284,  6330,  ...,   656,   262,  1660],\n",
            "        [50256, 16747,  1303,  ...,   247,    82,  1327],\n",
            "        [50256,    69, 10535,  ...,   284,   327,  4880]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   357, 16302,  ..., 17320,  3361,   272],\n",
            "        [50256,   220,   220,  ...,    12, 39231,    12],\n",
            "        [50256,   357,    81,  ...,  1877, 13184,    11],\n",
            "        ...,\n",
            "        [50256,    18,    67,  ...,   357,    20,     8],\n",
            "        [50256,   314,  1265,  ...,   407,  1336,   286],\n",
            "        [50256,   530, 12460,  ..., 21127,    73,   499]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    14, 37696,  ...,   518, 14989,    17],\n",
            "        [50256,   287, 20547,  ...,    30,  9365,   345],\n",
            "        [50256,   611,   484,  ...,  8218,   257,  4875],\n",
            "        ...,\n",
            "        [50256,   262,  7409,  ...,   428,  5449,   460],\n",
            "        [50256,    11,  3660,  ...,    13,  1120,     8],\n",
            "        [50256,  1866,   286,  ...,  3415,  2166,    12]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   314,  1975,  ...,  3432,   329,   340],\n",
            "        [50256,  4349,    13,  ...,    11,  7647,  6041],\n",
            "        [50256,   198,   220,  ...,   271, 19182,     7],\n",
            "        ...,\n",
            "        [50256,  3750,    13,  ...,  1478,  2447,  1596],\n",
            "        [50256,  2625, 40406,  ..., 43481, 13414,  1443],\n",
            "        [50256, 33661,     7,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   290,  ...,   655,  1751,   526],\n",
            "        [50256,   845,  1029,  ...,  7455,    35,  1503],\n",
            "        [50256, 36692,  4275,  ...,  2431,  2427,   286],\n",
            "        ...,\n",
            "        [50256,  7998,     8,  ...,    11,   339,   714],\n",
            "        [50256,  1295,    13,  ...,   351, 12098,    11],\n",
            "        [50256,   376,    13,  ..., 10238,   262, 14544]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   464,  ...,  1577,   362,    11],\n",
            "        [50256,  2026,    13,  ...,   220,   220,   220],\n",
            "        [50256, 29370,    59,  ...,  1485,    13,    20],\n",
            "        ...,\n",
            "        [50256,    44,  2389,  ...,  3290,    13,   198],\n",
            "        [50256, 29325,    11,  ...,   698,   796,   269],\n",
            "        [50256,    13,  2531,  ...,    83,  1174,    18]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   505,    13,  ...,   325,    79,    62],\n",
            "        [50256,    11,  4838,  ...,   198,   198,   464],\n",
            "        [50256,   339,  9373,  ...,   818,  3194,  3840],\n",
            "        ...,\n",
            "        [50256, 29393,   290,  ...,    11, 21072,   275],\n",
            "        [50256,     8,   198,  ...,    87,    23,     8],\n",
            "        [50256,  1276, 18044,  ...,  5507,    13,   785]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3878,  1526,  ...,     8,   198,   198],\n",
            "        [50256,  9948,    90,  ...,    57, 11709,    61],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   449,    13,  ...,   360,    13,  1849],\n",
            "        [50256,   220,   220,  ...,    92,    60,   198],\n",
            "        [50256,   319,   628,  ...,  2816, 29961,     8]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   414,  5202,  ...,    13,  1355, 30705],\n",
            "        [50256,  4157,   389,  ...,   311,   198,   198],\n",
            "        [50256,   764, 13702,  ...,    15,    59,  3506],\n",
            "        ...,\n",
            "        [50256,   737, 39514,  ...,    12,   486,  1415],\n",
            "        [50256, 18076,    29,  ..., 23513, 44165,   233],\n",
            "        [50256, 19796,     7,  ...,    30,   366,  1212]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 34645,   220,  ...,   416,  1957, 15441],\n",
            "        [50256,   640,    13,  ...,    13,   383,  4220],\n",
            "        [50256, 44070, 18840,  ...,  1031, 18840,   285],\n",
            "        ...,\n",
            "        [50256,  4357,   262,  ...,  3871,  2263,   290],\n",
            "        [50256,  2524,   220,  ...,    11,  6666,  2685],\n",
            "        [50256,   220,   220,  ...,   355,   340,   338]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 580, Loss: 6.2880\n",
            "tensor([[50256,   352,  3467,  ..., 23330,    59, 50033],\n",
            "        [50256,   356,   892,  ..., 29367,    13,   198],\n",
            "        [50256,  3706,   828,  ...,    26,   220,   279],\n",
            "        ...,\n",
            "        [50256,   220, 22728,  ...,   220,   220,   220],\n",
            "        [50256,   607,  6958,  ...,   422,   262, 22116],\n",
            "        [50256,  5866,  3119,  ...,    11, 39741,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   338,  5366,  ..., 12429, 21926,  3977],\n",
            "        [50256,  1174, 26093,  ...,  1174,   930,  4248],\n",
            "        [50256,   220,   220,  ...,   220,   220,  3467],\n",
            "        ...,\n",
            "        [50256,  2266, 30680,  ...,  1218,  1049,  8237],\n",
            "        [50256,  3843, 31273,  ...,   569,  1135,    72],\n",
            "        [50256,    87, 11024,  ...,    43,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 46417, 11352,  ...,  4758,   635,   468],\n",
            "        [50256,  8222, 12493,  ...,   220,   220, 44212],\n",
            "        [50256,  7138,    12,  ...,  1930,  1756,   547],\n",
            "        ...,\n",
            "        [50256,  8203,   262,  ...,  3312,    12,  2091],\n",
            "        [50256,   924,   474,  ...,   810, 17205,   467],\n",
            "        [50256,    11,   475,  ...,   467,   612,   314]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,   279,  ...,  6188,  1391,     2],\n",
            "        [50256,    13, 15965,  ...,  1616,    13,   785],\n",
            "        [50256,  6235,   284,  ...,  2176,  2267,   319],\n",
            "        ...,\n",
            "        [50256,  4094, 31109,  ...,  4172,    13,  1649],\n",
            "        [50256,   220,   220,  ...,   220,   311,   220],\n",
            "        [50256,    27,    51,  ...,   220,  5619,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 35335,  2323,  ...,   621,  2253,   447],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    13,   554,  ...,   286,  7394,   355],\n",
            "        ...,\n",
            "        [50256,   198,    12,  ...,   628,   198,   198],\n",
            "        [50256,  8344, 30753,  ...,  2077,  6411,    25],\n",
            "        [50256, 44678,  1512,  ...,  3751,   326, 16808]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   317,     5,  ...,    92,     3,  1744],\n",
            "        [50256,  7198,    59,  ..., 20475,    90,    56],\n",
            "        [50256,  8122,    11,  ..., 25038,   404, 26845],\n",
            "        ...,\n",
            "        [50256,    28,    59,  ..., 30300,  1782,    59],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   286,   262,  ...,   262,  6890,  3650]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,   262,  ...,   530,  2099,   286],\n",
            "        [50256,    11, 45294,  ...,  1645,    13,   198],\n",
            "        [50256,   198, 28452,  ...,   662, 27173,   290],\n",
            "        ...,\n",
            "        [50256,    13, 32520,  ...,   284,  8138,    11],\n",
            "        [50256,   286,  1393,  ...,    12,    24,    14],\n",
            "        [50256, 32092,    28,  ..., 32239, 28015,  1142]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 11160, 40028,  ..., 14922,   419,    13],\n",
            "        [50256,  7908,    14,  ...,   318,  3223,  4235],\n",
            "        [50256,  3365,  1600,  ...,   377,   506,     8],\n",
            "        ...,\n",
            "        [50256,  6428,   570,  ...,   247,  7977,  3644],\n",
            "        [50256,  4257,  1793,  ...,   455,   320,  1741],\n",
            "        [50256,   828,   290,  ...,   284,   257,  1551]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   284,  4279,  ...,  5379, 11527,    11],\n",
            "        [50256, 17716,   471,  ...,    16,    12,    59],\n",
            "        [50256,    13,  1439,  ...,   318,  1290,   517],\n",
            "        ...,\n",
            "        [50256, 14214, 14619,  ...,  3726,   737,  1002],\n",
            "        [50256,    59,    11,  ...,    14,    21, 19629],\n",
            "        [50256,    32,     8,  ...,   220,   309,    74]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2981,    29,  ...,    15,  5320,   201],\n",
            "        [50256,  6568,  2585,  ...,  1271,   287,   262],\n",
            "        [50256,    13, 28968,  ...,  7700,    55, 34519],\n",
            "        ...,\n",
            "        [50256,   286,   285,  ..., 16694,  4716,  4610],\n",
            "        [50256,  2099,   318,  ...,   257,  7532,  1043],\n",
            "        [50256,  8841,  1438,  ...,   118,   163,    95]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 590, Loss: 5.1565\n",
            "tensor([[50256,  1270,  4083,  ...,  2024,    58,    31],\n",
            "        [50256,   257,  4838,  ...,    92,     3, 25666],\n",
            "        [50256, 28706,   611,  ..., 47548,  1023,   389],\n",
            "        ...,\n",
            "        [50256,   356,   389,  ...,  4083,  2242,   843],\n",
            "        [50256,  5818,   447,  ...,    82,   262,  1410],\n",
            "        [50256,    32,   399,  ...,    31,    65,   571]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 18480, 12109,  ...,    14,    85, 49084],\n",
            "        [50256, 23235,   286,  ..., 12057,   291, 15568],\n",
            "        [50256,    11,   656,  ...,  1399,   523,   314],\n",
            "        ...,\n",
            "        [50256,  4890, 10812,  ...,   691, 10835,   547],\n",
            "        [50256,  1525,   531,  ...,     7, 23609, 26451],\n",
            "        [50256,  6764,   286,  ...,    12,  2433, 12403]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   284,  1382,  ...,  2230,   284,  1037],\n",
            "        [50256,   514,   508,  ...,   644,  3793,    11],\n",
            "        [50256,    25,    51,  ...,   709,  9720,  5667],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    13,    15,  6354],\n",
            "        [50256,  4890,   790,  ...,   880,   355, 30869],\n",
            "        [50256,  8434,   807,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 16293,   621,  ...,   625, 13991,   287],\n",
            "        [50256,  4064,   486,  ..., 31938,    12,  2075],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 17655,   257,  ..., 32661,  6864, 16989],\n",
            "        [50256,   460,  1607,  ..., 12698,   314,   373],\n",
            "        [50256,   788,   329,  ...,   314,  1101,  5597]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    76,     8,  ...,    19,    13,   220],\n",
            "        [50256, 12057,   357,  ...,    13,    50,    13],\n",
            "        [50256,  1141,  1635,  ...,   905,   994,   326],\n",
            "        ...,\n",
            "        [50256,  4457, 18700,  ...,  2968,  9094,  7776],\n",
            "        [50256,   220,   220,  ...,  1904, 26495,    58],\n",
            "        [50256,   329,   720,  ...,  1540, 23765,  4284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   379,   262,  ...,   198,     7,  4064],\n",
            "        [50256,  7003,   339,  ...,   609,  1192,   454],\n",
            "        [50256,   198,   198,  ..., 16439,   319,   262],\n",
            "        ...,\n",
            "        [50256,    78,    62,  ...,    81,    12,    16],\n",
            "        [50256,  7043,   390,  ...,   279, 35979,    11],\n",
            "        [50256,   357,    45,  ...,    13,  5595, 37709]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  6624,   705,  ...,  1438,    13,   198],\n",
            "        [50256,    11,   262,  ..., 44483,   290, 21097],\n",
            "        ...,\n",
            "        [50256,   301,   520,  ...,   718, 38219,    26],\n",
            "        [50256, 44554, 24025,  ...,  6983,  3592,   447],\n",
            "        [50256,   220,   357,  ...,  3467, 31944,  1391]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198, 22446,  ...,   286, 43849,    11],\n",
            "        [50256,  2628,  4909,  ...,    12, 36813,   672],\n",
            "        [50256,   198,  3792,  ...,  3696,     1,   393],\n",
            "        ...,\n",
            "        [50256,    71,    61,  ...,    79,    61,     9],\n",
            "        [50256,    13,  1114,  ...,   302,   521, 28153],\n",
            "        [50256,   447,   251,  ...,   250, 18108,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    82, 10098,  ...,   314,   447,   247],\n",
            "        [50256,  4781,   257,  ...,   465,  3088,   290],\n",
            "        [50256,   220,   220,  ...,   220,   220,   611],\n",
            "        ...,\n",
            "        [50256, 16870,   392,  ...,    18,     9,    65],\n",
            "        [50256,   526,   366,  ...,  1701,   366, 16676],\n",
            "        [50256,  4465, 13565,  ...,    11,   314,  1986]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 13148,   262,  ...,  4838,    13, 24982],\n",
            "        [50256,   197,     8,  ...,    13, 41509,    62],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 35307, 24982,  ...,   286, 14895,   319],\n",
            "        [50256,   197,   197,  ...,     7, 13116,    62],\n",
            "        [50256,  7349,    13,  ...,   366,  1343,  3722]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 600, Loss: 5.0955\n",
            "tensor([[50256, 18625, 14293,  ..., 19143,   284,   307],\n",
            "        [50256, 29167,    12,  ...,   465,  6915,   290],\n",
            "        [50256,   407, 26526,  ...,    13,   564,   250],\n",
            "        ...,\n",
            "        [50256,    13,  9175,  ...,  7888,  1627,  1022],\n",
            "        [50256,  3894,    11,  ...,  7674,    13,   921],\n",
            "        [50256, 23330,    72,  ..., 18242,   796,   366]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1566,   339,  ...,  6131,    11, 34794],\n",
            "        [50256,  2481,    60,  ...,   220,   220,   220],\n",
            "        [50256,  3261,    13,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   287, 10213,  ...,     8,   393,  1160],\n",
            "        [50256, 15638,    37,  ..., 11847,  7714,    13],\n",
            "        [50256, 19560,  3341,  ...,  3161,   284, 19560]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   262, 18563,  5174],\n",
            "        [50256,   220,   220,  ..., 10100,  1635, 17815],\n",
            "        [50256, 28770,   357,  ...,   271,  2123,   435],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    40,  6235,  ...,  7743,   286,   262],\n",
            "        [50256,    16,    14,  ..., 27363,    25,    69]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2013,  1139,  ...,  4753,  2683,   546],\n",
            "        [50256,   745,  6213,  ...,  1783, 32501,   198],\n",
            "        [50256,   836,   470,  ...,  1568,    11,   706],\n",
            "        ...,\n",
            "        [50256, 17440,  2514,  ...,    11,   407, 28028],\n",
            "        [50256,  6317,   706,  ..., 39037,   329,  2365],\n",
            "        [50256,   534,  9408,  ...,   198,   198, 17931]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1564,   796,  ...,   198,   220,   220],\n",
            "        [50256,  4079,   257,  ...,  8610,   355,  5128],\n",
            "        [50256,   271,    62,  ...,   220,  6246,    28],\n",
            "        ...,\n",
            "        [50256, 10950,   900,  ...,  1639,   761,   284],\n",
            "        [50256, 12003,    11,  ...,   198,   220,  5072],\n",
            "        [50256, 12060,  2628,  ...,     8,     3,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   284,  1061,  ..., 49876,   379,   352],\n",
            "        [50256,   683, 42687,  ...,   257,  3785, 13885],\n",
            "        [50256, 49196,    90,  ...,    77,    28,    16],\n",
            "        ...,\n",
            "        [50256,  6973,   198,  ...,   737,   383, 11478],\n",
            "        [50256,   477,   649,  ...,   871,   286,  3592],\n",
            "        [50256,   356,  1612,  ...,    90,    32, 23330]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1391,   352,  ...,  9796,    11,   220],\n",
            "        [50256,   645,  1738,  ...,   286,  1781,    11],\n",
            "        [50256,   796,   532,  ...,    59,  4426,    15],\n",
            "        ...,\n",
            "        [50256,  6952,   345,  ...,  4830,   930,   520],\n",
            "        [50256,   329,   554,  ...,   910,    11,   326],\n",
            "        [50256,   635, 10176,  ..., 32472, 22364,   546]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 10263,   241,  ...,   108, 22522,   252],\n",
            "        [50256,    61,    67,  ...,  1271,   286,  9421],\n",
            "        [50256,    13,  1439,  ..., 14340,   379,   262],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    12,  4906,  2625],\n",
            "        [50256, 10809,   422,  ...,  1022, 29925, 10128],\n",
            "        [50256,   577,     8,  ...,  1751,   329,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   532,    16,  ...,   352,     8,  1343],\n",
            "        [50256,  6004,   284,  ...,   607,   287,   262],\n",
            "        [50256,  5846,    13,  ...,    22,    13,  1954],\n",
            "        ...,\n",
            "        [50256,  1248, 15277,  ...,   357, 10333,   737],\n",
            "        [50256,   352,    13,  ...,  5647, 20662,   737],\n",
            "        [50256,  3402,   287,  ...,    83,     9,    12]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    18,    92,  ...,  1593,   284,   262],\n",
            "        [50256,  1395,  2746,  ...,  1531,   318,   257],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   471,    13,  ...,  3078,   338,  9110],\n",
            "        [50256,   198, 11976,  ...,   101, 48077, 11976],\n",
            "        [50256,  7733,  8064,  ...,    13,   554, 17969]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 610, Loss: 6.1578\n",
            "tensor([[50256,   295, 14659,  ...,    11, 11307,    11],\n",
            "        [50256, 16127,  2447,  ...,  1169,  2159,  5018],\n",
            "        [50256,     7,    56,  ...,  2014,     3,    25],\n",
            "        ...,\n",
            "        [50256,   307,    72,  ...,  8623,  4656, 21007],\n",
            "        [50256,   936,   397,  ...,  1031, 28749, 31215],\n",
            "        [50256,  3256,    21,  ...,   500, 20502,  5062]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,    17,  ...,  1912,   319,  2604],\n",
            "        ...,\n",
            "        [50256,    25, 16010,  ...,   368,   363,  4743],\n",
            "        [50256, 10860,   290,  ..., 13229,  1088,   262],\n",
            "        [50256, 25541,    12,  ...,  1988,  2625,    20]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286, 13759,  ...,   416,  1180,  1230],\n",
            "        [50256,   220,   220,  ...,   286,   360,   478],\n",
            "        [50256, 41269, 15448,  ...,    11, 36361,    82],\n",
            "        ...,\n",
            "        [50256,  2620,   262,  ...,  3052,   318,  2810],\n",
            "        [50256,  1502,  2625,  ...,   220,   220,   220],\n",
            "        [50256,   262,   745,  ...,    55, 47113,   720]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    16,    14,  ..., 20679, 32590, 37452],\n",
            "        [50256,   262,  8308,  ...,   340,  2391,   326],\n",
            "        [50256,   198,    17,  ...,   796,   269,  1343],\n",
            "        ...,\n",
            "        [50256, 21756,  1391,  ...,  8806, 11916,  3467],\n",
            "        [50256,    13,    17,  ...,    13,   383, 10376],\n",
            "        [50256,  3467, 30109,  ..., 35001, 38324,  6883]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6251,   615,  ..., 16922,    13,  1374],\n",
            "        [50256, 22693,   286,  ...,   892,   780,   340],\n",
            "        [50256,   286,   262,  ...,    13,   632,  5300],\n",
            "        ...,\n",
            "        [50256,   326,   743,  ...,    13,  3510,  1377],\n",
            "        [50256,    74, 20975,  ...,    15,     3,   307],\n",
            "        [50256,  3575,   265,  ...,   480,    90, 44601]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   373, 11476,  ...,   477,   760,   355],\n",
            "        [50256, 26801,  4554,  ..., 29291,    92,    12],\n",
            "        ...,\n",
            "        [50256,  5625,   284,  ...,     8,   290,   262],\n",
            "        [50256,   290,   262,  ...,  1776,  3795,   418],\n",
            "        [50256,   220,   220,  ...,    61,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3884,   351,  ...,  7864,   198,   392],\n",
            "        [50256,    25,   428,  ...,  1782,   198,   220],\n",
            "        [50256,  3332,   319,  ...,   836,   470,   760],\n",
            "        ...,\n",
            "        [50256,   749, 39280,  ...,    90,    47, 42535],\n",
            "        [50256,  2328,   318,  ...,   262,  2829,   475],\n",
            "        [50256,  2926,   301,  ...,   509,  2382,    89]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262, 47240,  ...,  2746,   319,   262],\n",
            "        [50256,  5558,    11,  ...,   220,   220,   220],\n",
            "        [50256, 31944, 31478,  ...,    59,    60, 15565],\n",
            "        ...,\n",
            "        [50256, 19272,   286,  ...,   515,   262,   939],\n",
            "        [50256,   314,   373,  ...,   607, 12411, 24362],\n",
            "        [50256,   287,   657,  ...,   373,   374,  1040]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   393,   402,  ...,   262,  2785, 11422],\n",
            "        [50256,   642,     9,  ...,    78,    14,    23],\n",
            "        [50256,   198,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 19484,  3484,  ...,  3544,   281,   987],\n",
            "        [50256,   422,   657,  ...,   651, 13459,  1566],\n",
            "        [50256,  2897,    11,  ...,  3419,  1391,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 48364,  7203,  ...,     7, 14421,  5159],\n",
            "        [50256, 12316,   326,  ...,   453,  7083, 10375],\n",
            "        [50256, 12096,  3467,  ...,  3398,    93,    18],\n",
            "        ...,\n",
            "        [50256, 11899,   333,  ...,  9589, 15198, 11416],\n",
            "        [50256,   231,  2919,  ...,   220,   220,   220],\n",
            "        [50256, 27705,    17,  ..., 24954,    15,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 620, Loss: 5.5894\n",
            "tensor([[50256,    65,   357,  ..., 11922,  1874,     8],\n",
            "        [50256,  3517, 12024,  ...,   286, 16425,   795],\n",
            "        [50256,   663, 12131,  ...,  8009,   286, 29240],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    13, 24210,    11],\n",
            "        [50256,   262, 11376,  ...,  3612,   546,   703],\n",
            "        [50256,   247,    76,  ..., 38253,  8829,  5438]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    27, 12626,  ...,  8504, 17143, 19482],\n",
            "        [50256, 44361,   290,  ...,   354,    14,  2538],\n",
            "        [50256,   220,   763,  ...,    16, 47113,   720],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  4494,  6852,  ..., 31944,    90,    68],\n",
            "        [50256,   287,  1542,  ...,  6465,  4310,   350]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ..., 28712,   796, 15797],\n",
            "        [50256,    67,    58,  ...,    59, 20106,   385],\n",
            "        [50256,    68, 36796,  ...,    74,   198,     5],\n",
            "        ...,\n",
            "        [50256,   286,   262,  ...,   262,  3113,   318],\n",
            "        [50256,   679, 43185,  ...,    82,  8886,  4947],\n",
            "        [50256,   905,   257,  ...,   547,   422,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   252,    35,  ...,   321,   365,   270],\n",
            "        [50256, 10541,   198,  ...,   220,   220,   220],\n",
            "        [50256,  3190,    13,  ...,  7367,  6124,   956],\n",
            "        ...,\n",
            "        [50256,  7446,  2779,  ...,  4575,   357,  9655],\n",
            "        [50256,   551,    69,  ...,   198,   198,   960],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 22914,    60,  ...,   307, 15475,   416],\n",
            "        [50256, 44996,  1504,  ...,  2563, 14587,   287],\n",
            "        [50256,    59,  2022,  ...,    62,    73,    59],\n",
            "        ...,\n",
            "        [50256,    13,  3406,  ...,   247,   297,   307],\n",
            "        [50256, 39720,    13,  ...,   551, 18389, 38529],\n",
            "        [50256,  2173,    13,  ...,    11,   884,   355]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1760,   326,  ...,   470,   765,   683],\n",
            "        [50256,  4129, 10795,  ..., 20428,   547,  8630],\n",
            "        [50256,  5110,  4006,  ...,    11,   290,   617],\n",
            "        ...,\n",
            "        [50256,  1333,   971,  ...,  1737,  2123,   435],\n",
            "        [50256,  3091,   287,  ...,    70, 30273, 19953],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5044,   318,  ...,   262, 21083, 23482],\n",
            "        [50256,  3623,  1628,  ...,   257,  1178,  1933],\n",
            "        [50256,     8,  5661,  ...,    11,  3267,  1160],\n",
            "        ...,\n",
            "        [50256,  7148,  1681,  ...,   284,  1220, 14784],\n",
            "        [50256,   764,   764,  ..., 19577,  7924,   936],\n",
            "        [50256,   317,  1598,  ..., 32525,   284,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 10615, 24233,  ...,   247,   303,  1239],\n",
            "        [50256, 39369,    13,  ...,  1558, 16870,   504],\n",
            "        [50256,  7767,   553,  ...,  6974,   257,  1612],\n",
            "        ...,\n",
            "        [50256,    32, 15581,  ...,   818,  5014,    22],\n",
            "        [50256,    13,    44,  ..., 15084, 14892,  4989],\n",
            "        [50256,  1773,   418,  ...,   286, 49545,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    62, 36604,  ..., 14610,   198,   220],\n",
            "        [50256,  2673,     7,  ...,    11, 20512,   277],\n",
            "        [50256,    13,  2816,  ...,    30,   198,  1828],\n",
            "        ...,\n",
            "        [50256, 39107,   262,  ..., 18242,    90,    69],\n",
            "        [50256,   220,   220,  ...,   952, 16922,   284],\n",
            "        [50256,    11,   852,  ...,  2577,   318,  2048]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1813,   416,  ...,    11,   220,   198],\n",
            "        [50256,  8217,    11,  ...,   284,  1249,  6751],\n",
            "        [50256,   262,   371,  ...,   281,  3224,  1822],\n",
            "        ...,\n",
            "        [50256,   815,   787,  ..., 41151,   290,   262],\n",
            "        [50256, 11550,    13,  ...,  5449,   284,   651],\n",
            "        [50256,  2661,   286,  ...,   262,  4986,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 630, Loss: 6.4672\n",
            "tensor([[50256,   611,     7,  ...,    62, 27447, 13912],\n",
            "        [50256,   290,    11,  ..., 13899, 11281,   656],\n",
            "        [50256,   295, 16359,  ..., 21283,    14, 37157],\n",
            "        ...,\n",
            "        [50256,    12, 29336,  ...,  9025,  1989,    13],\n",
            "        [50256,   606,   257,  ...,   287,   607,  3095],\n",
            "        [50256,    80,    89,  ...,    91,    61,    17]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   282,   354,  ..., 23475,    30,   632],\n",
            "        [50256,  2125,   470,  ..., 26729,    13, 21808],\n",
            "        [50256,   743,   307,  ...,   257, 36325,   286],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1912,  1861,  ...,   257,   513,    35],\n",
            "        [50256,   312,  4345,  ...,    50,    13,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,  2149,  ...,  7103, 16280,   373],\n",
            "        [50256,    17,    14,  ...,   357,    21,    14],\n",
            "        [50256, 11018, 19881,  ...,     3,   318,   880],\n",
            "        ...,\n",
            "        [50256,   406,    13,  ...,   347, 10679,   410],\n",
            "        [50256, 21356,    64,  ...,   384, 12379,   551],\n",
            "        [50256,   503,   286,  ..., 33519,   508,   892]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    24,   220,  ...,     0,    58,    33],\n",
            "        [50256,  5512,   198,  ...,    25,   657,    87],\n",
            "        [50256,  8564,   284,  ...,  1111,   777,  3640],\n",
            "        ...,\n",
            "        [50256,   737,  4619,  ...,   198, 13615,   284],\n",
            "        [50256,    34,  2043,  ..., 41973,  1377,   326],\n",
            "        [50256, 11887,   287,  ...,    13,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1315,  2154,  ..., 22695,  2957,   514],\n",
            "        [50256,   220,   220,  ...,   220,   220,  8915],\n",
            "        [50256,   750,   339,  ...,   757,   526,   366],\n",
            "        ...,\n",
            "        [50256,   220,  1987,  ...,    11, 15495,    11],\n",
            "        [50256,   678,   220,  ...,   642,   220,   220],\n",
            "        [50256,    77,    92,  ...,   306,  9702,   276]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 38016,    58,  ...,    59, 18242,    90],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 41886,   318,  ...,   198,   198, 11146],\n",
            "        ...,\n",
            "        [50256,   611,   484,  ...,   661,    13,   887],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   355,   880,  ..., 49202,  4876,   326]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   746,    12,  1558],\n",
            "        [50256,   447,   251,  ...,   447,   251,   198],\n",
            "        [50256,  1343,   807,  ...,    18,   290,  1577],\n",
            "        ...,\n",
            "        [50256,  2756,  3781,  ...,  1317,    13,   317],\n",
            "        [50256,    25,    15,  ...,   220,   220,   220],\n",
            "        [50256,    11,   767,  ...,   326,  4417,  9505]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    59, 10210,  ...,   287,   657,    13],\n",
            "        [50256,    83,    11,  ...,   361, 19510,  1186],\n",
            "        [50256,    11,   262,  ...,  3294,    12,  4354],\n",
            "        ...,\n",
            "        [50256,   416,   281,  ...,   618,   262,  4318],\n",
            "        [50256,  2124,  4521,  ...,   262,  9934,   286],\n",
            "        [50256, 17034,     7,  ...,     8,  1343,   532]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7611,    13,  ...,  5186,  1479, 47031],\n",
            "        [50256,    17,    58,  ...,   815,   779,  1576],\n",
            "        [50256,  5337, 23848,  ...,    13, 26122,   547],\n",
            "        ...,\n",
            "        [50256,   389, 42096,  ...,  4083,   317, 16096],\n",
            "        [50256,   163,   113,  ...,   231, 18566, 21689],\n",
            "        [50256,  1127,   410,  ..., 14883,   284, 18261]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    25,   657,  ...,   657, 26152,    21],\n",
            "        [50256,    14, 15542,  ...,  1906,    75,  2286],\n",
            "        [50256,   393,  7954,  ..., 13589,  5894,    11],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   612,    11,  ...,   319,  1115,  1180],\n",
            "        [50256,   612,  1022,  ...,  2919,  3122,    30]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 640, Loss: 5.4394\n",
            "tensor([[50256,  6163, 11666,  ...,  1849, 11296,    14],\n",
            "        [50256, 29625,  3467,  ...,  5969, 27454, 15453],\n",
            "        [50256,   351,   262,  ...,    62,  1837,  3020],\n",
            "        ...,\n",
            "        [50256, 26101,  1641,  ...,  1526,   270,   999],\n",
            "        [50256,   621,   393,  ...,   720,    32,    58],\n",
            "        [50256, 11315,  5696,  ..., 11315, 12014,  5323]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   532,  1959,  ...,  1467,    11,   644],\n",
            "        [50256,    18,    13,  ...,    13,  1114,   257],\n",
            "        [50256,   355,   379,  ..., 12273,   262, 14267],\n",
            "        ...,\n",
            "        [50256,   314,   481,  ..., 47727,  2657,    13],\n",
            "        [50256, 15248,  7700,  ...,    11,  7337,   299],\n",
            "        [50256,   220,   651,  ...,  3419,    92,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4486,   422,  ...,   198,  2215, 18832],\n",
            "        [50256,   314,     5,  ..., 17989,  5682,   290],\n",
            "        [50256,   464,  2619,  ...,    35, 11106,   338],\n",
            "        ...,\n",
            "        [50256,  1760,  8234,  ..., 12040,   286, 42423],\n",
            "        [50256,  3784, 12942,  ...,   220,   220,  1181],\n",
            "        [50256,   198,   447,  ...,  1351,  8613,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 18242,  5320,  ...,   220,   220,   220],\n",
            "        [50256,   290,  9378,  ...,  4950,    11,  1049],\n",
            "        [50256,  7328,    13,  ...,  1752,    12,   403],\n",
            "        ...,\n",
            "        [50256,  2060, 18666,  ...,   618,   428,   497],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    12,    16,  ...,  7841,   286,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  3985,  ...,   388,   531,    13],\n",
            "        [50256,   284,   543,  ..., 36367, 19450,  3056],\n",
            "        [50256,    11, 21757,  ...,  1110,    13,   198],\n",
            "        ...,\n",
            "        [50256,  2098,  3217,  ..., 27095,    11,  2300],\n",
            "        [50256,   257,  1255,  ...,  3915,  2334,    11],\n",
            "        [50256,    17,   198,  ...,   299,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 13425, 43840,  ..., 16488,  6001,    11],\n",
            "        [50256,  2347,   286,  ...,   198,   464,  9566],\n",
            "        [50256,   257,  2524,  ...,     2,  1671,  1299],\n",
            "        ...,\n",
            "        [50256,  6945,    13,  ..., 21482,  3006,    13],\n",
            "        [50256,   290,   334,  ..., 11472,    11,   475],\n",
            "        [50256,  2104,   649,  ...,  3164,   284,  3953]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2636,    12,  ...,  1335,   286,  7598],\n",
            "        [50256,   198,   198,  ...,  2248,   290,   371],\n",
            "        [50256,  6109,  6786,  ...,  4064, 29159,  3980],\n",
            "        ...,\n",
            "        [50256,    12,  4906,  ...,  2458,  2689,  1866],\n",
            "        [50256,   284,   642,  ...,   883,  7042,   351],\n",
            "        [50256, 48277,  3119,  ..., 18242,    29,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   796,  8265, 21947],\n",
            "        [50256, 10828,  2106,  ...,   584,   621,   644],\n",
            "        [50256,   262,  9041,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,    53,  2174,  ...,  7532, 18431,   265],\n",
            "        [50256,   262, 38977,  ...,   362,   290,   513],\n",
            "        [50256,  1737,    12,  ...,   575,   695,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1660,   329,  ...,  3488,  6644,  1417],\n",
            "        [50256,    13,   447,  ...,   198,   198, 18254],\n",
            "        [50256, 22046,   737,  ...,  8579, 13908, 32103],\n",
            "        ...,\n",
            "        [50256,    11,  3467,  ...,    59,   437,    90],\n",
            "        [50256,    62, 34574,  ...,  1438,     8,  1391],\n",
            "        [50256,   198, 31141,  ...,   365, 20769,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   373,   287,  ..., 49938, 43407,    13],\n",
            "        [50256,   220,   220,  ...,   290, 39514,    47],\n",
            "        [50256, 10305,   642,  ...,  1635,    77,     9],\n",
            "        ...,\n",
            "        [50256,   691,   307,  ...,    11, 38919, 21667],\n",
            "        [50256, 38339,    11,  ...,   283,  2870,  4028],\n",
            "        [50256,   319,  4290,  ...,    11,   337,    87]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 650, Loss: 6.7327\n",
            "tensor([[50256,    20,    60,  ...,  4436,  5612,  3965],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   351,   257,  ...,   262,  2793,  2184],\n",
            "        ...,\n",
            "        [50256,    59,    89,  ..., 44725, 31478, 31944],\n",
            "        [50256, 13746,   462,  ...,    13,  2919,  1899],\n",
            "        [50256,    13,   383,  ...,    11,   352,   447]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 16480,   618,  ...,   284,   838,     4],\n",
            "        [50256, 30907,   886,  ...,    33,    20, 35944],\n",
            "        [50256,  1672,    11,  ..., 33874,   287,  1248],\n",
            "        ...,\n",
            "        [50256,  1218,   329,  ...,   909, 41522,   306],\n",
            "        [50256, 44552,    25,  ...,   290,   714,  3613],\n",
            "        [50256,  1641,   550,  ...,  6576,    30, 14026]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7533, 13961,  ...,   198,   198,   464],\n",
            "        [50256,    59,   293,  ...,  3467, 42369,   350],\n",
            "        [50256,   198, 14261,  ...,   340,   422,   262],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    13,   383, 21716],\n",
            "        [50256,  1247,   286,  ...,   220,   220,   357],\n",
            "        [50256,   382,   310,  ...,    14,    43,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  1110,  ..., 47294,   689,    13],\n",
            "        [50256,   198,   198,  ...,    26,   285,  1299],\n",
            "        [50256,    61,     9,  ..., 13567,   460,   307],\n",
            "        ...,\n",
            "        [50256,   262, 11796,  ...,  1588,  3146,   286],\n",
            "        [50256,     7,    73,  ...,  5332,    13,  3914],\n",
            "        [50256,   887,   460,  ...,  3355,   287,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    44,  5912,  ...,   674,  2180,   287],\n",
            "        [50256, 12685,   375,  ...,     7,    31, 35067],\n",
            "        [50256,   536,  8609,  ...,     1,  3673,   881],\n",
            "        ...,\n",
            "        [50256,   475,   340,  ...,   407,  1280,  2723],\n",
            "        [50256,   284,  3650,  ...,   338,   366,    32],\n",
            "        [50256,  2050,   783,  ...,  4810, 13752,    17]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8208,    12,  ..., 32228,   290,  6700],\n",
            "        [50256,   257, 16084,  ...,   357,    64,  1624],\n",
            "        [50256,  2723, 13557,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   220,  4064,  ...,  1678,    13,   785],\n",
            "        [50256,   584,  2678,  ...,   290,  3555,    11],\n",
            "        [50256,  2050,   389,  ...,   468,  7425,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   416,   257,  ...,   290,  1400,    13],\n",
            "        [50256,   220,   290,  ...,   220,   220,   220],\n",
            "        [50256, 11331, 37064,  ...,   410,    13,   402],\n",
            "        ...,\n",
            "        [50256,   372,    11,  ...,  9116,  6814,   436],\n",
            "        [50256,   357, 21009,  ...,  2846,   743,   407],\n",
            "        [50256,   283, 42208,  ..., 29634, 16964,   555]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 16457,   355,  ...,  1588,  6182,  2607],\n",
            "        [50256,  2058,   284,  ...,   198,   198, 24441],\n",
            "        [50256, 11296,    13,  ...,    49, 46339,    11],\n",
            "        ...,\n",
            "        [50256,   257,  2836,  ...,   319,  1811,   286],\n",
            "        [50256,   331,  2986,  ..., 31173,  1699,   324],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 39160,   442,  ...,    23,    13,  1821],\n",
            "        [50256,     5, 37000,  ...,   290,   867,   584],\n",
            "        [50256, 41971, 14861,  ...,   663,  8830,   886],\n",
            "        ...,\n",
            "        [50256,    71,    12,  ...,   220,   220,   220],\n",
            "        [50256,  4451,    13,  ..., 20955,   866,    11],\n",
            "        [50256, 30579,   838,  ...,   247,    82,  2106]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 19897,     9,  ..., 11001,    13,   554],\n",
            "        [50256,   262,  8631,  ...,   198,  4821,   306],\n",
            "        [50256,   262,  1099,  ..., 11846,    11,   290],\n",
            "        ...,\n",
            "        [50256,   617,  6135,  ...,   884, 17820,   852],\n",
            "        [50256,  1870,   314,  ...,   366,  1858,   318],\n",
            "        [50256, 10671,  2611,  ...,    59,   335,  1747]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 660, Loss: 6.1647\n",
            "tensor([[50256,  2950,   287,  ...,   523,  9109,   284],\n",
            "        [50256,  1314,    10,  ...,  1782,    91, 36796],\n",
            "        [50256,   821, 11749,  ...,   821,  1016,   284],\n",
            "        ...,\n",
            "        [50256,    11,   657,  ...,    11,   657,    87],\n",
            "        [50256,  4907,    93,  ...,  4601,   262,   383],\n",
            "        [50256,   262,  8150,  ...,   262,  4315,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,  7568, 17457,  6888],\n",
            "        [50256, 21604,  1800,  ...,   198,  9288,    33],\n",
            "        [50256,   860,  1711,  ...,  9297,    44, 10442],\n",
            "        ...,\n",
            "        [50256,   286,  6737,  ...,  3467, 30109,    31],\n",
            "        [50256,  1241,    11,  ...,   836,   470,  1842],\n",
            "        [50256,   198, 21017,  ...,   257, 27407,  2815]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 14766, 25897,  ...,    49, 22182,  1849],\n",
            "        ...,\n",
            "        [50256,   257, 15525,  ...,   198,  1003,   351],\n",
            "        [50256,   317,  2872,  ..., 15419, 35067, 23850],\n",
            "        [50256,    82,  5420,  ...,   981,   262,  4049]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  5952,  ...,   262,   471,    13],\n",
            "        [50256, 45470,   393,  ..., 14246,  3896,   198],\n",
            "        [50256,    13,   837,  ...,  2304,  1000,  2927],\n",
            "        ...,\n",
            "        [50256,    82,  4019,  ...,   447,   247,   297],\n",
            "        [50256, 25355,   326,  ...,  2884,   262,  8157],\n",
            "        [50256,    13,  4222,  ...,   262, 16452, 16825]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,  8179,  ...,   363,    81,   562],\n",
            "        [50256, 26667,   290,  ...,  4572,    13,  1550],\n",
            "        [50256,  4268,  3307,  ...,   416, 30219,    11],\n",
            "        ...,\n",
            "        [50256,    12,  1129,  ...,   318,   262,  1988],\n",
            "        [50256,  2154,  4407,  ...,    18,    12,   820],\n",
            "        [50256,   329, 25597,  ...,   262,  1944,  6382]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   299,  ...,   225, 24243,  5055],\n",
            "        [50256,  1729,    12,  ...,    60,    59,    60],\n",
            "        [50256,  2060,  7446,  ...,  1218,  5270, 32841],\n",
            "        ...,\n",
            "        [50256,  7745, 40197,  ...,  4461,   345,   597],\n",
            "        [50256,  5035,  1895,  ...,  5752,   481,  4292],\n",
            "        [50256,    75, 17902,  ...,   262,   995,   447]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   197,  ...,    49,    62,    53],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,  2608],\n",
            "        ...,\n",
            "        [50256,   198,  1659,  ...,  4113,   257, 27931],\n",
            "        [50256,  4294,   303,  ...,   256,    11,   642],\n",
            "        [50256,   262,  1099,  ...,   319,   262, 13223]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  1770,  ...,   616,  1336, 41803],\n",
            "        [50256,  4871, 35868,  ...,   944,  2599,   198],\n",
            "        [50256,  8064,  1028,  ...,  2926,    68, 15152],\n",
            "        ...,\n",
            "        [50256,  9195,    14,  ...,  2042, 42649,    11],\n",
            "        [50256,   423,   587,  ...,  1466,   508,   547],\n",
            "        [50256,   329,   720,  ...,    12,    18, 31520]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4906,  2625,  ...,  6937, 20789,    74],\n",
            "        [50256,   326, 28025,  ...,    13,   383,  2176],\n",
            "        [50256,   238,   250,  ...,   102,   243, 26344],\n",
            "        ...,\n",
            "        [50256, 27379,  3710,  ...,   392, 22760,   290],\n",
            "        [50256,  6449,   274,  ..., 16567,   422,   606],\n",
            "        [50256,   198,   198,  ...,   307, 39280, 24142]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   705, 18851,  ...,  8215,  6016, 18915],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,    87,    19, 24598],\n",
            "        ...,\n",
            "        [50256,   357, 47487,  ...,   220,   220,  2534],\n",
            "        [50256,  2059,   828,  ...,   386,   948,   272],\n",
            "        [50256,  9881,   287,  ...,    13,  1415,  1391]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 670, Loss: 5.6901\n",
            "tensor([[50256,     9, 19199,  ...,   197,   197,  1640],\n",
            "        [50256,  1266,   284,  ...,   433,  2150, 14268],\n",
            "        [50256,   220,   220,  ...,     9, 19415,    60],\n",
            "        ...,\n",
            "        [50256, 11828,   198,  ...,  2488, 45145, 14134],\n",
            "        [50256,   717,  2415,  ..., 35752,   780,   286],\n",
            "        [50256,   526,   366,  ..., 43207,  1701,   366]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    59,    82,  ...,     8,     3,   290],\n",
            "        [50256,   517,  9584,  ...,  1129,  7131,  1828],\n",
            "        [50256,   532,   532,  ..., 20679,     7,    21],\n",
            "        ...,\n",
            "        [50256,   262,  4326,  ...,    44,  4635,  8710],\n",
            "        [50256,    92,    61,  ...,    11, 14170,   262],\n",
            "        [50256, 36801,    59,  ..., 34846, 36796,     7]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ..., 28166,   290, 28400],\n",
            "        [50256,   262,  5462,  ...,    51, 36048,   198],\n",
            "        [50256,   422,  3292,  ...,   584,  1588,  4736],\n",
            "        ...,\n",
            "        [50256, 30138,    72,  ..., 38227,    92,     7],\n",
            "        [50256, 10392,  2087,  ...,    60,   796,   642],\n",
            "        [50256,    11,   318,  ...,    13, 23279, 13260]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8830,  5651,  ...,    19,   198,   198],\n",
            "        [50256,   508,   198,  ...,  1475,  9948, 38616],\n",
            "        [50256,   600,   284,  ...,   286,   309, 21949],\n",
            "        ...,\n",
            "        [50256, 13209,  7348,  ...,    13,   843,   644],\n",
            "        [50256,  1406,   274,  ...,   587,   287,   262],\n",
            "        [50256,  2061,   318,  ...,  1415,  3104,    30]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4176,    11,  ..., 25457,   326,   520],\n",
            "        [50256,   220,   220,  ..., 11037,   198,   220],\n",
            "        [50256,   475,  4433,  ...,  1587,   245, 47115],\n",
            "        ...,\n",
            "        [50256, 16464, 32874,  ..., 13641, 36806,  7893],\n",
            "        [50256,   392,   836,  ...,   284,  8389,  5737],\n",
            "        [50256,   362, 26365,  ..., 19927,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   284,   423,  ...,  3656, 16156,    11],\n",
            "        [50256,   287,  3575,  ..., 17173,  2704, 14221],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  3163,    89,  ...,   670,   286,   685],\n",
            "        [50256,    12,    41,  ...,    11,  4916,     8],\n",
            "        [50256,  4257,    11,  ...,  6136,  2276,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 11627,   298,  ...,  6407,   611,   262],\n",
            "        [50256, 12227,   640,  ...,    11,  1657,  5002],\n",
            "        [50256, 26077,  1635,  ...,    16, 17394,     9],\n",
            "        ...,\n",
            "        [50256,   351,  1321,  ...,  2616,   338,  7739],\n",
            "        [50256,   220,  5078,  ...,   468,   531,   340],\n",
            "        [50256,  2192,  4952,  ...,  1871,  1862,  1450]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198, 16880,  ...,   447,   251,   416],\n",
            "        [50256,    11,  7613,  ...,   517,   621,   655],\n",
            "        [50256,   468,   655,  ...,   318,  1541,  1762],\n",
            "        ...,\n",
            "        [50256,  7014,   319,  ...,   283,   290,   607],\n",
            "        [50256,   220,   220,  ...,  8054,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1973,   881,  ...,   632,  2492,   470],\n",
            "        [50256,   220,   198,  ...,   330,  7015,  1352],\n",
            "        [50256,   840,   420,  ..., 16964,  1128,   601],\n",
            "        ...,\n",
            "        [50256,  3869,   290,  ...,   262,  2292, 16488],\n",
            "        [50256,   351,  1957,  ...,    13,  4619,   262],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5026, 31589,  ..., 16000,  1391,   198],\n",
            "        [50256,   684,   268,  ...,   286,   262,  5931],\n",
            "        [50256,   220,  2073,  ...,   994,   356,   779],\n",
            "        ...,\n",
            "        [50256,   670,    11,  ...,   257,  8025,   286],\n",
            "        [50256,  1551,   530,  ...,  1460,   543, 17253],\n",
            "        [50256,  1343,  3275,  ...,  2277,   262,  4136]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 680, Loss: 6.4084\n",
            "tensor([[50256,   198,   198,  ...,   198, 30934,   198],\n",
            "        [50256,    77,    11,  ...,  4309,   357,    33],\n",
            "        [50256,  5112,  5610,  ...,    51,   447,   247],\n",
            "        ...,\n",
            "        [50256,  3256,   705,  ...,    11,   685,  8841],\n",
            "        [50256,   290, 15175,  ...,   247,   260,  6294],\n",
            "        [50256,   290,  1660,  ..., 24841,    11,   356]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12,   744,  ...,  1795,    11,  4153],\n",
            "        [50256,   257, 16918,  ...,    11,   326,   339],\n",
            "        [50256,   855, 16208,  ...,   198,   220,   220],\n",
            "        ...,\n",
            "        [50256,    25,  1821,  ...,   287,  1109,    11],\n",
            "        [50256,  2951,  1399,  ...,   198,   198, 31055],\n",
            "        [50256,    26,   220,  ...,  1014,   284, 26898]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4357,   198,  ..., 11250,     8,   198],\n",
            "        [50256,    12, 15464,  ...,   220,   220,   220],\n",
            "        [50256,   351,   262,  ...,   198,   220,   220],\n",
            "        ...,\n",
            "        [50256, 30170,  8536,  ...,  8168,  1165,  3772],\n",
            "        [50256,    11,   262,  ...,  3615,  1230,   284],\n",
            "        [50256, 10052,    28,  ...,   286, 15010,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2951, 15403,  ...,    11,   345,   766],\n",
            "        [50256,  2597,    26,  ...,  4693,    11,   257],\n",
            "        ...,\n",
            "        [50256,  1976,    13,  ...,   796,   532,  3388],\n",
            "        [50256,   402,   398,  ...,   866,   262, 30881],\n",
            "        [50256,   287,  1539,  ..., 12849,    25,  6073]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   314,  2588,  ...,    71,   506, 37834],\n",
            "        [50256,  1271, 11470,  ...,  1248,  2791,   287],\n",
            "        [50256,  1893,   286,  ...,  1297,  2687,   379],\n",
            "        ...,\n",
            "        [50256,  3688,  1022,  ...,  1065,    14,    51],\n",
            "        [50256,   220,   220,  ..., 14245,   625,   428],\n",
            "        [50256,   973,   284,  ...,  5205,   290,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1174, 14095,  ...,    13,    21,   357],\n",
            "        [50256,    74, 26531,  ..., 13907,   312,   876],\n",
            "        [50256, 38430,    31,  ..., 13729,    82,   547],\n",
            "        ...,\n",
            "        [50256, 17583,   329,  ...,   338,  3725,    11],\n",
            "        [50256, 37240,   355,  ...,  4986,   290,   407],\n",
            "        [50256, 10991,    11,  ..., 42367, 12727,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 15437,  2479,  ..., 28481,    11, 13374],\n",
            "        [50256,   290, 24353,  ...,   247,    83,   423],\n",
            "        [50256,  4694,   318,  ..., 17476,  3625,   389],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ..., 20067,  2514, 17563],\n",
            "        [50256, 41334, 17233,  ...,  2620,   355,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  2026,  ...,   326,   262, 48114],\n",
            "        [50256, 43068, 28632,  ...,   220,  1171,  7951],\n",
            "        [50256,   351, 18671,  ..., 32604,     7,  4868],\n",
            "        ...,\n",
            "        [50256,  4847, 20905,  ...,  4427,   318,   284],\n",
            "        [50256,  1142,   448,  ...,   198,   412, 34655],\n",
            "        [50256, 10205,    60,  ...,   452,    13,  2398]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1238,   796,  ...,   198,    12,    19],\n",
            "        [50256,   287,   262,  ...,    11,   366,  5562],\n",
            "        [50256,   220,   220,  ..., 19131,    11,   475],\n",
            "        ...,\n",
            "        [50256,   711,   257,  ...,    71,   393,  3744],\n",
            "        [50256,    82,  3419,  ...,   829,   357,    33],\n",
            "        [50256,   561,  1011,  ...,   287,   262, 32410]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   777,  1903,  ...,   481,  3993,   329],\n",
            "        [50256,    10,     3,  ...,   317,    12, 15654],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    17,    12, 14686],\n",
            "        [50256,  5647, 20662,  ...,   356,  6157, 10742],\n",
            "        [50256,  8585,   262,  ...,     1,   290,   788]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 690, Loss: 5.6557\n",
            "tensor([[50256,   340,    13,  ...,   262,  3012, 20347],\n",
            "        [50256,    14,  4749,  ...,    29,   198,    27],\n",
            "        [50256,   684,    13,  ...,     8,   198,  9288],\n",
            "        ...,\n",
            "        [50256, 14508,  1444,  ...,  1751,   338,   412],\n",
            "        [50256, 30120,  1160,  ...,    13,  2102,    11],\n",
            "        [50256,   366,    40,  ...,   526,   366,    40]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   256,  ..., 38705,  1522, 15061],\n",
            "        [50256,    11,    59,  ...,    18, 47762,    17],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2005,   616,  ...,  2084,    13,   317],\n",
            "        [50256,  1212,   373,  ...,  4523,  1730,  4488]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,  3046,  ...,  4656,   572,   528],\n",
            "        [50256,    13,  1052,  ...,   345,   447,   247],\n",
            "        [50256,    11,  6337,  ...,   318,   262,   289],\n",
            "        ...,\n",
            "        [50256, 27131,   515,  ...,   198,   198, 11158],\n",
            "        [50256,   220,  5510,  ...,   220,   362,   198],\n",
            "        [50256,   197,    15,  ...,  1462,    12,  1169]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 12156,  2412,  ...,   464, 15203,    12],\n",
            "        [50256,  9698,  1906,  ..., 20501,   318,  3058],\n",
            "        [50256,  1183,   651,  ...,   284,   766,   644],\n",
            "        ...,\n",
            "        [50256,   340,  2331,  ...,  4295,  4345,  3234],\n",
            "        [50256,  5696,    13,  ...,   465,   717,  4574],\n",
            "        [50256,   433,  1008,  ...,   198,    25,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   197,   197,  ...,    52,    87,    48],\n",
            "        [50256,    31,    38,  ...,  7634, 30676,   271],\n",
            "        [50256,  5610,   287,  ...,  1022, 19651, 37783],\n",
            "        ...,\n",
            "        [50256,  3128,   329,  ...,   220,   220,   220],\n",
            "        [50256,  2675,  6168,  ...,   286, 18292,   329],\n",
            "        [50256,   198,  2043,  ...,  9138,  1664,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,     7,    17,  ...,     7,    16,    11],\n",
            "        [50256,   287,   262,  ..., 30372, 11973,   460],\n",
            "        ...,\n",
            "        [50256,   925,  1900,  ...,   262, 14498,   286],\n",
            "        [50256,    12,    24,  ...,    33, 15377,    12],\n",
            "        [50256,   198,  8595,  ...,  8704, 15868,   979]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   666, 39280,  ..., 31166, 17034,    90],\n",
            "        [50256,   640,    11,  ...,   247,   447,   247],\n",
            "        ...,\n",
            "        [50256, 23257,  1040,  ...,    26,   201,   198],\n",
            "        [50256,  6568,   546,  ...,   286, 30011,   396],\n",
            "        [50256,  2625, 11487,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ...,   284,   262,   348],\n",
            "        [50256,   318,   262,  ...,   351,   262,  3649],\n",
            "        [50256, 31904,   284,  ...,   960,   292,   287],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   509, 16211,  2926],\n",
            "        [50256,  9387,   287,  ..., 11748,   474,   615],\n",
            "        [50256,   383,  3825,  ...,   618,   314,  1280]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220, 11900,  ...,    16,   284,   604],\n",
            "        [50256,  5447,   287,  ..., 21079, 12181,    11],\n",
            "        [50256, 39960,    13,  ...,   198, 16799,  2091],\n",
            "        ...,\n",
            "        [50256,   329,  1479,  ...,   257,  3290,   290],\n",
            "        [50256,  1627,    11,  ..., 13326,  4179,   286],\n",
            "        [50256,   220,   220,  ..., 28243,    29,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 45035, 30143,  ...,   227, 15166, 21169],\n",
            "        [50256,   338,  9669,  ...,  1310,  3487,   948],\n",
            "        [50256,  4758,  1701,  ...,   319,   534,   835],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   326,   465,  ...,  1114,  1909,   447],\n",
            "        [50256,   290,  3067,  ...,    13, 15894,   484]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 700, Loss: 5.7245\n",
            "tensor([[50256,    40,    92,  ...,    38, 36796,    40],\n",
            "        [50256,  2474,   366,  ...,    40,  1183,  1949],\n",
            "        [50256,  9829,  1812,  ...,    11, 12354,    11],\n",
            "        ...,\n",
            "        [50256,   326,   428,  ...,  8617,  2092,   284],\n",
            "        [50256,  9568, 37671,  ...,   306,    12,   411],\n",
            "        [50256,  3373,  8069,  ...,    13,   952,    14]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5485,    11,  ...,   351,   606,   526],\n",
            "        [50256,   635,  5644,  ..., 15996,   287, 13623],\n",
            "        [50256,  1306,  1178,  ...,   465,  1613,    11],\n",
            "        ...,\n",
            "        [50256,  8148, 29568,  ...,   602,   389,  6157],\n",
            "        [50256, 48453,   262,  ...,   517,   621, 29095],\n",
            "        [50256,    17, 16945,  ...,  1058,    78,    16]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   563,   710,  ...,   319,  8031,   338],\n",
            "        [50256,   640, 33205,  ...,  9520,  5214,    25],\n",
            "        [50256,   286,  7440,  ..., 38834, 47797,   121],\n",
            "        ...,\n",
            "        [50256, 25512,   341,  ...,   262,   327,  9655],\n",
            "        [50256,   281, 21152,  ...,  5210,    11,  1877],\n",
            "        [50256,    11,  6455,  ...,  4981,   286,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    59,   220,   220],\n",
            "        [50256,  1492,   198,  ...,  6634,  7136,  5382],\n",
            "        [50256, 12130,  1153,  ...,  4788,   290,  9021],\n",
            "        ...,\n",
            "        [50256,   284,  1986,  ...,   340,   290,  2989],\n",
            "        [50256,     8,  1174,  ...,   286,   309,    93],\n",
            "        [50256,    39,     3,  ...,    17,     7,    87]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 15374,   805,  ...,   290,  4145,   356],\n",
            "        [50256,  2824,   597,  ...,   329,  9164, 22535],\n",
            "        ...,\n",
            "        [50256,   262,  6762,  ..., 25873,   290,  3739],\n",
            "        [50256,  2526,  4769,  ...,   290,  1535,    12],\n",
            "        [50256, 32017,  6597,  ...,   262,  1854,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 41701,    11,  ...,  1239,   284,   423],\n",
            "        [50256,   257,  2661,  ...,   655,   257,  2068],\n",
            "        [50256, 10296, 18639,  ...,  1546,   198,   198],\n",
            "        ...,\n",
            "        [50256,    63,  1671,  ...,   198,   197,  7783],\n",
            "        [50256,   282,  3743,  ...,   198,  2990,   547],\n",
            "        [50256,  1312,    13,  ...,   298,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2499,   287,  ...,  1200,    11,  2370],\n",
            "        [50256,   511,  1295,  ...,    33,   397, 15158],\n",
            "        [50256,  4307,  1134,  ..., 20111,   306,  1043],\n",
            "        ...,\n",
            "        [50256,   220,   720,  ...,  9806,    92,     3],\n",
            "        [50256,  7177,   351,  ...,   220,   220,   220],\n",
            "        [50256,     7,    21,  ...,   257,  1624,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  4645,    11,  ...,  1191,   554,   383],\n",
            "        [50256,  9626, 48209,  ...,  9457,   866,    11],\n",
            "        ...,\n",
            "        [50256,   287,   262,  ...,    59, 10210,  1747],\n",
            "        [50256,   198,   198,  ..., 21799,    13,   198],\n",
            "        [50256, 10745,   418,  ...,   287, 20218,  2536]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3127,   326,  ...,  9948,    90,    32],\n",
            "        [50256,   734,    13,  ...,  1399,   523,   314],\n",
            "        [50256,   198,   198,  ...,  2612,   286,  6190],\n",
            "        ...,\n",
            "        [50256,   220,   370,  ...,   220,   198,   220],\n",
            "        [50256,  4666,    62,  ...,   220,   220,   220],\n",
            "        [50256,   262,  4248,  ...,   416,   262,  2842]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  2617,  ...,   220,   220,   220],\n",
            "        [50256,   635,  5150,  ..., 27301,    60,   290],\n",
            "        [50256,  8929,    61,  ...,    12,    34,   324],\n",
            "        ...,\n",
            "        [50256, 24846, 16177,  ..., 17953,     7, 14478],\n",
            "        [50256,  2107,   329,  ..., 22123,   526,   366],\n",
            "        [50256,   749,  1807,  ...,    87,   532,  1467]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 710, Loss: 5.2369\n",
            "tensor([[50256,    82, 18477,  ...,    11,    82, 18477],\n",
            "        [50256,   691,   983,  ...,   286,   262,  1938],\n",
            "        [50256,   725,    68,  ..., 24247,  5633,   784],\n",
            "        ...,\n",
            "        [50256,   262,   886,  ..., 10980, 32460,  1108],\n",
            "        [50256,  5353,   287,  ...,    11,   547,   262],\n",
            "        [50256,  2625,  4310,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1398,   287,  ...,  6672,    11,   290],\n",
            "        [50256,  3704,   286,  ..., 28364,    11,  1566],\n",
            "        [50256,   642,   447,  ..., 30109,    31,    33],\n",
            "        ...,\n",
            "        [50256, 17124,    13,  ...,   220,   938, 26545],\n",
            "        [50256, 10868,   352,  ...,    11,   479,    25],\n",
            "        [50256, 21828,    92,  ...,    93,    45,    93]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    55,     3,  ...,   720,    41,  3467],\n",
            "        [50256,   259,   318,  ..., 32031,  4778,   416],\n",
            "        [50256,  4928,   428,  ...,   290,   423,   262],\n",
            "        ...,\n",
            "        [50256,   511,   555,  ..., 21487,   284, 34449],\n",
            "        [50256,   767,  4309,  ..., 29101,   376,    13],\n",
            "        [50256,  2488, 17143,  ...,   357, 28920, 16763]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    25,   198,  ...,  4028,    13,   357],\n",
            "        [50256,  3859,   198,  ...,   466,   597,   670],\n",
            "        [50256,  1568,   618,  ...,   314,   373,  8970],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ..., 22446,  1136, 10100],\n",
            "        [50256,  6186,   447,  ...,   287,   262,   995],\n",
            "        [50256,   284,  2869,  ...,  2739,    11, 17634]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5004,  1771,  ...,  3580,   373,  6157],\n",
            "        [50256,   532,   257,  ...,    17, 11709,  3467],\n",
            "        [50256,  4947,   973,  ...,    11,   262, 32799],\n",
            "        ...,\n",
            "        [50256,   220, 14381,  ...,   220,   220,   220],\n",
            "        [50256,   257,  4941,  ...,   281,  7097,  3335],\n",
            "        [50256,   198,   198,  ...,  2157,   968, 34723]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,  4101],\n",
            "        [50256,  9539,   286,  ...,   290,   369,  3919],\n",
            "        [50256,   278,   351,  ...,   389,   262,  1388],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1378,  1102,  ...,  1008,   264,   516],\n",
            "        [50256,   198,    40,  ..., 21575,     7, 14781]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1343,   299,  ...,   289,     7,    70],\n",
            "        [50256,   220,  2488,  ...,  6030, 20180, 37835],\n",
            "        [50256,   262, 22106,  ...,   290,   294,  8226],\n",
            "        ...,\n",
            "        [50256,   287, 13310,  ...,   389,  1115,   517],\n",
            "        [50256,   272, 12342,  ...,   589,    13,  2949],\n",
            "        [50256,    11,  8687,  ...,    11,  8687,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   737, 21048,  ...,   611,     7, 19545],\n",
            "        [50256,  1891,    13,  ...,     7, 22510,    62],\n",
            "        [50256,   422,   262,  ...,   262,  3504,  1398],\n",
            "        ...,\n",
            "        [50256,   484,   836,  ...,   679,   561,  8212],\n",
            "        [50256,    11,  8148,  ...,  1245, 18268,   287],\n",
            "        [50256, 48417, 17154,  ...,  2635,  2097,   851]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,  3003,   198,  4299],\n",
            "        [50256,   259,   979,  ..., 27313,    25, 34458],\n",
            "        [50256, 17724,  9922,  ...,   284, 47873,  5443],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  2618,    29,   198],\n",
            "        [50256,   198,  4242,  ...,   220,   220,   220],\n",
            "        [50256,  4339, 14195,  ...,  1410,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 11376,   810,  ...,   368,   888,   338],\n",
            "        [50256,   262, 17507,  ...,   198, 11627,   974],\n",
            "        [50256,   198,   198,  ...,  1174,    20,  1174],\n",
            "        ...,\n",
            "        [50256,  2513,  1363,  ...,   546,   340,     0],\n",
            "        [50256,  1176,   284,  ...,   410,    13,  5007],\n",
            "        [50256, 25152,  2004,  ...,   366,  1532,   326]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 720, Loss: 6.4888\n",
            "tensor([[50256,  5891,  4409,  ...,   198,  3824,    13],\n",
            "        [50256,    66,    14,  ...,   220,   220,   220],\n",
            "        [50256,   198,   220,  ..., 19606,   287,   262],\n",
            "        ...,\n",
            "        [50256,   290,   362,  ...,  7034,    13,  8227],\n",
            "        [50256,   220,   220,  ...,    27,   657,    13],\n",
            "        [50256,  2919,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3244, 32382,  ...,  2617, 27363,   509],\n",
            "        [50256, 10669, 13247,  ...,  1136, 47139,    34],\n",
            "        [50256,   779,   402,  ...,   705,    41,   259],\n",
            "        ...,\n",
            "        [50256,   259,  3467,  ...,    11, 39280, 13290],\n",
            "        [50256,   282,  7095,  ...,   357,  2780,  7200],\n",
            "        [50256,    72,  1424,  ...,   286,   606,   355]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   428,  9313,  ...,  3000,   296,  1701],\n",
            "        [50256,  1111,  3640,  ..., 30109,    31,    33],\n",
            "        [50256,    53,  1000,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   466,   262,  ...,   262, 20897,    11],\n",
            "        [50256,  3977,  3888,  ...,  3977,    13,   198],\n",
            "        [50256,   286,  6970,  ...,  7955,   287,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   857,   407,  ...,   884,   355,   262],\n",
            "        [50256,   220,   220,  ...,   513,   220,   220],\n",
            "        [50256,  3270,    11,  ...,   657,    87, 25150],\n",
            "        ...,\n",
            "        [50256,  3099,  5454,  ...,     5,  3672,  2625],\n",
            "        [50256,   262, 37968,  ...,  2615,    13,   198],\n",
            "        [50256,   318,  1593,  ...,   444,    11,   777]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    25,   220,  ...,  3709,    13,   198],\n",
            "        [50256,   329,   932,  ...,   262,   779,   286],\n",
            "        [50256,   403, 12523,  ...,   549, 19724,   883],\n",
            "        ...,\n",
            "        [50256,   314,   651,  ..., 10629,   284,   923],\n",
            "        [50256,  2656, 14250,  ...,  2937,    47, 10468],\n",
            "        [50256,  1279,   262,  ...,  7308,   357, 34831]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2904,  3417,  ...,  2791,   198,    47],\n",
            "        [50256,   198, 23330,  ..., 11018,  9948,    90],\n",
            "        [50256, 10348,  5721,  ...,  2188,  7716,     1],\n",
            "        ...,\n",
            "        [50256,    33,  3467,  ...,   720,    33,  3467],\n",
            "        [50256,    14,  2231,  ..., 25708,  5366,   286],\n",
            "        [50256, 19415,  4357,  ...,   329,   262,  7625]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  2695,  ...,   220,   220,   220],\n",
            "        [50256,  9509,   507,  ...,  5657,   445,    13],\n",
            "        [50256,    92, 47113,  ...,   383,  2512,    12],\n",
            "        ...,\n",
            "        [50256, 23330,    59,  ..., 32239, 28015,  1142],\n",
            "        [50256,   197, 41068,  ..., 41068,    17,    26],\n",
            "        [50256,   338,  4387,  ...,  4808,    41,  2507]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   406,  3087,  ...,  4974,    13,   198],\n",
            "        [50256,   198, 14231,  ...,    13,   198,   198],\n",
            "        [50256,    59, 28803,  ...,    25, 32382,    47],\n",
            "        ...,\n",
            "        [50256,    11,   543,  ...,   531,    25,   705],\n",
            "        [50256,   198,  1635,  ..., 11708,    62, 16177],\n",
            "        [50256,   651,   612,  ...,   547, 18829, 21490]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    92,    17,  ...,    17, 47113,   720],\n",
            "        [50256,   357,  8841,  ...,     7,    72, 36911],\n",
            "        [50256,  3707,    13,  ...,  1271,   290, 19440],\n",
            "        ...,\n",
            "        [50256, 44036,   329,  ...,  3691,    13,   262],\n",
            "        [50256, 15028,   198,  ...,    11, 12681,  1535],\n",
            "        [50256,  2456,    11,  ...,  8811,  5884,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1805,   262,  ...,  1262,  4580,    14],\n",
            "        [50256,   198,    19,  ...,    14, 10232,   737],\n",
            "        [50256,  1064,   616,  ...,   198,  1635,   770],\n",
            "        ...,\n",
            "        [50256,    12, 33704,  ...,  4031,   284,  1205],\n",
            "        [50256,    19,   427,  ...,   492,  4808,  1477],\n",
            "        [50256,  4479,   410,  ...,   284,   884,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 730, Loss: 5.5874\n",
            "tensor([[50256, 18182,   351,  ...,  2390,    25,   628],\n",
            "        [50256,   220,   406,  ...,   220,   220,   220],\n",
            "        [50256,    61, 27007,  ..., 10662, 36796,     7],\n",
            "        ...,\n",
            "        [50256, 21881,  4221,  ..., 28311,   262, 32595],\n",
            "        [50256,    11,   339,  ...,  5003,    13,   632],\n",
            "        [50256,  2718,  3901,  ...,   657,    87,  2816]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   554,  2276,  ...,  1238,   357,    70],\n",
            "        [50256, 40091, 13389,  ..., 12962,   290,   357],\n",
            "        [50256,    11, 13755,  ...,    13, 21699,   198],\n",
            "        ...,\n",
            "        [50256,  2760,     7,  ...,   796,   720,  5589],\n",
            "        [50256,    61,    58,  ...,   832, 42465, 50124],\n",
            "        [50256,   351,   264,  ...,  3108,  6644, 29509]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7285,    88,  ...,  1279, 47546, 32517],\n",
            "        [50256,   291,  8655,  ...,   262,   314,  8577],\n",
            "        [50256,   329, 17909,  ...,   284,   262, 19239],\n",
            "        ...,\n",
            "        [50256,    13,   198,  ...,   905,    13,   843],\n",
            "        [50256,   475,   460,  ...,  2188,   519,    12],\n",
            "        [50256,   262,  2496,  ...,   479,  6739,   554]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2199,   278,  ..., 27712,    13,  5420],\n",
            "        [50256, 18251,    11,  ...,   437,   666,  1108],\n",
            "        [50256,    13,  6682,  ...,  5004, 25601, 33543],\n",
            "        ...,\n",
            "        [50256,   287,  6273,  ...,  3693,    60,    90],\n",
            "        [50256,    65,    19,  ..., 40538,   784,  1367],\n",
            "        [50256,  2402, 16937,  ..., 20608,    28,    74]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,  1281,  ...,   923, 19493,   878],\n",
            "        [50256,   857,     0,  ...,   286,   257,  1402],\n",
            "        [50256, 13414, 30909,  ..., 38361, 40941, 48962],\n",
            "        ...,\n",
            "        [50256,   356, 10667,  ...,  1377, 14304,   355],\n",
            "        [50256,  3467, 34846,  ..., 36796,    42, 18477],\n",
            "        [50256,    13,   887,  ...,   281,  1468, 26536]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   334,  ...,   220,   334,     7],\n",
            "        [50256,  1057,   257,  ...,    29, 23986,   449],\n",
            "        [50256,  2576,  1625,  ...,  9527,  8107,   373],\n",
            "        ...,\n",
            "        [50256,     0,  1119,  ...,   340,   925,   262],\n",
            "        [50256,  3605,    11,  ...,   434, 34547,   262],\n",
            "        [50256,   750,   287,  ...,  4436,   393,  1448]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   340,  ...,   314,   892,    13],\n",
            "        [50256,   884,   257,  ...,   287,  1566,   691],\n",
            "        [50256,  3388,  4531,  ...,    25,   657,   657],\n",
            "        ...,\n",
            "        [50256,   357,  5304,  ...,  1849,     7,    18],\n",
            "        [50256,   508,  1625,  ...,   373, 36045,  3777],\n",
            "        [50256,   262,   362,  ..., 23133,    68,  7058]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4008,    14,  ...,  2078, 29006,    12],\n",
            "        [50256,   284,  7048,  ..., 13238,   287,   262],\n",
            "        [50256, 16142, 20375,  ...,    11, 12466,   118],\n",
            "        ...,\n",
            "        [50256,    56,    28,  ...,   736,   284, 11089],\n",
            "        [50256,    37,  1722,  ..., 11423, 23462,  9297],\n",
            "        [50256,   287,   616,  ...,   922,   636,    12]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   311,    13,  ...,  7410,  5690,   284],\n",
            "        [50256,    24, 12906,  ..., 28896,    12,    83],\n",
            "        [50256,  1139,  8511,  ...,    13, 17877,   815],\n",
            "        ...,\n",
            "        [50256,    67,    23,  ...,   278,   510,   262],\n",
            "        [50256,   257, 17853,  ...,  6478,   526,   198],\n",
            "        [50256,   357,  4304,  ..., 20679, 32590, 45722]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6469,   198,  ...,  5420,    12,  4906],\n",
            "        [50256, 31380,    12,  ..., 26378,   286,  1737],\n",
            "        [50256,   262,   327,  ...,  1341, 27428,   832],\n",
            "        ...,\n",
            "        [50256, 14848,    37,  ...,  1776,   201,   198],\n",
            "        [50256,   262, 21752,  ...,   262, 21752,   714],\n",
            "        [50256,  2363,    19,  ...,   287,  9530,    12]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 740, Loss: 5.8353\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1780,  1012,  ...,    50,    13,   767],\n",
            "        [50256,   561,   423,  ...,  2184, 27383,  3481],\n",
            "        ...,\n",
            "        [50256,  3155,   286,  ...,    13, 13908,  8479],\n",
            "        [50256,   287, 44741,  ..., 11843,    13,  6288],\n",
            "        [50256,  1849, 21533,  ...,   351,   257,  6317]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6751,  4003,  ...,   287,   262,  2181],\n",
            "        [50256,    13,   317,  ...,   259, 19628,     7],\n",
            "        [50256, 38117, 23862,  ..., 18477,    49, 23330],\n",
            "        ...,\n",
            "        [50256,  1661,    11,  ...,   251,   389,  1938],\n",
            "        [50256,   326, 14293,  ...,    12, 17319,  9965],\n",
            "        [50256,   355,   257,  ...,  1804,   640,   287]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   352,    13,  ..., 11756, 18305,   516],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   273,   602,  ...,  2383,  1989,   286],\n",
            "        ...,\n",
            "        [50256,    62,  4879,  ...,  1309,   796,   642],\n",
            "        [50256,  1471,  1326,  ...,     6,  2058,   422],\n",
            "        [50256, 10156,   284,  ..., 31944,    90,    16]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2168,    11,  ...,    13, 24006,  5432],\n",
            "        [50256,  5149,  2241,  ...,   706,   812,   286],\n",
            "        [50256,  2897,   257,  ...,    13,  2080,   663],\n",
            "        ...,\n",
            "        [50256,    11,   440,  ...,     6,  3041,  1030],\n",
            "        [50256,  1252,   382,  ...,   249,    75,    11],\n",
            "        [50256,   319,   345,  ...,   257,  1588,  5873]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   279, 29090,  ...,  4604,    68,   773],\n",
            "        [50256,   720,    16,  ...,    13,  5961,  1605],\n",
            "        [50256,  6622,  2081,  ..., 45136,   832,   262],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  3669, 35430,   198],\n",
            "        [50256, 21672,    25,  ...,    58,    83,    60],\n",
            "        [50256,    82,   422,  ...,   828,  5051,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   407,    13,  ...,   262,  8300,  4905],\n",
            "        [50256,  1377, 37994,  ...,   851,  1390, 44946],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   720,    77,  ...,    59, 31166, 17034],\n",
            "        [50256,  1590,    11,  ...,  3432,   284,   262],\n",
            "        [50256, 11351,  2052,  ..., 31667,    58,    20]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1314,    14,  ...,   428,  2583,   417],\n",
            "        [50256,   612,  1254,  ...,   645,  4330,  3387],\n",
            "        [50256,   259, 19628,  ...,    76,    92, 23330],\n",
            "        ...,\n",
            "        [50256, 23048,   373,  ...,   262,  4854,   326],\n",
            "        [50256,     8,   366,  ...,   737,  1400,  3580],\n",
            "        [50256,    61, 31478,  ...,  3264, 34657,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2937,    34,  ...,  6168,   290,   262],\n",
            "        [50256,  2043,   405,  ...,    13,   383,  6291],\n",
            "        [50256,   269,   318,  ...,    71,  1174,  1157],\n",
            "        ...,\n",
            "        [50256,  4537,  8264,  ...,   220,   220,   220],\n",
            "        [50256,   198, 21481,  ...,     2,  5837,   283],\n",
            "        [50256,   788,   617,  ...,   250,  2514,  1265]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 23362,    92,  ...,   290, 17242,     7],\n",
            "        [50256,   405,  4846,  ...,  4846, 28896,    12],\n",
            "        [50256,  8141,  6089,  ..., 16715,   422,   262],\n",
            "        ...,\n",
            "        [50256,   371,  1921,  ..., 17615,    34,  3722],\n",
            "        [50256,  1174,    17,  ...,    90,    92,   685],\n",
            "        [50256,  3581, 10478,  ..., 45687,    50, 14603]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1016,   284,  ...,   326,   966,   287],\n",
            "        [50256,   198, 21017,  ..., 11817,   346,    13],\n",
            "        [50256,   319,  7125,  ...,  1104, 38581,  3477],\n",
            "        ...,\n",
            "        [50256,    59,     9,  ...,  2808,    13,    18],\n",
            "        [50256,   220,   220,  ...,  9723, 20693,   198],\n",
            "        [50256,   262,  2587,  ...,   326,   262, 44162]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 750, Loss: 4.9983\n",
            "tensor([[50256,  2747, 21361,  ...,   262, 21792,   347],\n",
            "        [50256,  1297,   262,  ..., 47321,  3426,   642],\n",
            "        [50256,    11,   309,  ...,   614,   284,   422],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ..., 21725,   311,  3525],\n",
            "        [50256,  3467,  3506,  ...,  3506,    59, 42369],\n",
            "        [50256,  3568,   287,  ..., 13208, 16031,   607]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   327,  ..., 15696,   286,   383],\n",
            "        [50256,    64,    12,  ...,    63,   198,   198],\n",
            "        [50256, 23518,  2751,  ...,  8493,   287,   262],\n",
            "        ...,\n",
            "        [50256,   351,  2461,  ...,   355,   337,  2696],\n",
            "        [50256,   286,  1393,  ...,   220,   220,   220],\n",
            "        [50256,    13, 16320,  ...,    13,  1849,  3856]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2271,    13,  ...,   262,  6099,  3977],\n",
            "        [50256, 17852, 22312,  ...,    27,     4,    31],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  7248,    25,   366],\n",
            "        [50256,   373,   257,  ...,   645,  2126,   828],\n",
            "        [50256,   389,  3221,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ..., 21597,   599,   506],\n",
            "        [50256,  2185,  8607,  ...,   156,   110,   123],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   284,   262,  ...,   572,   319,   502],\n",
            "        [50256,  3051,   290,  ...,   486, 31020,    60],\n",
            "        [50256,   435,    12,  ...,   317,  1921,   287]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   611,   262,  ...,   286,   257, 17372],\n",
            "        [50256,    25, 11291,  ..., 16151,     2,    50],\n",
            "        [50256,   351,   428,  ...,   509,  6557,   380],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1267,  1391,  ...,   796,  1635,  6738]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 27778,   198,  ...,    11,   383,     1],\n",
            "        [50256,   484,   481,  ...,   547,  1263,    25],\n",
            "        [50256,   329,   309,  ...,  5332,  2920,    12],\n",
            "        ...,\n",
            "        [50256,    34,    13,  ...,  9309,    11, 37576],\n",
            "        [50256,    13,  2188,  ...,  5450,  1378, 12567],\n",
            "        [50256,   366,   271,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13, 18087,  ...,  1034, 32820,   481],\n",
            "        [50256,  6736,  7923,  ...,   198,  1026,   561],\n",
            "        [50256,  7874,    19,  ...,   290, 22498,    26],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,  3349,    11,   412],\n",
            "        [50256,  6157,   281,  ...,    65,   357,   464],\n",
            "        [50256,   319, 21277,  ...,  3009,    25,  2488]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9776,  1760,  ...,    13,   513,    67],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    13,   198,  ...,   986, 10755, 14504],\n",
            "        ...,\n",
            "        [50256,    22, 20679,  ...,    67,  1174,     7],\n",
            "        [50256,  3987,  2067,  ..., 25609, 18604,   198],\n",
            "        [50256,    51,    13,  ...,    13, 45020,   578]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,   636,  ...,    82,    13, 25024],\n",
            "        [50256,   534,  2298,  ...,   284,   534,  2882],\n",
            "        [50256,  5178,    12,  ...,  7268, 15139,    99],\n",
            "        ...,\n",
            "        [50256,    66,    62,  ...,  6494,     2,    64],\n",
            "        [50256,  8747,    11,  ...,   818,   477,  2663],\n",
            "        [50256,  1687,  2005,  ...,  4918,  1969,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,    47,  ..., 31944,    90,    89],\n",
            "        [50256,    13,   198,  ..., 14083,   428,   416],\n",
            "        [50256,  9002,  4249,  ...,   257,  4917,    26],\n",
            "        ...,\n",
            "        [50256,   318,  6393,  ...,    49, 22182,  1849],\n",
            "        [50256,   198,   198,  ...,    13,   556,    81],\n",
            "        [50256,  7747,   286,  ..., 12023,    11,  4295]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 760, Loss: 5.9906\n",
            "tensor([[50256,    13,   952,  ...,  4615,    13,  1002],\n",
            "        [50256,   287,   262,  ...,  6142,  8405,    13],\n",
            "        [50256,   383,     1,  ...,   198, 28827,   385],\n",
            "        ...,\n",
            "        [50256, 11454, 19039,  ...,    66,   445, 14817],\n",
            "        [50256,   198,    27,  ...,  7635,    13, 13812],\n",
            "        [50256,   222, 11976,  ..., 24231,   222, 28225]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  2425,  1828,  ...,   685,    35,  2265],\n",
            "        [50256,   657, 27705,  ..., 20986,  5512,   198],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    12, 48916,  ...,   286,   582,    11],\n",
            "        [50256,   627,   668,  ..., 34743,  6608,   286]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ..., 25968, 33616, 12837],\n",
            "        [50256,    37,  4872,  ...,     9,    15,    13],\n",
            "        [50256,   379,  3598,  ..., 27283,   784,   314],\n",
            "        ...,\n",
            "        [50256,   796,   362,  ...,   318,   655,   257],\n",
            "        [50256,    11,    76,  ...,    59, 11018,  9948],\n",
            "        [50256,    23,  3695,  ...,    13,    54,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   402,  5446,  ...,   220,   220,   220],\n",
            "        [50256,   290,   783,  ...,   373,  1705,   326],\n",
            "        ...,\n",
            "        [50256,  5512,    59,  ..., 12962,   356,   651],\n",
            "        [50256,  4625,  1370,  ..., 38491,   286,   262],\n",
            "        [50256,   220,   220,  ...,  3400,  6448,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,  3265,   286,   262],\n",
            "        [50256,   326,   314,  ...,    75,  3467, 14323],\n",
            "        [50256, 26604,  1315,  ..., 10638,  8492,    13],\n",
            "        ...,\n",
            "        [50256,     8,  1391,  ..., 11028, 12885,    26],\n",
            "        [50256,   287,  4330,  ...,  8476,   338, 17918],\n",
            "        [50256,  5050,    13,  ...,  8655,   311,    18]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    17,    87,  ...,  4417,   284,  8335],\n",
            "        [50256,  4610,   311,  ...,  4758,   318,  1690],\n",
            "        [50256,   257,  7540,  ..., 16069,   422, 24584],\n",
            "        ...,\n",
            "        [50256,  8873,  5241,  ...,    25,  1983,  3122],\n",
            "        [50256,   281, 29605,  ...,  1388,  9052,   286],\n",
            "        [50256,   898,  1981,  ...,  2138,   588,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   884,   326,  ..., 38165,     7,    87],\n",
            "        [50256, 13141,   546,  ...,   351, 12183, 21748],\n",
            "        [50256,    74,    92,  ...,  2035,  2029,   393],\n",
            "        ...,\n",
            "        [50256,  2219,  8513,  ...,  3210,   583,    72],\n",
            "        [50256,   337,  5446,  ...,    35,  1080,    13],\n",
            "        [50256,   257,  2912,  ...,  4083,   317,  3092]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 15163, 40181,  ..., 15816,  6833,    11],\n",
            "        [50256,   526,   366,  ...,   526,   366,  1026],\n",
            "        [50256,  9145, 30309,  ...,   327, 11731,    19],\n",
            "        ...,\n",
            "        [50256,    40,    12,  ..., 13664,   279,  4310],\n",
            "        [50256,  1589,   410,  ...,   400,  5849, 38001],\n",
            "        [50256,     8,   220,  ..., 38831,    11, 38867]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    33,  4944,  ...,   293,   400,   338],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   284,  1630,  ...,  5447,   287,   262],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    14,  4967,  ...,    31,  9419,    17],\n",
            "        [50256,    11,  3573,  ...,   284,  1104,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1016,   284,  ...,  2810,   345,   460],\n",
            "        [50256,   469,    80,  ..., 23330,    73,    11],\n",
            "        [50256,   503, 36074,  ...,   899,  3369,   257],\n",
            "        ...,\n",
            "        [50256,  2930,    79,  ...,   561,   423,   587],\n",
            "        [50256,  4877,  9348,  ...,    14, 12942, 21855],\n",
            "        [50256,   259,  8893,  ..., 33080, 12737,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 770, Loss: 6.4747\n",
            "tensor([[50256,    12,  5715,  ...,   262,   662,   268],\n",
            "        [50256,  2256,  2123,  ...,  1826,   262,  2457],\n",
            "        [50256,  3277,   338,  ...,    53,   726,  1095],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   111,    11,  ...,  4834,    62,    22],\n",
            "        [50256,   905,   287,  ..., 28596,   257,  1402]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1867,   338,  ...,   257,    30,   198],\n",
            "        [50256,   737, 12642,  ...,   307,  7997,   416],\n",
            "        [50256,    68, 47662,  ...,  1143, 37350,  8495],\n",
            "        ...,\n",
            "        [50256,    82,   318,  ...,  8698,   584,   779],\n",
            "        [50256,  9871, 23168,  ...,  3513,   318,  8793],\n",
            "        [50256,    81,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3968,    11,  ...,   198, 17932,   278],\n",
            "        [50256,   284,   423,  ...,   198,   198,   464],\n",
            "        [50256,   262, 30725,  ..., 30330,   416, 11983],\n",
            "        ...,\n",
            "        [50256,   290,   262,  ...,   329, 10231,  3602],\n",
            "        [50256,  8006,   465,  ...,    13,   198,   198],\n",
            "        [50256,   373,  6157,  ...,    13,    16, 29565]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  4916,  ...,    16,    62,  4834],\n",
            "        [50256,    59,     7,  ...,  8148,    11, 18074],\n",
            "        [50256,   366, 41494,  ...,    13,   554,  1502],\n",
            "        ...,\n",
            "        [50256,    40, 49671,  ...,  1719,   616,  1336],\n",
            "        [50256, 14436, 48475,  ..., 15641,   422,   657],\n",
            "        [50256,   471,   286,  ...,    13,  4619,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2611,     3,  ...,    13,  1849, 39961],\n",
            "        [50256,   371,  4728,  ...,   308,  1530,   286],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,    62, 22866,  ...,   220,   220,   220],\n",
            "        [50256,  2134,   326,  ...,  1111,  4899,   389],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   366,  1701,  ...,   366,  1701,   366],\n",
            "        [50256,  7511,  2165,  ...,    22,  1343, 13841],\n",
            "        [50256,   832,   514,  ...,  2368,  2230,    13],\n",
            "        ...,\n",
            "        [50256,  9361,   284,  ..., 13096,   340,   198],\n",
            "        [50256, 19737, 14027,  ...,   286,  1877,  2974],\n",
            "        [50256,    90,    34,  ...,    62,    16, 47113]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   407,  3595,  ...,  1893,    11,  1864],\n",
            "        [50256,  2625, 11487,  ...,   220,   220,   220],\n",
            "        [50256,   326, 39280,  ...,    59,   538, 18217],\n",
            "        ...,\n",
            "        [50256,  7842,  9229,  ..., 32551,    12, 10414],\n",
            "        [50256,  3381,   389,  ...,   554,  1948,    11],\n",
            "        [50256,   220,   220,  ...,   312, 13924,   540]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2601,   682,  ...,  1138,   439,   404],\n",
            "        [50256, 27611,   262,  ...,  2178,  3219, 11898],\n",
            "        [50256,    17, 19953,  ...,  2716,   379,   262],\n",
            "        ...,\n",
            "        [50256, 28199,    13,  ...,  8020,   470,  3750],\n",
            "        [50256,   220,  1171,  ..., 29668,    13,  1136],\n",
            "        [50256,    62,    34,  ...,   198,  1639,   460]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 47505,    39,  ...,   357,    66,     8],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 36796,    19,  ...,    18,    92,    17],\n",
            "        [50256,   220,   220,  ...,   290,  6155,   284],\n",
            "        [50256,  1965,    11,  ...,   309,    12, 15600]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   422,  2961,  ..., 27008,  2173,   503],\n",
            "        [50256,   338,  1521,  ...,   674,  4439,    11],\n",
            "        [50256, 39280, 31361,  ...,   262,   720, 36796],\n",
            "        ...,\n",
            "        [50256,   284,  2728,  ...,   484,   460,   307],\n",
            "        [50256,  8548,   282,  ...,   198,   198,  1129],\n",
            "        [50256,  1989,  4144,  ...,    13,   775,  5295]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 780, Loss: 6.2806\n",
            "tensor([[50256,  4533,   369,  ...,  4533,   369,  8591],\n",
            "        [50256, 43718,   115,  ...,   222,   120, 32573],\n",
            "        [50256,   513,    13,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 30328,   720,  ...,   318,   257,  2579],\n",
            "        [50256,   220,   220,  ..., 19076,  6624, 29369],\n",
            "        [50256,   357,  4309,  ...,     8,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    58,    19,  ...,    13,  1318,   547],\n",
            "        [50256, 20015,   236,  ...,   223,   248, 49035],\n",
            "        [50256,    52, 23330,  ...,    90,    39,    92],\n",
            "        ...,\n",
            "        [50256,    11,   471,  ...,  4354,  6142, 17262],\n",
            "        [50256,    42,  1018,  ...,   262,  2071,   286],\n",
            "        [50256,   338,  4506,  ...,    14,  9804,   287]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3007,   326,  ...,    25,   198,   198],\n",
            "        [50256, 39555,   803,  ...,  2259,  9720,   287],\n",
            "        [50256,   220,   220,  ..., 16177, 26687,    29],\n",
            "        ...,\n",
            "        [50256,   290,   788,  ...,   262,  2723,  2393],\n",
            "        [50256,   940,    11,  ...,    13,  2724,    26],\n",
            "        [50256,  1782,   198,  ...,     8,   269, 10951]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6614,  2627,  ...,   314,  1053,  1282],\n",
            "        [50256,   220,   198,  ...,  1640,   564,   250],\n",
            "        [50256,   383,  3290,  ..., 10747,  4329,  1683],\n",
            "        ...,\n",
            "        [50256,   257,  2888,  ...,  1839,   262,  4165],\n",
            "        [50256,  5672, 14121,  ...,    12, 42484,   318],\n",
            "        [50256,    69, 42421,  ...,   198,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5572,    47,  ..., 30102,    74,  1058],\n",
            "        [50256,  2327,   285,  ...,  1237,   684, 20429],\n",
            "        [50256,   257, 28294,  ...,  2657,  2137,  1683],\n",
            "        ...,\n",
            "        [50256,    72, 25908,  ...,   479, 20975,   347],\n",
            "        [50256,   329,   520,  ...,   273,  3805,   606],\n",
            "        [50256,  3993,  6482,  ...,   286,  1692,  1767]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   468,  ...,    13,   383,  2033],\n",
            "        [50256,   262, 11192,  ...,  2327,    30,   198],\n",
            "        [50256,   250,  1870,  ...,    30,   770,   318],\n",
            "        ...,\n",
            "        [50256,  5674,  1503,  ...,   198, 42615,   560],\n",
            "        [50256,   553,   366,  ...,  1906, 18781,    11],\n",
            "        [50256, 24861,   245,  ...,   286,   262,   327]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,  7740,  ...,   198,   447,   250],\n",
            "        [50256,  1895,  1271,  ...,   262,  1988,   287],\n",
            "        [50256,  1279,  8841,  ...,   929,  4976,    62],\n",
            "        ...,\n",
            "        [50256, 14312,  2569,  ...,   198,   198,  1135],\n",
            "        [50256,   262, 10649,  ...,    11,   884,   257],\n",
            "        [50256,   262, 27458,  ...,  8313,    11,   543]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   351,   262,  ...,  1364,   290,   314],\n",
            "        [50256,   318, 27464,  ...,   355,   287, 12138],\n",
            "        [50256,     1,  6376,  ...,  4531, 25270, 27728],\n",
            "        ...,\n",
            "        [50256,   281, 13181,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   286,  ...,  9085,  8136,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   366,  3987,  ...,   366,  1639,  1612],\n",
            "        [50256,   325,     7,  ...,   198,  2601,   333],\n",
            "        [50256,   198,   198,  ...,    13,  1270,  4426],\n",
            "        ...,\n",
            "        [50256,   198,   220,  ...,   220,   220,   220],\n",
            "        [50256,   383,   627,  ...,    13,   318,  4855],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9695,    25,  ...,   986,   198,   198],\n",
            "        [50256,   327,  2389,  ...,   198,   220,  3373],\n",
            "        [50256,  1343,   532,  ...,    18,    13,  3914],\n",
            "        ...,\n",
            "        [50256,   638,  1329,  ...,   257,  1510,  8872],\n",
            "        [50256,   657,    87,  ...,   198,   197, 45214],\n",
            "        [50256,   418,   920,  ..., 21504, 24419,  4951]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 790, Loss: 6.2496\n",
            "tensor([[50256,  7733,   481,  ...,   416,   262,  3708],\n",
            "        [50256,   440,  1455,  ...,   706, 15987, 21841],\n",
            "        [50256, 30072, 47113,  ..., 18640,  1255,    11],\n",
            "        ...,\n",
            "        [50256,   340,    11,  ...,  3198,  1110,    11],\n",
            "        [50256,   780,   356,  ...,    11,  2106,   290],\n",
            "        [50256,   526,   198,  ...,   346,  1965,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257, 45574,  ...,   257, 44457,    11],\n",
            "        [50256, 21242,   422,  ...,   669,    12,  1238],\n",
            "        [50256,   362,    35,  ..., 20878,    12, 17223],\n",
            "        ...,\n",
            "        [50256, 21226,    11,  ...,   670,    30,   198],\n",
            "        [50256,    22,    13,  ...,   357,    64,     8],\n",
            "        [50256,    31,  8726,  ...,    27,    87,  6649]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 23330,    72,  ..., 31361, 23330,    15],\n",
            "        [50256,   257,  9321,  ..., 23041,   525,   468],\n",
            "        [50256,   197,   197,  ..., 37796,    13,   198],\n",
            "        ...,\n",
            "        [50256,   526,   366,  ...,   366,  2949,    11],\n",
            "        [50256, 19502,  1220,  ...,    11,  1205,  3186],\n",
            "        [50256,  5176,     0,  ...,   510,   257,  1310]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 32482,  1619,  ...,    11, 17086,  2529],\n",
            "        [50256,  1468, 29039,  ...,    13, 29232,   325],\n",
            "        [50256,  1271,   621,  ...,    11,   547, 49966],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   352,    13,  ...,    14,   535,  3693],\n",
            "        [50256,  9554,    11,  ...,  1871,   513,    35]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9262,  2672,  ...,  1029,  2866,   357],\n",
            "        [50256,   257,  7172,  ...,   612, 27606,   318],\n",
            "        [50256,   262,  1280,  ...,   564,   250, 20521],\n",
            "        ...,\n",
            "        [50256,     8,   290,  ..., 13999,    13,   770],\n",
            "        [50256,  1352,   286,  ...,   198,   198, 10603],\n",
            "        [50256,   262, 35560,  ..., 16874,   286,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  2051,  ...,   607,  1353,  3957],\n",
            "        [50256,   262, 15915,  ...,    13,   379,   807],\n",
            "        [50256,  1391,   198,  ...,     3,   307,   262],\n",
            "        ...,\n",
            "        [50256,  4624, 17033,  ..., 17598,   373, 18846],\n",
            "        [50256,  6083,   284,  ...,   198,  2437,   466],\n",
            "        [50256,   291,   290,  ...,    80,    12,    75]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    34,  2043,  ..., 24531,  1590,    11],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,   198,  ..., 40639,    60,    59],\n",
            "        ...,\n",
            "        [50256,   340,   284,  ...,    11,   262, 14052],\n",
            "        [50256,    25,   815,  ...,   198,   198,    58],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  5273,  ...,  6128,   287,  3687],\n",
            "        [50256,  1290,   355,  ...,   287, 23469,   466],\n",
            "        [50256,  2904,  3199,  ...,   807,  7679, 28700],\n",
            "        ...,\n",
            "        [50256,   284,  1205,  ...,   635,   281,  6325],\n",
            "        [50256,  2692,   355,  ...,  6409, 10245,   286],\n",
            "        [50256,   198,    18,  ...,   547,  1596, 19481]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257, 12899,  ...,    13,  2425,  1849],\n",
            "        [50256,    11, 17342,  ...,   750,   407,  4691],\n",
            "        [50256,  1768,  4943,  ...,   201,   198,   220],\n",
            "        ...,\n",
            "        [50256, 20906,   357,  ...,   220,   220,   220],\n",
            "        [50256, 20531,   550,  ..., 12316,   262,  1738],\n",
            "        [50256,  1692,  4430,  ...,   287,   511,  2614]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  5975,   340,  ...,   362,   784,   257],\n",
            "        [50256,  8671,    29,  ...,  2213,    29,   198],\n",
            "        ...,\n",
            "        [50256,  4094, 15162,  ...,  7957,    74,  5069],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 10318,    46,  ...,  3614,  2597,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 800, Loss: 4.6493\n",
            "tensor([[50256,   326,   262,  ...,  3638,   319,   262],\n",
            "        [50256,   198,  2514,  ...,   262,  2184,    13],\n",
            "        [50256,   287,   262,  ..., 12040,   290,  3081],\n",
            "        ...,\n",
            "        [50256,    60,   770,  ...,   683,    11,  4642],\n",
            "        [50256,   220,   220,  ...,    26,   198,   220],\n",
            "        [50256,   425, 18610,  ...,   201,   198,   201]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    16,    13,  ...,   338,  1807,   326],\n",
            "        [50256,  4227, 22154,  ..., 31007,   198,   198],\n",
            "        [50256,    92,     7,  ..., 11250,    13,    71],\n",
            "        ...,\n",
            "        [50256,   284,   923,  ...,   921,   460,   991],\n",
            "        [50256,    13,  3423,  ...,     7,    20,   737],\n",
            "        [50256,  4781,  1729,  ...,   657,    13,  8298]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9071,  6379,  ...,     8,   198,   198],\n",
            "        [50256,   466,   407,  ...,   561,  1656,   326],\n",
            "        [50256,   464,  4094,  ...,  4430,   989,   326],\n",
            "        ...,\n",
            "        [50256,  3440,  1366,  ...,   290, 17282,  6153],\n",
            "        [50256,   198,   198,  ...,   717, 26384,   656],\n",
            "        [50256,   612,   318,  ...,   514,   356,   714]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   437,   326,  ...,  4329,   257,  1263],\n",
            "        [50256,   286,   262,  ...,   606,   389, 11004],\n",
            "        [50256,  9564,    51,  ...,  3417,    13,    61],\n",
            "        ...,\n",
            "        [50256,  1661,   777,  ...,   618,   484,   467],\n",
            "        [50256,  4295,  4695,  ...,   262, 27763,   286],\n",
            "        [50256, 48969,    11,  ...,     1, 16454,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   663,  7332,  ...,    11,   379,   720],\n",
            "        [50256, 16585,  3977,  ...,  4900,   262, 17724],\n",
            "        [50256,  1343,   532,  ...,   286,   513,  1343],\n",
            "        ...,\n",
            "        [50256,    68,    59,  ...,    85,    59,    62],\n",
            "        [50256, 12178,   465,  ...,  3947,   257,  1643],\n",
            "        [50256,   379,   262,  ...,    11,  3706,   329]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2481,    12,  ..., 16096,   284,   262],\n",
            "        [50256,   749,  3665,  ...,   468, 14251,  5179],\n",
            "        [50256,    16,  5974,  ...,  8280, 26742,    13],\n",
            "        ...,\n",
            "        [50256,   351,   262,  ...,  2482,   737,   440],\n",
            "        [50256,   198,   464,  ...,   262, 25452,  7291],\n",
            "        [50256, 39025,   416,  ...,  3819, 18152,   286]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3048,   319,  ...,     8,  5214,   275],\n",
            "        [50256, 10999,    11,  ...,   198,    65,  4127],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   257, 10016,  ...,   423,  1541,  3088],\n",
            "        [50256,    11,  4521,  ...,   318,  2124,    68],\n",
            "        [50256,   220,   220,  ...,   220, 12429,    15]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 12095,    16,  ...,    58,  3506,    28],\n",
            "        [50256, 34568,    12,  ...,   379,    13,   198],\n",
            "        [50256,   198,   198,  ...,   640,    13,  3894],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   526,   198,  ...,  1735,    11,   523],\n",
            "        [50256,    13,   198,  ...,   301,    76,  6744]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1635,    11,  ...,  2878, 20221,   355],\n",
            "        [50256,   628,   220,  ..., 11404,  8606,   428],\n",
            "        [50256,   373,  1804,  ...,  4129,   286,   511],\n",
            "        ...,\n",
            "        [50256, 12033, 21983,  ...,  2665,   286,   262],\n",
            "        [50256,    11,   262,  ...,  4445,   284,   766],\n",
            "        [50256,   508,  9894,  ...,   198,     7,     2]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 28778, 11177,  ...,   220,   289,   940],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   621,  2180,  ...,   815,   307,  6751],\n",
            "        ...,\n",
            "        [50256,   198,   737,  ...,  2718,    12,  2548],\n",
            "        [50256,   198,   220,  ...,    13,  8356,    13],\n",
            "        [50256, 11153,   389,  ...,  7562,  9251,   287]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 810, Loss: 5.7782\n",
            "tensor([[50256, 11954,    11,  ...,   272, 14386,    11],\n",
            "        [50256,  6444,    13,  ...,   393,   262,  4452],\n",
            "        [50256, 17005,    13,  ...,   410,    13,  1812],\n",
            "        ...,\n",
            "        [50256,   812,   286,  ...,   287, 14074,  3418],\n",
            "        [50256,   331,  2088,  ...,   777,  5043,  6774],\n",
            "        [50256,  1270,  3122,  ...,   338, 12436,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 25875,   468,  ...,  3265,    13,   198],\n",
            "        [50256,   540, 43608,  ...,   319,   262, 37218],\n",
            "        [50256,   220,   220,  ...,   263,   772,  1231],\n",
            "        ...,\n",
            "        [50256,   314,  1101,  ...,   531,   911,   346],\n",
            "        [50256,  5803,    11,  ...,   284,  9365,  7994],\n",
            "        [50256,  1479,    13,  ...,   338,   890,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12,  4852,  ...,    11,   284,   642],\n",
            "        [50256,     9,  2430,  ..., 10879,    62,   259],\n",
            "        [50256, 26931,   286,  ...,   286,   597,   286],\n",
            "        ...,\n",
            "        [50256,    11,   611,  ..., 14158,    11,   352],\n",
            "        [50256, 40333, 35328,  ...,   866,   287,   777],\n",
            "        [50256,    26,    11,  ...,    13, 20483,    19]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8019,    62,  ...,  2615,   287,  1596],\n",
            "        [50256, 25414,    13,  ...,  1453,   198,   220],\n",
            "        [50256,   366,  1639,  ...,  3497,  8272,     1],\n",
            "        ...,\n",
            "        [50256,    17,    61,  ...,    17,    61,    11],\n",
            "        [50256,  2219,  2565,  ...,   286,  3794,   338],\n",
            "        [50256,   319, 40679,  ...,  6091,   325,  5268]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12,  1084,  ...,   685, 12310,    49],\n",
            "        [50256,   220,   220,  ..., 27850,     8,   201],\n",
            "        [50256, 19953,  5420,  ...,  3614,  4547,   286],\n",
            "        ...,\n",
            "        [50256, 12647,   338,  ...,  1701,   366,    40],\n",
            "        [50256,   535,   273,  ...,   259,    62,  4775],\n",
            "        [50256,    51,    62,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2293,   262,  ..., 30232,   290, 21919],\n",
            "        [50256,  4943,  1391,  ...,     7,    66,  1635],\n",
            "        [50256,   262,  3096,  ...,  5707,    13,   198],\n",
            "        ...,\n",
            "        [50256,  8655,   311,  ...,   287, 15568,   290],\n",
            "        [50256,  9001,   290,  ...,  4003,    11,   281],\n",
            "        [50256,   287,   326,  ...,   836,   470, 11691]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   767,  2713,  ...,     1,  6536,   326],\n",
            "        [50256,   220,   220,  ...,  4469,    12,  8043],\n",
            "        [50256,   287,   655,  ...,    30,  1002,   262],\n",
            "        ...,\n",
            "        [50256,   307,   257,  ...,   291,  5202,  1028],\n",
            "        [50256,    17,    92,  ..., 31688,    21,    60],\n",
            "        [50256,   714, 12259,  ...,  6147,   561,  4439]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 15882,   262,  ...,   543,  3544,   257],\n",
            "        [50256,    12, 20986,  ...,  2599,  1550,   262],\n",
            "        [50256, 15964,  6232,  ...,  5665,  3078,   329],\n",
            "        ...,\n",
            "        [50256,   364,   262,  ...,    11,  2177,   198],\n",
            "        [50256,  2606,  8035,  ...,   326,  6136,   338],\n",
            "        [50256,   220,   220,  ..., 23031, 20368, 30934]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   470,  1494,  ...,   326,   340,  3947],\n",
            "        [50256, 45659,    13,  ..., 24464,    11,   691],\n",
            "        [50256,    29,  9444,  ...,    14, 10827,  2436],\n",
            "        ...,\n",
            "        [50256, 10338,   422,  ...,  8055,    11,   543],\n",
            "        [50256,    11, 18579,  ..., 17463,   263, 33721],\n",
            "        [50256, 15097,  8244,  ...,  1755,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3465,    11,  ...,   717,  3187,   286],\n",
            "        [50256,    74,     9,  ...,   737,  1649,   262],\n",
            "        [50256,    65,    13,  ...,   198,    34,    13],\n",
            "        ...,\n",
            "        [50256,  2607,   290,  ...,   447,   251,   290],\n",
            "        [50256,   422,  2517,  ...,  6150,   319,   511],\n",
            "        [50256,   832,   606,  ...,   198,   220,  1401]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 820, Loss: 6.3578\n",
            "tensor([[50256,   284,  1064,  ..., 16586,  4610,   318],\n",
            "        [50256,  3389,   532,  ..., 16847,  3615,    13],\n",
            "        [50256,    83,   766,  ..., 15046,   262,   812],\n",
            "        ...,\n",
            "        [50256,   345,   460,  ...,   340,    13,  2080],\n",
            "        [50256,   336, 19257,  ...,  2736,   328,    83],\n",
            "        [50256, 10825,    13,  ..., 36986,  3667,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3505,   326,  ..., 17520,   316,    11],\n",
            "        [50256,  2430,   400,  ..., 25226,    85, 17015],\n",
            "        [50256,   439,  5638,  ...,    13,  2735,    11],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,    92, 13702, 11337],\n",
            "        [50256,   621,   530,  ...,  1656,   284, 10568],\n",
            "        [50256,  2357, 32536,  ...,    14,  9410,  4248]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  3887,  ..., 14093,    13, 16238],\n",
            "        [50256,  7346,   262,  ...,   727,   536,  2634],\n",
            "        [50256,  1171, 48599,  ...,   198,   220,   220],\n",
            "        ...,\n",
            "        [50256,   198,   405,  ...,    11, 30368, 14610],\n",
            "        [50256,    13,  8989,  ...,  1178,  1243,    13],\n",
            "        [50256,  1629,   428,  ...,   198,   198, 19927]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   952,   574,  ...,  6843, 12497,   319],\n",
            "        [50256, 14367,  3712,  ...,   393, 12734,    13],\n",
            "        [50256,  1532,   345,  ..., 22359,    12, 38345],\n",
            "        ...,\n",
            "        [50256,    70,  1539,  ...,   329, 14916,    13],\n",
            "        [50256,  6651, 22952,  ...,    12, 10246,   589],\n",
            "        [50256,  6440,    11,  ...,    11,   262,  4652]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4365,   318,  ...,  5137,   477,   674],\n",
            "        [50256,    11,   409,  ...,   198,   198,   464],\n",
            "        [50256,   262,  5128,  ...,   546,  1802,   285],\n",
            "        ...,\n",
            "        [50256, 27230,  2713,  ...,  1872,     0,    48],\n",
            "        [50256,   286,   767,  ...,  5837,  3712, 29138],\n",
            "        [50256,    11, 40216,  ...,   262, 37923, 10066]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,   826,  ...,   923,    11,   356],\n",
            "        [50256,   286,   262,  ...,    25, 16753,    11],\n",
            "        [50256, 11817,   346,  ...,  5182,   329,   374],\n",
            "        ...,\n",
            "        [50256, 14143,  3953,  ...,    28,    16,    92],\n",
            "        [50256,  7482,   284,  ..., 11734,    11,   340],\n",
            "        [50256,  3251,    13,  ...,  1644,   423,   584]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ...,   628,   198,   198],\n",
            "        [50256,  3954, 11162,  ...,   314,  1053,   587],\n",
            "        [50256,   220,   220,  ...,    13,  2713,   220],\n",
            "        ...,\n",
            "        [50256, 13255,     7,  ...,    90,   198,   197],\n",
            "        [50256,  5185, 47748,  ...,  1176,   284,  7125],\n",
            "        [50256,  1747,    11,  ..., 31478, 11018,    69]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198, 18849,  ...,   220,   141,   230],\n",
            "        [50256,  5786,  1437,  ..., 10903,    25,   220],\n",
            "        [50256,   262,  3265,  ..., 10488,   355,   257],\n",
            "        ...,\n",
            "        [50256,    82,    92,  ...,    59, 26224,   279],\n",
            "        [50256,    13,  5420,  ...,   734, 23163,   357],\n",
            "        [50256,  8187, 35846,  ...,  5447,   355,  5679]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   264,   396,  ..., 22820,   397,  1192],\n",
            "        [50256, 13760,    30,  ...,   513,    13,   198],\n",
            "        [50256,  7619,  5036,  ...,   628,   220,   220],\n",
            "        ...,\n",
            "        [50256, 14250,   318,  ...,  5645,  4143,  1022],\n",
            "        [50256,    25,   198,  ..., 29199,  1108,    12],\n",
            "        [50256,    62,    73,  ...,  3467,    58,  1069]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   314,   447,  ...,  3835,   355,   880],\n",
            "        [50256, 44639,   286,  ..., 11923,    12,  5662],\n",
            "        [50256,  4048,   379,  ...,  4875,  7124,  4811],\n",
            "        ...,\n",
            "        [50256,  2589,   326,  ...,   262, 12910,  4497],\n",
            "        [50256,   828, 23430,  ...,   289,  6357,    12],\n",
            "        [50256,   220,   220,  ...,   220,   657,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 830, Loss: 5.8397\n",
            "tensor([[50256,   198,   198,  ..., 25049,  2238,     8],\n",
            "        [50256,    13, 16742,  ...,  1760,   329,   345],\n",
            "        [50256,    13,    22,  ..., 11502,  1507,  4407],\n",
            "        ...,\n",
            "        [50256,    62, 20034,  ...,   366, 21633, 14257],\n",
            "        [50256,  2667,   319,  ...,   220, 34645,   220],\n",
            "        [50256,  2893,   428,  ...,   393,  1936,  3625]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1607,   262,  ...,   314,  1612,   262],\n",
            "        [50256,   257,  1398,  ...,   220,   220,   220],\n",
            "        [50256, 23805,    13,  ...,    13,  2080,   262],\n",
            "        ...,\n",
            "        [50256,   284,  3952,  ...,   447,   250,  8642],\n",
            "        [50256,   220,   220,  ...,  3918,  9487,  2625],\n",
            "        [50256, 40408,    13,  ...,  1181,   286,  4113]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,  1168,   437,    62],\n",
            "        [50256,   670,   784,  ...,    11,   257,  6103],\n",
            "        [50256,   284,  2972,  ...,  7686,    13,   198],\n",
            "        ...,\n",
            "        [50256,    47,  2974,  ...,    13,   198,   198],\n",
            "        [50256,   341,   286,  ...,  4551,    72,  6173],\n",
            "        [50256,   220,   220,  ...,   220,   220, 10111]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,    24,  ...,    17, 17257,    28],\n",
            "        [50256,    62,    18,  ...,   334,    12,    17],\n",
            "        [50256,   989,   257,  ...,   112, 33232,   100],\n",
            "        ...,\n",
            "        [50256, 16151,    82,  ...,   721,   803,  2354],\n",
            "        [50256,  1744,    13,  ..., 18493,  1377,   543],\n",
            "        [50256,  4124,  6451,  ..., 18829,  2802,   561]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,     1,   393,  ...,   611,   673,  3136],\n",
            "        [50256,  8666,    13,  ...,   262,  1363,  2427],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 22519,  1849,  ...,    13, 46821, 24991],\n",
            "        [50256,   898, 11485,  ..., 13571,    62, 12417],\n",
            "        [50256,   220,   220,  ...,  5752,    13,    34]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1135,   389,  ...,   281, 19546,  2560],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   284,  4296,  ...,     6,  6460,    11],\n",
            "        ...,\n",
            "        [50256,  1218,  4459,  ...,   777,   198,  6604],\n",
            "        [50256, 49117,   422,  ...,   198, 27857, 11230],\n",
            "        [50256,   357,  1129,  ...,  9823,   286,  3871]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   447,   251,  ...,    11,   340,   750],\n",
            "        [50256,  1339,  3933,  ...,    13, 12501,  1098],\n",
            "        ...,\n",
            "        [50256,  3122,   198,  ...,   198, 15982,   198],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 21442,  3111,  ...,  1705,   286,   607]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,  4257,  ...,    13,   198,   198],\n",
            "        [50256,    13,  2860,  ...,  1171,  7951,  2223],\n",
            "        [50256,   374,  4248,  ...,   290, 27521, 18989],\n",
            "        ...,\n",
            "        [50256,   290,  2192,  ..., 38310,  3842,   468],\n",
            "        [50256,   257,  6268,  ...,  6759,  8609,  8122],\n",
            "        [50256, 18077,   284,  ...,    13,   383, 19234]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   247, 16151,  ...,    77,   312,    28],\n",
            "        [50256,   198, 20379,  ..., 11015,  2484,  1144],\n",
            "        [50256,  4301,  3173,  ...,  3681,   417,  9333],\n",
            "        ...,\n",
            "        [50256,  1366,   878,  ...,    13,  1675, 19818],\n",
            "        [50256,  6822,   262,  ...,    11,  3724,  2795],\n",
            "        [50256,   925,   621,  ...,    11,   314,   892]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3262,    14,  ...,   361, 13845,    13],\n",
            "        [50256, 11538,   284,  ...,  1782, 23330,    74],\n",
            "        [50256,   220,   220,  ...,   290,   329,  5479],\n",
            "        ...,\n",
            "        [50256,   532, 40256,  ...,   287,   718,     9],\n",
            "        [50256,    18,     9,  ...,  2996,    11,   532],\n",
            "        [50256,   220,  6818,  ...,   220,   220,  9466]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 840, Loss: 4.5921\n",
            "tensor([[50256, 49335,  8771,  ...,   220,   220,  4731],\n",
            "        [50256,   198,   220,  ..., 15856,  3355,   287],\n",
            "        [50256,   876, 14139,  ...,  1478,    11,  7559],\n",
            "        ...,\n",
            "        [50256,  2713,  3122,  ...,    30,   198,  1065],\n",
            "        [50256,  1635, 10855,  ..., 39322,    56,     8],\n",
            "        [50256, 17312,   235,  ...,   198, 46036, 46036]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 36311,   276,  ..., 23068,  1495,    11],\n",
            "        [50256,  1241,    13,  ...,  1061,   262, 32645],\n",
            "        [50256, 29871,   290,  ...,  4726,  1389, 13076],\n",
            "        ...,\n",
            "        [50256,   287,   262,  ...,  2317,   284,   262],\n",
            "        [50256, 15526,    13,  ...,    13,   198,   198],\n",
            "        [50256,    13,   291,  ...,  3825,     8,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5125,    14,  ..., 32869,  1983,   198],\n",
            "        [50256,  9166,    13,  ...,   198,   198,    33],\n",
            "        [50256,  1022,  3513,  ...,  1386,  5732,   625],\n",
            "        ...,\n",
            "        [50256,   262, 14081,  ...,    13,  3244,   340],\n",
            "        [50256,   262,  2166,  ...,   257,  3154,  2565],\n",
            "        [50256,  3621,   526,  ..., 11131,   526,   366]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12,  3023,  ..., 13888, 13160,   286],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 19081, 11395,  ..., 44301,    11,   314],\n",
            "        [50256,   287,  1570,  ...,    13,   198, 13615],\n",
            "        [50256,    60,    59,  ...,    59,    60,  4418]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,  4941,  ..., 10425,   389,  1877],\n",
            "        [50256,   373, 10770,  ..., 35960,  3822,  3220],\n",
            "        [50256,   318,   407,  ...,  4235,   340,   318],\n",
            "        ...,\n",
            "        [50256,   262,  1981,  ...,   587, 27383,  3481],\n",
            "        [50256,   220,   220,  ...,   198,   220,   220],\n",
            "        [50256,  1569, 23571,  ...,   289,  2118,  2899]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   657,    13],\n",
            "        [50256, 24505,  7028,  ...,   262,  3277,   338],\n",
            "        [50256,  1821,    13,  ...,  1270,    13,  2919],\n",
            "        ...,\n",
            "        [50256,   531,    25,  ...,   269,    65,     7],\n",
            "        [50256,  2885,  7707,  ...,  6561,    13, 38948],\n",
            "        [50256, 24867,   423,  ..., 35204,   326,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   345,   466,  ...,   284,   345,  9313],\n",
            "        [50256,  4386,   351,  ...,   796,  3467,  5239],\n",
            "        [50256,    25,  1129,  ...,  2505,    25, 24958],\n",
            "        ...,\n",
            "        [50256,   402,  1617,  ...,  1617,   261,   714],\n",
            "        [50256, 18705,    30,  ...,    11,   996,   673],\n",
            "        [50256,   286, 34998,  ...,   553,   475,   340]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   422,   262,  ...,  3306,  2882,   284],\n",
            "        [50256,   356,  2540,  ...,   470,  1037, 30442],\n",
            "        [50256, 22190, 10051,  ...,  1657, 15584,   318],\n",
            "        ...,\n",
            "        [50256,  3691,    13,  ..., 34085,   447,   231],\n",
            "        [50256,  6684,    38,  ..., 10848,  7372,    13],\n",
            "        [50256,   749, 20755,  ..., 44360,    13,  5121]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   287,   674,  ...,   393,   561,  5078],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   729,  7363,  ...,   257,  3154,  8631],\n",
            "        ...,\n",
            "        [50256,    13,   198,  ...,   416,   281,  5743],\n",
            "        [50256,    12,    82,  ...,    13,   198,   198],\n",
            "        [50256,  1549,  2127,  ...,    28,    31,    62]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,   257,  ...,    11,  7869,    11],\n",
            "        [50256,   564,   246,  ...,  6011,  2594,   262],\n",
            "        [50256,    86,  2967,  ...,   447,   247,    82],\n",
            "        ...,\n",
            "        [50256,  9839,   290,  ...,   981, 29045,   447],\n",
            "        [50256,   607,  2489,  ...,   376,    76,  7801],\n",
            "        [50256,   597, 22575,  ..., 33834,   447,   251]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 850, Loss: 6.0918\n",
            "tensor([[50256,  9688,     1,  ..., 43362, 12894,     1],\n",
            "        [50256, 28463,    13,  ...,     3,  7266,  7839],\n",
            "        [50256,   247,    82,  ..., 27313,    25, 12332],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   657,     8,  1391],\n",
            "        [50256,   531,    13,  ...,   262,  2793, 21755],\n",
            "        [50256,   220,   220,  ...,   724,  9441,  2746]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    92,  1279,  ...,  4811,    11,   262],\n",
            "        [50256,   385,   321,  ...,   308,  4741,   494],\n",
            "        [50256, 17952,   286,  ...,    82,   524,    80],\n",
            "        ...,\n",
            "        [50256,   718,    25,  ...,  5668,  7675,    11],\n",
            "        [50256,  1101,   257,  ...,   262, 13017,    11],\n",
            "        [50256,  1871,   606,  ...,  3636,   470,  4719]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257, 14899,  ...,   423,  6989, 29483],\n",
            "        [50256,    26,  4353,  ..., 19726, 31748,   268],\n",
            "        [50256,    28,    18,  ...,    35,    16,    44],\n",
            "        ...,\n",
            "        [50256,   341,  1598,  ...,   284,  2652,   329],\n",
            "        [50256,   198,   198,  ...,  3887,  1110,    11],\n",
            "        [50256,  1270,    12,  ...,   393,  1440,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   422, 12551,  ...,   279,    13,    38],\n",
            "        [50256,   290,   314,  ...,   357,  2704,    13],\n",
            "        [50256,   198,  5167,  ...,   357,    35,   828],\n",
            "        ...,\n",
            "        [50256, 39652,   291,  ...,  7337,    11,   830],\n",
            "        [50256,   318,   284,  ..., 35307,  3244,    11],\n",
            "        [50256,   625,  2274,  ...,   307,  3220,   319]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1497,  2774,  ...,  3162,   357,  2969],\n",
            "        [50256,    13,  3605,  ...,    11,   290,   412],\n",
            "        [50256,   422, 20039,  ...,     2,    79,  5235],\n",
            "        ...,\n",
            "        [50256, 39314,    11,  ...,  1539,   220,  1849],\n",
            "        [50256,   685,  4357,  ...,  1303,    47,  2389],\n",
            "        [50256,  1337,   611,  ...,   460,   447,   247]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   543,   318,  ...,   796,   657, 26867],\n",
            "        [50256, 33180, 28134,  ...,   237, 39258, 28134],\n",
            "        [50256,   247,   168,  ...,   543,   743,  4425],\n",
            "        ...,\n",
            "        [50256,  5050,    13,  ...,    81,   796,   532],\n",
            "        [50256, 38298,  6163,  ...,   286,   262,  6801],\n",
            "        [50256,  1626,   257,  ...,  2198, 22580, 10474]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   379,  1551,  ..., 34946,  1505, 13759],\n",
            "        [50256,   198,   198,  ...,   262,  1628,   447],\n",
            "        [50256,   464, 10033,  ...,  1366,   422,   262],\n",
            "        ...,\n",
            "        [50256, 19953,  5420,  ...,   355,   262,  2620],\n",
            "        [50256,   290,  3724,  ..., 12580,   338,  1339],\n",
            "        [50256,   317,    16,  ...,   329,  1237,   684]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1238,    66,  ..., 27379, 10976, 11709],\n",
            "        [50256,    50,    13,  ...,    12,    67, 25218],\n",
            "        [50256,  4044,    14,  ...,    12, 32256, 19196],\n",
            "        ...,\n",
            "        [50256,  6041,   286,  ...,   444,    13,   628],\n",
            "        [50256,   351,   883,  ...,  4249,  4044, 19288],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   352,  ...,  4343,  2717,   198],\n",
            "        [50256, 32239,  6122,  ...,   220,   311, 23330],\n",
            "        [50256,  2885,    11,  ...,   198, 41441,    59],\n",
            "        ...,\n",
            "        [50256,   198,   198,  ...,   762,  2634,    66],\n",
            "        [50256, 31478, 47172,  ...,    59,  2725,    72],\n",
            "        [50256,  5183, 31478,  ...,    25,  3556, 12626]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   351,  6117,  ..., 35944,  1002,   477],\n",
            "        [50256, 18906,     1,  ...,   416,  3704,   262],\n",
            "        [50256,   422,   262,  ...,   329,  2330,  9684],\n",
            "        ...,\n",
            "        [50256,   685,    31,  ...,  2274,  2050,  1262],\n",
            "        [50256,   198,   198,  ..., 10744,    11,   543],\n",
            "        [50256, 22174, 26945,  ...,   230, 24336, 24186]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 860, Loss: 5.9720\n",
            "tensor([[50256,  3118,   896,  ...,   309,    61,    12],\n",
            "        [50256,  1705, 12353,  ...,    11,   257,  5581],\n",
            "        [50256,   290, 22190,  ...,   832,   262, 31094],\n",
            "        ...,\n",
            "        [50256,   845,  1290,  ...,  2067,   262,  1907],\n",
            "        [50256,   198,   197,  ...,  3368, 31998, 48082],\n",
            "        [50256,  2037,  1002,  ...,   423,  1257,     0]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   881,   290,  ...,   290,   257, 49448],\n",
            "        [50256,   513,   438,  ...,    16,    93,    61],\n",
            "        [50256,   220,   220,  ...,     4,  3256,   198],\n",
            "        ...,\n",
            "        [50256,    11,   830,  ...,    37,  7036,  9768],\n",
            "        [50256,  2151,  2067,  ...,   290,  7209,  1108],\n",
            "        [50256,  1478,    11,  ...,    11,   612,   389]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,  4770,  ...,    11,   262,  2121],\n",
            "        [50256, 20146,  4778,  ..., 32411,   262,   350],\n",
            "        [50256,  6492,   416,  ...,   803, 13375,   286],\n",
            "        ...,\n",
            "        [50256,   625,    13,  ..., 23031,   198, 13881],\n",
            "        [50256, 13632,  3262,  ...,   286,   262,  2882],\n",
            "        [50256,    67,   379,  ...,   259,   284,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    37,   447,  ...,  1903,   287,   262],\n",
            "        [50256,   198,    40,  ...,   564,   250,   738],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   366,    39,  ...,   470,   345,   281],\n",
            "        [50256,  7514, 21610,  ..., 36221, 31761, 12870],\n",
            "        [50256, 26286,    11,  ...,  4811,   290,  3863]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 43300,  3963,  ...,  3210,  4049,  3815],\n",
            "        [50256,   220,   220,  ...,  4566, 24714,   198],\n",
            "        [50256,  1334,   561,  ...,   257,  1104,  7846],\n",
            "        ...,\n",
            "        [50256,   534,  2214,  ...,  4875,  2479,   351],\n",
            "        [50256,   357,  2481,  ...,  7695,   684,  1872],\n",
            "        [50256,    85,   128,  ...,   251,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   318,  1409,  ..., 34561,   352,  1719],\n",
            "        [50256, 16171, 35120,  ...,  4028,   416,   262],\n",
            "        [50256,   510,   416,  ...,   423,  3022,    13],\n",
            "        ...,\n",
            "        [50256,  7096,   320,  ...,    12,  8199, 10045],\n",
            "        [50256,  1735,   286,  ...,   339,   714,   407],\n",
            "        [50256,  4439,   318,  ...,   673,   635,  6348]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   299,   305,  ...,  7819,   994,    13],\n",
            "        [50256, 10546,  7536,  ...,    11,  3387,   526],\n",
            "        [50256, 31274,   468,  ...,   447,   251,  2426],\n",
            "        ...,\n",
            "        [50256,   287,  1874,  ...,   446,   259,  2123],\n",
            "        [50256, 33707,    13,  ...,   262, 12681,  2223],\n",
            "        [50256, 50033,     3,  ...,     7,    51, 47505]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 25501,  1906,  ...,   520,    11, 28593],\n",
            "        [50256,   220,   220,  ...,    62,  5446, 19555],\n",
            "        [50256,    11,    15,  ...,    67,   403,  3070],\n",
            "        ...,\n",
            "        [50256,  2407,   281,  ...,   471,    13,    50],\n",
            "        [50256,  9185,   393,  ...,    11,  8779, 22328],\n",
            "        [50256,   198,   540,  ...,   407,  3393,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262, 10863,  ..., 27533,   317,   318],\n",
            "        [50256,   198,  4339,  ...,   284,   262,   717],\n",
            "        [50256,    13,   383,  ...,  5888,     8,  4295],\n",
            "        ...,\n",
            "        [50256,   283,    13,  ...,   749,   286,   262],\n",
            "        [50256,   836,   470,  ...,  1479,    11,   772],\n",
            "        [50256,  1597,   416,  ..., 11676, 18969,   826]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1588,  1271,  ..., 26296, 31804, 18128],\n",
            "        [50256,  3083,  3519,  ...,   220,   220,   220],\n",
            "        [50256,  9974,   373,  ...,   484,  2923, 47244],\n",
            "        ...,\n",
            "        [50256,   883,  1626,  ...,   481,  1037,   534],\n",
            "        [50256,   220,   220,  ...,   220, 38190,    14],\n",
            "        [50256,  4531,    43,  ...,  6515,   389,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 870, Loss: 5.8227\n",
            "tensor([[50256,    87, 23330,  ...,    59, 28483,  2611],\n",
            "        [50256,  1029,    12,  ...,    11, 23005,   287],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 13254,  3900,  ..., 48165, 14633,  1849],\n",
            "        [50256,   405,   257,  ...,   290,   327,  1304],\n",
            "        [50256,  3892,   284,  ...,  9659, 22864,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6241,   355,  ...,  4068,    11,   290],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1931,  6580,  ..., 21241,   260,   479],\n",
            "        ...,\n",
            "        [50256,   286, 44546,  ..., 16884,  6176,  2055],\n",
            "        [50256,  2438,     8,  ...,    13,   314,   423],\n",
            "        [50256,   220,   220,  ..., 10548,  2625,  9464]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   198,  ...,   284,   257, 32724],\n",
            "        [50256,   220,   220,  ...,   340,   561,  1884],\n",
            "        [50256,    25,   198,  ...,    11,   262,  4731],\n",
            "        ...,\n",
            "        [50256,   787,   262,  ..., 12804,     8, 36796],\n",
            "        [50256,    83,   423,  ...,   737,  1312,  2314],\n",
            "        [50256, 14079, 32101,  ...,   464,  6193,  1321]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6122,   290,  ...,    36, 11709,     7],\n",
            "        [50256,   517,  1241,  ...,  2227,   284,   467],\n",
            "        [50256, 11033, 22877,  ...,   301,  8738,   956],\n",
            "        ...,\n",
            "        [50256,    15,    13,  ...,   198,  1858,   389],\n",
            "        [50256,  6194,   286,  ...,   198,    43,   330],\n",
            "        [50256,     9,    76,  ...,   796,   657,     9]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   351,  ...,   550,   587,   287],\n",
            "        [50256, 15462,    11,  ..., 12612,   844,  1282],\n",
            "        [50256,    12,  1558,  ...,   407,  1290,   422],\n",
            "        ...,\n",
            "        [50256, 10538,  2936,  ...,  9871, 32403,   286],\n",
            "        [50256,   930,   198,  ..., 12814, 12405, 17563],\n",
            "        [50256,  6764,   796,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   612,   318,  ...,  2568,    11,   287],\n",
            "        [50256, 18490,   261,  ...,   550,  1751,   739],\n",
            "        [50256,   379,   509,  ...,   287,  1524,    11],\n",
            "        ...,\n",
            "        [50256, 11337,   311,  ...,   257, 32366,  5295],\n",
            "        [50256,  1438,  2625,  ...,  1003,   220,   220],\n",
            "        [50256,   284, 15690,  ...,   314,  3421,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  4068,   290,  ...,  1965,  1771,   262],\n",
            "        [50256, 28728,  2321,  ...,   543,   257, 14309],\n",
            "        ...,\n",
            "        [50256,  3113,    13,  ...,   483,   631,   332],\n",
            "        [50256,  1061,   262,  ...,  2050,  3467, 30109],\n",
            "        [50256, 32974,  3348,  ...,  2267,  2695,    14]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   611,   340,  ...,   318,   281,   705],\n",
            "        [50256,  2196,   543,  ...,  1095,  1391,   651],\n",
            "        [50256, 16151,     2,  ..., 10097,  3880, 26866],\n",
            "        ...,\n",
            "        [50256,   511,  5479,  ...,  3833,  8564,   512],\n",
            "        [50256,    62,  6200,  ...,   220,   220,   220],\n",
            "        [50256,  4166,    13,  ...,   287,  3357,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8048, 20746,  ...,  3256,   705,    50],\n",
            "        [50256,   262, 29598,  ...,  4588,   460,   307],\n",
            "        [50256,   220,   220,  ...,  7785,  1776,   198],\n",
            "        ...,\n",
            "        [50256,    31, 28821,  ...,    92, 23330, 38227],\n",
            "        [50256,  4890,    13,  ...,   262,  8922,   318],\n",
            "        [50256, 43420,    59,  ...,    76,     3,     8]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   892,    11,  ...,   351,   511,  6665],\n",
            "        [50256,    59,    62,  ...,    43,   321,     3],\n",
            "        [50256,  7360,   290,  ...,  4047, 20050,  2026],\n",
            "        ...,\n",
            "        [50256,   340,   714,  ...,   351,   534,  3988],\n",
            "        [50256,   513, 25272,  ...,     2,    83,  2436],\n",
            "        [50256,   257,   845,  ...,   247,    82,  4874]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 880, Loss: 5.9740\n",
            "tensor([[50256,   220,   220,  ...,  8053, 10267,   818],\n",
            "        [50256,  1180, 15584,  ...,   257,  1790,  1762],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,    13,  3262,  ...,    30,  6371,    28],\n",
            "        [50256,   262,  1306,  ...,   287, 43301, 16213],\n",
            "        [50256,   197,    70,  ...,    13,    23,     8]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 39226, 27493,  ...,   657,    13,  8298],\n",
            "        [50256,    11,   347,  ...,   371,   357,    33],\n",
            "        [50256, 32425,   338,  ...,    11,  3576,    11],\n",
            "        ...,\n",
            "        [50256,   326,   460,  ...,  5591,   340, 15165],\n",
            "        [50256, 12157,    11,  ...,    11,   340,   318],\n",
            "        [50256,  1966,  2985,  ...,  9109,  4745,   319]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   532,   642,  ...,  4521,   198,    50],\n",
            "        [50256,   290,  5716,  ...,   198,   198,  2964],\n",
            "        [50256,   290,  5942,  ...,  3180,     1, 29809],\n",
            "        ...,\n",
            "        [50256,  2404,  5450,  ..., 11139, 15410, 18463],\n",
            "        [50256, 47637,  1466,  ...,  5566,  2793, 30948],\n",
            "        [50256,  3662,   611,  ...,  5520,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 21940,   220,  ...,  3141,  9706, 25970],\n",
            "        [50256,   198,     2,  ...,  3304,    13, 21943],\n",
            "        [50256,   304,    13,  ...,   561,   307, 10678],\n",
            "        ...,\n",
            "        [50256,    13,   198,  ...,    11, 14340, 21228],\n",
            "        [50256,  5516,    11,  ...,  6859,  3544,   663],\n",
            "        [50256,   860,  3829,  ...,    17,    67,   379]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 18947, 20729,  ..., 10064,   761,    77],\n",
            "        [50256,  6329,   198,  ..., 30109,    31,    33],\n",
            "        [50256,   339,   290,  ...,  3737,   407,  1464],\n",
            "        ...,\n",
            "        [50256,   832,  3220,  ...,   523,   326,   262],\n",
            "        [50256,  3599, 41683,  ...,  1266,  1938,   319],\n",
            "        [50256,  3436,    11,  ...,  2795,  2813,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9848,  2859,  ...,    19,   198,   198],\n",
            "        [50256,  1900,   355,  ...,  6867,   286,  1635],\n",
            "        [50256,   198, 13414,  ..., 30813,  3299,  4678],\n",
            "        ...,\n",
            "        [50256,   287,   309,  ...,   674,  3640,   351],\n",
            "        [50256,  9060,  2853,  ..., 12872,  4831,   284],\n",
            "        [50256,    13, 12489,  ...,    13,    48,    25]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6898,   416,  ...,   319,  3035,   838],\n",
            "        [50256,  2312,   389,  ...,   357,   273,  6093],\n",
            "        [50256,  7596, 44957,  ...,  5999, 27705,    17],\n",
            "        ...,\n",
            "        [50256,  2823, 17161,  ...,    11, 17161,   447],\n",
            "        [50256,  1528,    11,  ...,   286, 44473,    11],\n",
            "        [50256,   220,   220,  ...,   198,  4805, 12394]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  9107,   393,  ...,  5175,  7108,   329],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   287,   262,  ...,  5860,   290,  3487],\n",
            "        ...,\n",
            "        [50256,   259,   347,  ...,    64,     3,   481],\n",
            "        [50256,    13,   410,  ...,   547, 20756,    26],\n",
            "        [50256,   300,   501,  ...,   357,    82,  1875]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1959,    60,  ...,   319, 11863, 36275],\n",
            "        [50256, 29999,    25,  ...,   517,   621, 20143],\n",
            "        [50256,    13, 10805,  ...,   220,   220,  7536],\n",
            "        ...,\n",
            "        [50256,  7088,    13,  ..., 22803,    13,  1114],\n",
            "        [50256,   465, 17841,  ...,   251,   284,  1194],\n",
            "        [50256,  7946,    16,  ..., 10959,    13,   383]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   845, 20923,  ..., 30490,   290, 17065],\n",
            "        [50256, 16183,   561,  ...,   338,  5544,  4387],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256, 32869,    12,  ...,  1416,  3577,    12],\n",
            "        [50256,   290,  1210,  ...,  3662,   338,  6701],\n",
            "        [50256,   356, 33657,  ...,  5647,    17, 19953]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 890, Loss: 5.2142\n",
            "tensor([[50256,    90,    43,  ...,    92,    29,    51],\n",
            "        [50256,   287, 12138,  ...,  5647,    25, 47658],\n",
            "        [50256,   262,  1138,  ...,    33, 23726,    12],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    25,   198,  ...,  7778,   292,  8477],\n",
            "        [50256,    12,    17,  ..., 39280,  2725,    72]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   555, 41771,  ..., 29681,   286,  3313],\n",
            "        [50256,    26,   350,  ...,    54,  2040, 26139],\n",
            "        [50256,  2548,  2231,  ...,  1415,  1558,    13],\n",
            "        ...,\n",
            "        [50256, 11362,  3440,  ..., 48792,  3979,   779],\n",
            "        [50256, 12995,  1595,  ..., 16083,   779,  3519],\n",
            "        [50256,   564,   250,  ...,  8246, 44189,  2393]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14069, 13229,  ...,   890,   285,    62],\n",
            "        [50256, 19629,   198,  ...,  3023,  2624,    59],\n",
            "        [50256,  7009,  1657,  ...,   318,   281,  1593],\n",
            "        ...,\n",
            "        [50256,    18,    13,  ...,   262,  7840,  3214],\n",
            "        [50256, 43827,     8,  ...,  2857,   357,    20],\n",
            "        [50256,    11,  8685,  ..., 11973,   373,   973]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  4088,  ...,   198,   198,  2484],\n",
            "        [50256,    13,  6385,  ...,  4732,    13, 21947],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   287,   262,  ..., 46570,  3573,   287],\n",
            "        [50256,   657,    13,  ...,    12,  1954,   220],\n",
            "        [50256,   198,  1722,  ...,   367,   828, 12429]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 31478, 35505,  ...,    59,    80, 47003],\n",
            "        [50256,   407,  1620,  ...,   262, 24843, 13789],\n",
            "        [50256,   416,   262,  ..., 36980, 38536,  2059],\n",
            "        ...,\n",
            "        [50256,   383, 14091,  ...,   796,   371,   412],\n",
            "        [50256,   317,   833,  ...,    13,   887,   257],\n",
            "        [50256,   503,   284,  ...,    13,   376, 26458]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 42131,    62,  ...,   220,   220,   220],\n",
            "        [50256,    62,   312,  ..., 47854, 23296,   198],\n",
            "        [50256,    12,    16,  ..., 29006,    16,    14],\n",
            "        ...,\n",
            "        [50256, 24604,  1843,  ...,    13,   198,   198],\n",
            "        [50256,   286,  4847,  ...,  4166,   832,   257],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,   198,  ...,   198,   198, 25631],\n",
            "        [50256,   484,   389,  ...,   357,  1073,   690],\n",
            "        [50256,  1351,   564,  ...,   517, 12661,   290],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   198,   220,   220],\n",
            "        [50256,  1135,   821,  ...,   198,   198,    50]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    13,   198,  1959],\n",
            "        [50256,  1181,    11,  ..., 47662,  7886,  3561],\n",
            "        [50256, 11999, 27398,  ...,    87,  1795,    87],\n",
            "        ...,\n",
            "        [50256, 25306,    20,  ...,    25,   657,    87],\n",
            "        [50256,   423,   587,  ...,  7004, 32679,  8985],\n",
            "        [50256,    50,   979,  ...,    13, 26977, 15765]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,  4476,  ..., 19819,    12, 26209],\n",
            "        [50256,   447,   251,  ...,   607,  3397, 10357],\n",
            "        [50256,    90,    70,  ...,   370,    62,    83],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 15704,   287,  ..., 11251,  1797,   828],\n",
            "        [50256,   338,   749,  ...,   198,    27,  5126]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   897, 15090,  ...,   400,    13, 11075],\n",
            "        [50256,   259,  1952,  ...,  7723,   422,   513],\n",
            "        [50256,  3871,   351,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   405,    67,  ...,    11,   657,    87],\n",
            "        [50256,   767,  2996,  ..., 36150,   198,   220],\n",
            "        [50256,  2623, 16151,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 900, Loss: 4.3759\n",
            "tensor([[50256,  7159,  2883,  ...,   521,   377, 12745],\n",
            "        [50256,   220,   220,  ...,   247,    82,   357],\n",
            "        [50256,   411,    11,  ...,   551,   300,     6],\n",
            "        ...,\n",
            "        [50256,   338, 31088,  ...,  1367,    12, 18085],\n",
            "        [50256,   267,     7,  ...,    83,   329,   256],\n",
            "        [50256,   198,    32,  ..., 18439,    13,  9800]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,  1441,  ...,   198,   600, 18007],\n",
            "        [50256, 18452, 13043,  ...,   383,  7054,    53],\n",
            "        [50256,   523,  2968,  ...,  3919,   684,   314],\n",
            "        ...,\n",
            "        [50256,   262,  9002,  ...,  8710,   557,    11],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   287,  1176,  ...,  1182,   286,   262]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 30869,   284,  ...,   262,  2656,   481],\n",
            "        [50256, 10644, 26612,  ...,   262,   288,  1516],\n",
            "        [50256,  1675,  3128,  ...,    12,   940,  3227],\n",
            "        ...,\n",
            "        [50256, 13219,     7,  ...,   262, 22146,  5945],\n",
            "        [50256,  8313,    11,  ...,    39,    13,  3738],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 25219,  1701,  ...,  1037,   502,  4929],\n",
            "        [50256,  8614,  5447,  ...,   256,    79,    58],\n",
            "        [50256,  1390,   257,  ...,   373,   407,   329],\n",
            "        ...,\n",
            "        [50256, 16151,   261,  ..., 17765,   290, 17085],\n",
            "        [50256,  3946,   329,  ..., 11581, 11898,   329],\n",
            "        [50256,    11,   611,  ...,  3465,   257,  1588]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  3513,  ...,  4906,  2625,   847],\n",
            "        [50256,   220,   220,  ...,  6669,  1096,    88],\n",
            "        [50256,   530,  5827,  ...,   464,  1554, 18569],\n",
            "        ...,\n",
            "        [50256, 26025,  1084,  ...,  4811,   284,   307],\n",
            "        [50256,   532, 14808,  ..., 13841,    16,  1343],\n",
            "        [50256,  1276,   307,  ...,  9397,   284,  3491]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    40,   836,  ...,  2050,    13,   314],\n",
            "        [50256,    17, 47676,  ...,  2514,  3953, 22949],\n",
            "        ...,\n",
            "        [50256, 20077,    14,  ..., 20077,    14, 16886],\n",
            "        [50256,    18,     9,  ...,     9,    83,  1174],\n",
            "        [50256,    11,   655,  ...,   514,    13,   775]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,   350,  ...,   198, 11522,  6826],\n",
            "        [50256,  8949,    12,  ...,  7394,  1624,    13],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  1248,   198,  ..., 44367,   198,   198],\n",
            "        [50256,   290, 24033,  ...,  1455,   268,  1976],\n",
            "        [50256,     7, 17440,  ...,  8000,    25,  9242]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256, 23330,    17,  ...,     3,   318,  6439],\n",
            "        [50256,  4426, 30030,  ...,   286,  4401,     8],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   287,  4888,  1281],\n",
            "        [50256, 25096, 29416,  ...,   220, 33411,   256],\n",
            "        [50256,     9,    69,  ...,    64,    13,  1867]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    17,    66,    60],\n",
            "        [50256,    13,    82,  ...,    12,  9288,  4602],\n",
            "        [50256, 39280,    83,  ...,    92,   275,    61],\n",
            "        ...,\n",
            "        [50256,  1448,   286,  ...,    13,   198,   198],\n",
            "        [50256,   262,   749,  ...,   612,   389,   257],\n",
            "        [50256,  3220,   471,  ...,   438,    34, 16151]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,   198,  ...,   785,    26,  2688],\n",
            "        [50256,  3672, 10354,  ...,    11,  2192,  2233],\n",
            "        [50256,   121,  3556,  ...,   672,   441,   929],\n",
            "        ...,\n",
            "        [50256,   257,  5337,  ...,  2746,   326,   985],\n",
            "        [50256, 14628, 33812,  ..., 37214,  5061,  7577],\n",
            "        [50256, 11532,    13,  ...,   262,   717,  4382]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 910, Loss: 6.3108\n",
            "tensor([[50256,   319,   511,  ...,   621,   262,   530],\n",
            "        [50256,   198,     2,  ...,  8841,  2836,  5376],\n",
            "        [50256,   764, 13397,  ...,  1115,  1933,   290],\n",
            "        ...,\n",
            "        [50256,    17,    67,  ...,    35,    13,   632],\n",
            "        [50256,  8265, 21947,  ...,    13,    39,   312],\n",
            "        [50256,  1200,   416,  ...,    13,   402,  1638]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3712, 10267,  ...,  1137,    62,    39],\n",
            "        [50256,    29,   198,  ...,   314,   481,   923],\n",
            "        [50256,   714,   307,  ...,   314,   561,  7685],\n",
            "        ...,\n",
            "        [50256,   287,   355,  ...,  2882,   198,   198],\n",
            "        [50256,   562,   570,  ...,   220,  2081,    11],\n",
            "        [50256,  4168,  3467,  ...,   383,   412,  7792]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   257,  1479,  ...,   352,    13,  2713],\n",
            "        [50256,  4922,   286,  ...,   733, 14315,    60],\n",
            "        [50256,    11,   314,  ...,     1,    32,   632],\n",
            "        ...,\n",
            "        [50256,    12,  3147,  ...,   366, 16454,   526],\n",
            "        [50256,   318,  1057,  ...,   284, 17369,   262],\n",
            "        [50256,  1119,  3947,  ..., 14757,  1965,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    13,   366,  ...,   543,   547,  2138],\n",
            "        [50256, 30215,   422,  ...,   262,  2748,  1271],\n",
            "        [50256,   220,   220,  ...,   355,   286, 11811],\n",
            "        ...,\n",
            "        [50256,  1733,   583,  ...,    12,    16,    26],\n",
            "        [50256,  6537,   326,  ...,   284,  1487,   663],\n",
            "        [50256,   796,   513,  ...,    33,  6684,  2257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   830,  ...,   198,   198, 39358],\n",
            "        [50256,  2026,   812,  ..., 11169,    11,  3601],\n",
            "        [50256,   299,   549,  ...,   779,   287,  2003],\n",
            "        ...,\n",
            "        [50256,  2177,    12,  ...,  2177,    12,  1065],\n",
            "        [50256,    92,    62,  ...,    59,   259,  3467],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 23330,    15,  ...,    92,     3,  1635],\n",
            "        [50256,  5647, 20662,  ...,   290,   262,  3001],\n",
            "        [50256,   770,   670,  ...,  6826, 25056,    13],\n",
            "        ...,\n",
            "        [50256,  1069,  4516,  ...,   848,  6212,  9449],\n",
            "        [50256,   220,  1782,  ...,   220,   329,   357],\n",
            "        [50256,   128,   108,  ...,  2269, 16175,   263]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    13,  5066,   220],\n",
            "        [50256,  1339,    11,  ..., 27908,     8,  4113],\n",
            "        [50256,   287, 41898,  ...,    67,     8,  1596],\n",
            "        ...,\n",
            "        [50256,    12, 31943,  ...,   818,   428,  3318],\n",
            "        [50256,   319,   663,  ..., 21027,   957, 17141],\n",
            "        [50256,   513,  1661,  ...,  2494,   373, 16726]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   319,   465,  ...,    13,   366,  8567],\n",
            "        [50256,   198,   220,  ...,   447,   247,    82],\n",
            "        [50256,   881,   326,  ...,   316,  1088,   257],\n",
            "        ...,\n",
            "        [50256,  3037,    13,  ...,    11,   393,  4232],\n",
            "        [50256,   499,  5799,  ..., 31676, 23513,  7908],\n",
            "        [50256,   309,   724,  ...,   559,   198,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   543,   318,  ...,  5014,   583,  1247],\n",
            "        [50256, 20803, 38797,  ...,    11,   475, 10143],\n",
            "        [50256,  2611, 14749,  ...,  9641,  2625, 38892],\n",
            "        ...,\n",
            "        [50256,    86,    25,  ...,   829,    74,    53],\n",
            "        [50256,   220,   220,  ...,  2860, 31929,     7],\n",
            "        [50256,  4025, 40182,  ...,  1174, 43100, 10362]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8534,   855,  ...,   366,    67,   333],\n",
            "        [50256,  4270,   506,  ...,   340,   373, 31210],\n",
            "        [50256,   373,   523,  ...,   989, 14757,   290],\n",
            "        ...,\n",
            "        [50256,    58,  2539,  ..., 19165,   784,   645],\n",
            "        [50256,    13,    40,  ...,  4808,   464, 30722],\n",
            "        [50256,   428,  9190,  ...,  7386,   810,   345]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 920, Loss: 5.7017\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    69,    59,  ...,    90,    92,  6039],\n",
            "        [50256,  3334,  7663,  ...,   475,   635,   329],\n",
            "        ...,\n",
            "        [50256, 19881,    65,  ...,    21,    66,    20],\n",
            "        [50256,   220,   220,  ...,    12, 20285,  2640],\n",
            "        [50256,  6751, 18022,  ...,   284,  5128,  1321]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   282, 34963,  ...,  1248,  1415,   220],\n",
            "        [50256,   437,    90,  ...,   565,   268, 38016],\n",
            "        [50256,   352,    13,  ...,  3614,   428,  1700],\n",
            "        ...,\n",
            "        [50256,  6520,   262,  ..., 10675,    12,  6511],\n",
            "        [50256, 11299,    13,  ...,    13,   679,  2277],\n",
            "        [50256,   447,   251,  ...,   314,  2497,   550]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   329,  5969,  ...,   220,   220,  3467],\n",
            "        [50256,   737,  1867,  ...,     9,    77,  1174],\n",
            "        [50256,    21,    14,  ...,    11,   663,  1281],\n",
            "        ...,\n",
            "        [50256,    59, 34777,  ...,  2611,  4808, 31478],\n",
            "        [50256,  1309,   467,  ...,   326,   867,   564],\n",
            "        [50256,  1971,  4332,  ...,  6786,  2873,     1]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1770,    13,  ..., 16384,   351,   345],\n",
            "        [50256,   314, 23330,  ...,    92,    60,    90],\n",
            "        [50256,   373, 12548,  ...,    13,   220,   198],\n",
            "        ...,\n",
            "        [50256,    16, 31324,  ...,     2,    51,    17],\n",
            "        [50256,   783,  8399,  ...,  3651,   287, 34782],\n",
            "        [50256,   198,   198,  ..., 14323,    59, 26518]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198, 20548,  ...,   532,   269,  1174],\n",
            "        [50256, 22137,   287,  ...,  5992,     0,   198],\n",
            "        [50256,  6621,   286,  ...,  5243, 25278,   198],\n",
            "        ...,\n",
            "        [50256,    31,  1477,  ...,  8957,    18,    31],\n",
            "        [50256,  2435,  1693,  ...,    40,  2051, 26467],\n",
            "        [50256,   290,  3649,  ...,  6210,  7010,   803]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   547, 25543,  ...,  7923,   388,   290],\n",
            "        [50256,   326,   277,  ...,  1111,  7375,   290],\n",
            "        [50256,  3797,   364,  ...,    13,  2724,     8],\n",
            "        ...,\n",
            "        [50256,  3492,   329,  ...,    11,  5403,   287],\n",
            "        [50256,    49,  8577,  ...,  5078,   357,    77],\n",
            "        [50256,   198,   197,  ...,    79,   541,  4008]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14288,  2479,  ...,   284,   262,   471],\n",
            "        [50256,  4141,  7072,  ...,   672,  1706,   447],\n",
            "        [50256,    12, 13982,  ...,  8491,   345,  5938],\n",
            "        ...,\n",
            "        [50256,   501,  9212,  ...,   645,  5068,  3616],\n",
            "        [50256,   257, 26192,  ...,   290,  2208,    12],\n",
            "        [50256, 22666,   737,  ...,   326,   423,   407]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    72, 15951,  ...,   284,   262,  1148],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,    60,   438,    58],\n",
            "        ...,\n",
            "        [50256,  1781,    11,  ...,   366,  2949,    11],\n",
            "        [50256,   286,   262,  ...,   290,   347,  2246],\n",
            "        [50256,   532,  1105,  ...,    19,   198,  2061]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  3506,     8,  ...,    11,    70,    62],\n",
            "        ...,\n",
            "        [50256, 30024,   422,  ..., 10703,    11,   257],\n",
            "        [50256, 35646,    82,  ..., 45034,   530,    13],\n",
            "        [50256,    90,    67,  ...,  5183,    90,    32]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14980,   198,  ...,   220,   220,   220],\n",
            "        [50256,  9336,   475,  ...,   991,  4691,   510],\n",
            "        [50256, 23330,    65,  ...,  9561,  3781,    11],\n",
            "        ...,\n",
            "        [50256,    11,   287,  ...,  3734,   329,   262],\n",
            "        [50256,   779,   511,  ...,  1637,   290, 11754],\n",
            "        [50256,   220,   220,  ...,  5474,    26,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 930, Loss: 5.4620\n",
            "tensor([[50256,  5832,   869,  ..., 31236,   465,  1808],\n",
            "        [50256,    59,    83,  ...,    92,  3467, 31361],\n",
            "        [50256, 42049,  1448,  ...,  3952,    11,   475],\n",
            "        ...,\n",
            "        [50256,   323,    11,  ...,  2156,    13,   314],\n",
            "        [50256,   767, 32465,  ...,    15,    13, 19924],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   220,  ...,   368,   657,   657],\n",
            "        [50256,   220,   220,  ...,   331,    18,  2625],\n",
            "        [50256,   264,  4248,  ..., 22136,    12,  2548],\n",
            "        ...,\n",
            "        [50256,   276,   872,  ...,    44,    83,    65],\n",
            "        [50256,  2488, 36695,  ...,  4098,   329,  9265],\n",
            "        [50256,    11,   326,  ...,    50,   889,   263]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,    23,    92,  ...,   351,  6458,  2920],\n",
            "        [50256,  5456,    13,  ...,   197,   197,   197],\n",
            "        ...,\n",
            "        [50256,   220,   352,  ...,   220,   220,   220],\n",
            "        [50256,   714,   423,  ...,   611,   314,   550],\n",
            "        [50256,  6814,  2163,  ...,   493,   198,   197]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   318,   783,  ...,   673, 10408,   290],\n",
            "        [50256,   286,  7026,  ...,    13,    50,    13],\n",
            "        [50256,    13,   383,  ..., 40189,    25,   366],\n",
            "        ...,\n",
            "        [50256,    28,  1238,  ...,  7380,  3146,   357],\n",
            "        [50256,   339, 16387,  ..., 18840, 28131,   551],\n",
            "        [50256,    67,   379,  ...,  8487,    12,  1238]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   259,     6,  ...,  3881,   259,     6],\n",
            "        [50256,    13,    24,  ...,  1963,   396,   433],\n",
            "        [50256,   481,   307,  ...,  3776,    11,   345],\n",
            "        ...,\n",
            "        [50256,   973,    17,  ...,   197,  4798,  7203],\n",
            "        [50256,   628,   220,  ...,  4357,   474,    58],\n",
            "        [50256,  2961, 26021,  ...,   468,  1464,  1900]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ..., 18292, 28125,   198],\n",
            "        [50256,   326,  3607,  ...,   284,  2270,   449],\n",
            "        [50256, 20401, 23925,  ...,   290,  1903,    12],\n",
            "        ...,\n",
            "        [50256,  3725,  1900,  ..., 22055,    13,  1114],\n",
            "        [50256, 15847,   510,  ...,    11,  5176,   284],\n",
            "        [50256,   290, 34858,  ...,   329,  3267,  1596]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4169,   303,  ...,    25,   705, 11246],\n",
            "        [50256,   220,   220,  ...,   438,    81,  1523],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,    11,   220,  ...,     8,   286,   884],\n",
            "        [50256,   484,   714,  ...,   655,   284,  1577],\n",
            "        [50256,   534,  8278,  ...,  1282,  1141,  2276]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  6364, 25449,  ...,  1748,  7372,   287],\n",
            "        [50256,  3704,    11,  ...,   286,   883,   366],\n",
            "        [50256,    33,  4846,  ..., 29954,   618, 19736],\n",
            "        ...,\n",
            "        [50256,  1288,   293,  ...,  2123,   725, 12685],\n",
            "        [50256,    82,  1804,  ...,   198,   198,   447],\n",
            "        [50256, 27371,  1906,  ...,    90,  5512,  7913]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1262,  3563,  ...,   287, 44237,  8334],\n",
            "        [50256,   318,   286,  ...,   373,  9181,    11],\n",
            "        [50256,   720,    34,  ..., 23330,    59, 26224],\n",
            "        ...,\n",
            "        [50256,  3298,   986,  ...,    11,   428,   318],\n",
            "        [50256,   198,   198,  ...,    13,  1119,  6807],\n",
            "        [50256,  6611,  1028,  ...,   326,   340,  7498]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7923, 45083,  ...,   656,   257,  2060],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1744,   618,  ...,  6190,  4369,    13],\n",
            "        ...,\n",
            "        [50256, 12684,  1595,  ...,   416,  8415,   510],\n",
            "        [50256,   258,  3529,  ...,  4486,     8,  6264],\n",
            "        [50256,   262,   406,  ...,    62,    15,  5512]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 940, Loss: 5.6133\n",
            "tensor([[50256,   777, 27490,  ...,   397,  1512, 10066],\n",
            "        [50256,   198,   220,  ...,  7146,    29,   198],\n",
            "        [50256,   526,   198,  ...,   284,  4724,   553],\n",
            "        ...,\n",
            "        [50256,   739,   257,  ...,   532,    76,  2624],\n",
            "        [50256,   220,   220,  ...,     7,    15,    87],\n",
            "        [50256,   887,  1440,  ...,   925,   465,  4664]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   110, 12466,  ...,  7208,  2628,    11],\n",
            "        [50256,    65,  2598,  ...,  5339,   286, 41286],\n",
            "        [50256,  6459,   379,  ...,   286,  2665, 20248],\n",
            "        ...,\n",
            "        [50256, 28350,    60,  ..., 46320,   287,   257],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   220,  1782,  ...,   198,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2250,    11,  ...,  1169,    65,  1585],\n",
            "        [50256, 12429,  6489,  ...,   220,   220,   220],\n",
            "        [50256,  1068,   599,  ...,   319,   262, 34794],\n",
            "        ...,\n",
            "        [50256, 30786, 26038,  ...,   543,   318,   262],\n",
            "        [50256,   220,   220,  ...,   220,   220,  1782],\n",
            "        [50256, 12405,   416,  ...,  6802,    13,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   379,   691,  ...,    76,  9675,   329],\n",
            "        [50256, 27166,  1046,  ...,   357,  7437, 31549],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  4206, 22197,  ...,   257,  5975,  3741],\n",
            "        [50256,    11,   356,  ...,  2622,   284,  9161],\n",
            "        [50256,   220,   220,  ...,  4569,  2939,  3781]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   632,   338,  ...,   366,  9360,  1263],\n",
            "        [50256, 25507, 12405,  ...,    11,  7102,  2257],\n",
            "        [50256, 43666, 16142,  ...,   224, 29826,    97],\n",
            "        ...,\n",
            "        [50256,  3853,   257,  ...,  2078,    92,     3],\n",
            "        [50256,  7248,   262,  ...,   198,   220,   220],\n",
            "        [50256,  5410,   290,  ...,   262,  5198, 23071]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    90,     3,    43],\n",
            "        [50256,    55,  5781,  ...,   477,   286,  8342],\n",
            "        [50256,  4999,   262,  ...,    11,   475, 12612],\n",
            "        ...,\n",
            "        [50256,   284,   651,  ...,   340,  2474,   366],\n",
            "        [50256,    30,  1374,  ..., 33552,   262, 21752],\n",
            "        [50256, 14386,   287,  ...,   329,   198,  6248]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    40,   460,  ...,  6568,    13,   383],\n",
            "        [50256,   287,  2046,  ...,  7375,    17,  2046],\n",
            "        [50256,  3785,   503,  ...,    13,   198,   198],\n",
            "        ...,\n",
            "        [50256,   262,  2732,  ...,  5260,    13, 44536],\n",
            "        [50256,   290,  4165,  ...,  2098,   326,  5035],\n",
            "        [50256,    20,    30,  ...,    11,   644,   318]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   276, 37021,  ...,  4128,   276, 15205],\n",
            "        [50256, 27471,    90,  ...,    25,   397,    59],\n",
            "        [50256,  2415,   508,  ...,  1620,   777,  3946],\n",
            "        ...,\n",
            "        [50256,   641,  1912,  ...,  7612,    13,   554],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   291, 17745,  ...,   318,  2562,   284]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   276,    83,  ...,   198,   198,  1537],\n",
            "        [50256,  2346,     8,  ...,    11,    73,    59],\n",
            "        [50256,    11,   475,  ...,  2106,   598,  5670],\n",
            "        ...,\n",
            "        [50256, 24967,   338,  ...,    11,   262,  6763],\n",
            "        [50256,   850,  1589,  ...,   319,  5742,  1805],\n",
            "        [50256,   198,   197,  ...,  1616, 28632,  4965]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    19,  4426,  ...,    13,    20,  4608],\n",
            "        [50256,     8,  1500,  ..., 26257,    46,     7],\n",
            "        [50256,   366,    40,  ..., 33945,   737,   198],\n",
            "        ...,\n",
            "        [50256,    12, 15542,  ...,  1866,   286,   262],\n",
            "        [50256,    66, 47467,  ...,    12,  1558,    12],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 950, Loss: 5.4469\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  3501,   329,  ...,   318,  2087,    11],\n",
            "        [50256,   286, 10156,  ...,  1625,   656,  2800],\n",
            "        ...,\n",
            "        [50256,   220,  1222,  ...,  6624,   360,  5258],\n",
            "        [50256, 34763,   416,  ...,   423,   257, 29384],\n",
            "        [50256,  2035, 12121,  ...,   276, 20897,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   297,  1309,  ...,    50,    14,    44],\n",
            "        [50256, 17536,   815,  ..., 19248,  1616,   593],\n",
            "        [50256, 21466, 24835,  ...,  4008,  1391,   201],\n",
            "        ...,\n",
            "        [50256, 13047,  4441,  ...,  1994,  7753,    13],\n",
            "        [50256,   383,  1388,  ...,   198,   464, 11529],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 13159,  4494,  ...,   356,   423,   973],\n",
            "        [50256,  9738,    11,  ...,  2708,  3136,   257],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   270,    11,  ...,   790,  1688, 13093],\n",
            "        [50256,  3578,   257,  ...,   329,   262,  2717],\n",
            "        [50256,   796,   198,  ...,   198,   198,    31]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   526,   198,  ...,  9550,   655, 13226],\n",
            "        [50256,    15,  1776,  ...,  1279,   838,    26],\n",
            "        [50256,   284,  1355,  ...,   366,  8645,   602],\n",
            "        ...,\n",
            "        [50256, 33233,  1058,  ...,   197,   197, 11377],\n",
            "        [50256, 11744, 16232,  ...,   503,   287,   262],\n",
            "        [50256,   537, 26696,  ...,   287,  2723,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  7203,    12,  ...,  2583,   366,  1343],\n",
            "        [50256,   198,   198,  ...,   286, 47485,   960],\n",
            "        [50256,   262,  6846,  ...,  8277,   287, 10256],\n",
            "        ...,\n",
            "        [50256,   428,    11,  ..., 47938,    11,   290],\n",
            "        [50256,  2163,   286,  ..., 47113,  1312,    13],\n",
            "        [50256,   464,  2068,  ..., 11907,    60,  7131]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 14922,  3970,  ...,   198,  3646,   415],\n",
            "        [50256,   705,  9800,  ...,   286,  9094,     0],\n",
            "        [50256,  6247, 14309,  ...,   720,    32,    27],\n",
            "        ...,\n",
            "        [50256,  6899,   286,  ...,   251,   632,   373],\n",
            "        [50256, 23330,    33,  ...,    16, 18477,    17],\n",
            "        [50256,  1849,  1485,  ...,   357,  1795,  4407]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    17,    93,  ...,   286, 11963,  2449],\n",
            "        [50256,  5332,   357,  ...,   220,   220,   220],\n",
            "        [50256,  4647,   286,  ..., 13481,  4783,    13],\n",
            "        ...,\n",
            "        [50256,  7044,  3747,  ...,    11,   311,   856],\n",
            "        [50256,  1497,    13,  ...,   262,  3807,    13],\n",
            "        [50256,   614,   287,  ...,   618,   262,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   197,  ...,    11,  1222,    79],\n",
            "        [50256,    13, 33660,  ...,   220,   220,   220],\n",
            "        [50256,  1266,  3931,  ...,  1701,   366,  8128],\n",
            "        ...,\n",
            "        [50256,   867,   286,  ...,  3570,   283,   284],\n",
            "        [50256,   366,   314,  ...,   366,  1639, 17753],\n",
            "        [50256,   220, 19141,  ..., 23270,   357, 31435]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,    13,  7802,  1139],\n",
            "        [50256,  3442,  2014,  ...,  4365,   338, 10384],\n",
            "        [50256,  4004, 28022,  ...,  3187,   351,  1770],\n",
            "        ...,\n",
            "        [50256,  1169,  3450,  ...,   813, 33760,    58],\n",
            "        [50256,    13,  2840,  ...,  7959,  3784,  3672],\n",
            "        [50256,  2229,    14,  ...,  1381,  1525,  8457]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   198,   220,  ...,   220,   220,   220],\n",
            "        [50256,   587,  5291,  ...,   198,    91,   416],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,   198, 49153,  ..., 37965,     8,   198],\n",
            "        [50256,   607,  5408,  ...,   262,  7850,   290],\n",
            "        [50256,  2458,   761,  ...,   389,  1695,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 960, Loss: 6.5000\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   373,  1972,  ...,    11,   564,   250],\n",
            "        [50256,   314, 18303,  ...,   503,  8979,   220],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   428,    13],\n",
            "        [50256,   379,   326,  ...,   220,   220,   220],\n",
            "        [50256,   407,  3375,  ...,  2000,   355,   673]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    17,   532,  ..., 24185,  1271,    30],\n",
            "        [50256,   466,    13,  ...,  3271, 26039,   805],\n",
            "        [50256,   287, 16673,  ...,   340,  3675,   309],\n",
            "        ...,\n",
            "        [50256,   318,   635,  ...,  2060,  2823,  3074],\n",
            "        [50256,   374, 10203,  ...,   772,  2058,  1969],\n",
            "        [50256, 11848,  1195,  ...,  1195, 32239,  6122]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   569,    11,  7275],\n",
            "        [50256,  8398,    13,  ...,    13,  4874,   757],\n",
            "        [50256,  1795,    87,  ...,   543,  2095,  4340],\n",
            "        ...,\n",
            "        [50256,  9519,   290,  ...,  4064, 29326, 41580],\n",
            "        [50256, 14826,  3403,  ..., 16340,    59, 12962],\n",
            "        [50256,   644,  1524,  ..., 34629,   402,  2799]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   379,   718,  ...,  2414,    11,   337],\n",
            "        [50256,    11,   356,  ...,    90,    55,    62],\n",
            "        [50256,  4089,    11,  ..., 41460,  1022,   262],\n",
            "        ...,\n",
            "        [50256,    31,    67,  ...,  5321,  8739,  1391],\n",
            "        [50256,  2592,  2081,  ...,  3161,  1242,   467],\n",
            "        [50256,   475,   714,  ...,   198,    92,   198]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8597,   291,  ...,   612,   447,   247],\n",
            "        [50256,   287,   257,  ...,  2102,    11,   340],\n",
            "        [50256,    43, 20808,  ..., 11765,   262, 17675],\n",
            "        ...,\n",
            "        [50256,  2033,   286,  ...,   510,  2427,   286],\n",
            "        [50256,  7521,   669,  ...,    37,   290,   815],\n",
            "        [50256,  1600,   198,  ...,   220,  5218,   357]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   996,  ...,  1276,   407,   307],\n",
            "        [50256, 11266,   422,  ..., 32775, 26925,   318],\n",
            "        [50256,   198,   220,  ...,   220,   220,  3373],\n",
            "        ...,\n",
            "        [50256, 36610,  1348,  ...,   468,  2775,  2489],\n",
            "        [50256,   286,   262,  ...,   500,  2927,  5040],\n",
            "        [50256,   220,   220,  ...,   438,    15,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  1790,   640,  ...,   338,  1611,   286],\n",
            "        [50256, 13509, 31003,  ...,   198, 49998, 12696],\n",
            "        [50256,  1080,   316,  ...,  1062,  3996,   260],\n",
            "        ...,\n",
            "        [50256,   361,  1157,  ...,  3132,    49, 28104],\n",
            "        [50256,    93,    11,  ...,   290,  3001, 40492],\n",
            "        [50256,   286, 17843,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 34069,   299,  ...,  5448,    11,   356],\n",
            "        [50256,   714,   766,  ...,   526,   366,    36],\n",
            "        [50256,     7, 34365,  ...,   389, 26879,  1695],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   251,   198,  ...,  1544,  2331, 19084],\n",
            "        [50256,  4884,  1526,  ...,   287,  4890,  3871]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    79, 13102,  ..., 10100,     7,    15],\n",
            "        [50256,    11,   314,  ...,  3088,   326,   526],\n",
            "        [50256,  2139,   319,  ...,    13,   350,   498],\n",
            "        ...,\n",
            "        [50256,    12,    67,  ...,  1106,     1,   198],\n",
            "        [50256,   749,  5863,  ...,  3800,    11, 36036],\n",
            "        [50256,   533,    11,  ...,    19,    11,    18]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    11,   198,  ...,   197,   197,   197],\n",
            "        [50256,  8591,   302,  ...,   415, 10287,   384],\n",
            "        [50256, 18783,   290,  ...,   198, 34750, 30461],\n",
            "        ...,\n",
            "        [50256,   198,    47,  ...,    13,   785,    14],\n",
            "        [50256,  6448,   389,  ...,   517,  1593,    11],\n",
            "        [50256,   286,  3576,  ...,    13,  2724,    26]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 970, Loss: 6.3068\n",
            "tensor([[50256,  1174,    18,  ...,   362,    14,  1558],\n",
            "        [50256, 40497,   329,  ...,  1697,   417, 11904],\n",
            "        [50256, 21169, 16142,  ..., 47113,   475,   314],\n",
            "        ...,\n",
            "        [50256,    92,   198,  ...,  8317,   796,    59],\n",
            "        [50256,   669,    11,  ...,   287,  3592,    13],\n",
            "        [50256,   220,  2073,  ...,   284,  8160,   257]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   281,   388,  ...,  2290,   265, 43577],\n",
            "        [50256,  6345,    13,  ...,  4871, 30794,    13],\n",
            "        [50256, 21947,    11,  ..., 11208,   685,    31],\n",
            "        ...,\n",
            "        [50256,   284,   502,  ...,    12,    49,    52],\n",
            "        [50256,   284,  1011,  ...,   416, 10948,   406],\n",
            "        [50256,   447,   247,  ...,   447,   247,    82]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2388,   220,  ...,   220,   220,   220],\n",
            "        [50256,   284,  1938,  ...,    12,  3803,  6266],\n",
            "        [50256,  2024,   329,  ...,    90,    40,    92],\n",
            "        ...,\n",
            "        [50256,   530,  3025,  ...,    11,   393, 11991],\n",
            "        [50256,  8209,   290,  ...,   428,  1611,   286],\n",
            "        [50256, 12039,  4149,  ...,  3035,   338, 13850]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  4929,   902,  ...,   616,  2438,   287],\n",
            "        [50256,   576,  2837,  ...,  1544,   635,  6492],\n",
            "        [50256,  1635,   220,  ...,   198,   220,   220],\n",
            "        ...,\n",
            "        [50256,   645,  2300,  ...,  7586,   319,   607],\n",
            "        [50256,     7,    87,  ...,     8,    61,    17],\n",
            "        [50256,  7584,   674,  ...,   198,  1537,  8168]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1624,   326,  ..., 23349,   198,  4178],\n",
            "        [50256,   262,  1271,  ..., 47531,   902,   287],\n",
            "        ...,\n",
            "        [50256,    12,  4965,  ...,  7714,   345,   460],\n",
            "        [50256,   198,   198,  ...,   520,  2607,    13],\n",
            "        [50256,   446,   270,  ...,    33,   349,    58]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    77, 37761,  ...,  4492, 11637, 11769],\n",
            "        [50256,  5124,  8409,  ..., 23588,   874,     7],\n",
            "        [50256,   284, 10176,  ..., 28715,   468,  9555],\n",
            "        ...,\n",
            "        [50256, 34013,   262,  ...,   220,   220,   220],\n",
            "        [50256,   996,  1771,  ...,  1375,  6159,  2982],\n",
            "        [50256, 39280, 11018,  ...,   335,  1747,    11]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286,  2479,  ...,   220,   679, 15463],\n",
            "        [50256,  1607,     7,  ...,   220,   220,   220],\n",
            "        [50256,   290, 40709,  ...,   356,  1541,   423],\n",
            "        ...,\n",
            "        [50256,   318,  3753,  ...,   670,   290,  3640],\n",
            "        [50256,   286,   262,  ..., 10199,   706,   262],\n",
            "        [50256,   655,   307,  ...,   262, 24412,    47]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 34464,  7405,  ...,   287, 19015, 49373],\n",
            "        [50256,   287,  3035,  ..., 24835, 15001,     1],\n",
            "        [50256, 18133,  1619,  ...,    19,    92,   198],\n",
            "        ...,\n",
            "        [50256,   262,  3734,  ...,  9610,    12,  3106],\n",
            "        [50256, 36311,  3419,  ..., 10786,  1065,    25],\n",
            "        [50256,    17,    67,  ...,  7274,   290, 46463]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  2558,   361,  ...,   262, 13214,   326],\n",
            "        [50256,   357,   220,  ...,  1222, 18715,   198],\n",
            "        [50256,    11,   355,  ..., 18268,   416, 10345],\n",
            "        ...,\n",
            "        [50256,    13,  2893,  ...,  1368,    11,   607],\n",
            "        [50256,     6,  2947,  ...,  1502,   284,  5879],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  4959,  ...,   220,   220,   220],\n",
            "        [50256,  4364,   263,  ...,   393, 10561,   306],\n",
            "        [50256,  7753,    13,  ...,    14, 17953,  8979],\n",
            "        ...,\n",
            "        [50256,   617,  5891,  ...,    11,   884,   281],\n",
            "        [50256,   247,    83,  ...,   661,   508,   423],\n",
            "        [50256,   220,   220,  ...,   198,   220,  2608]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 980, Loss: 5.3619\n",
            "tensor([[50256,   992,    67,  ...,  1558, 44242, 13705],\n",
            "        [50256,   257,  2440,  ...,   770,   318,   635],\n",
            "        [50256,   286,   262,  ...,  7123,   286,  1294],\n",
            "        ...,\n",
            "        [50256,    11, 15268,  ...,   406,   620,   261],\n",
            "        [50256,    79,    13,  ...,   286,  2587,   345],\n",
            "        [50256,    11,  1910,  ...,     6, 10944,  3881]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   355,   880,  ...,  4661,   286,   262],\n",
            "        [50256,  5397,   415,  ...,   286,   465,  9709],\n",
            "        [50256, 13869,   780,  ...,  4409,   981,   262],\n",
            "        ...,\n",
            "        [50256, 33124,   290,  ...,  2479,    11,  6001],\n",
            "        [50256,   290,  2594,  ...,  7133,   198,   198],\n",
            "        [50256,   220,   220,  ...,  1058,   318,    62]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    15,     3,  ...,  1553,     3,   290],\n",
            "        [50256,  3288,  1692,  ..., 50006,   543,   318],\n",
            "        [50256,   466,   428,  ...,   290,   314,   373],\n",
            "        ...,\n",
            "        [50256, 18712, 13559,  ..., 25597,    59, 35138],\n",
            "        [50256,  5528,   776,  ...,   656,  9751,    13],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  1981,  ...,  4339,    40,    26],\n",
            "        [50256,  1064,   530,  ...,   749, 32460,  1517],\n",
            "        [50256, 17716,    90,  ...,   355,   281,   720],\n",
            "        ...,\n",
            "        [50256,  4521,    33,  ..., 19160, 12240, 32057],\n",
            "        [50256, 31944,    90,  ...,    17, 10779,    59],\n",
            "        [50256,   318,  5447,  ...,    12,  1102,  9275]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256, 12952,    14,  ..., 20245,    11,  1105],\n",
            "        [50256,  1049, 12607,  ...,   389, 36841,  1365],\n",
            "        [50256,   318,    11,  ..., 11406,   284,  3342],\n",
            "        ...,\n",
            "        [50256,  1943,   286,  ...,    51,  1313,    11],\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,   198,   198,  ...,     3, 23214,    13]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   332,   353,  ...,   475,   314,   460],\n",
            "        [50256,  3640,    13,  ...,    12,  2433,  5444],\n",
            "        [50256,   319,  8969,  ..., 19811,    13,   770],\n",
            "        ...,\n",
            "        [50256,   290,   198,  ...,   685,  4349,    60],\n",
            "        [50256,   625,  1992,  ...,  1665,   844,    68],\n",
            "        [50256,  9007,  4788,  ...,  3741,   286,  3640]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   262,  2276,  ...,   355,   281,  1593],\n",
            "        [50256, 19332,  1583,  ...,  4007,   284,  1037],\n",
            "        [50256,   532,   352,  ...,   197,   197,  4871],\n",
            "        ...,\n",
            "        [50256,   287,  2166,  ...,   284,  4152,   526],\n",
            "        [50256,   796,   953,  ...,    58,   944,    13],\n",
            "        [50256,   198,    15,  ...,    87,  5777,  5237]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   393,   326,  ...,   262,  1812,   447],\n",
            "        [50256,  2441,  7274,  ...,    81,  1512, 16237],\n",
            "        [50256,   284,  1950,  ...,   373,   326,  5788],\n",
            "        ...,\n",
            "        [50256,   198,   532,  ...,   220,   220,   220],\n",
            "        [50256,  2504,   815,  ...,   286,   281,  9572],\n",
            "        [50256, 12425,    93,  ...,  4764,    50,   350]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3672,    13,  ...,   953,    62,  3672],\n",
            "        [50256,   785, 11139,  ..., 11139,    83,    18],\n",
            "        [50256,   284,   823,  ...,   326, 32382,    59],\n",
            "        ...,\n",
            "        [50256, 10345,  3975,  ...,  4778,    11, 10712],\n",
            "        [50256, 48963, 11672,  ..., 41475,    13,   198],\n",
            "        [50256,    15,    11,  ...,    11,  3467, 29992]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    25,   198,  ...,   198, 11505,   534],\n",
            "        [50256,   278,  3690,  ..., 40699, 33138,  5929],\n",
            "        [50256,   198,   197,  ...,    15,  5320,   198],\n",
            "        ...,\n",
            "        [50256,   198,  1135,  ...,   835,   326,  3751],\n",
            "        [50256,  8861,   287,  ...,  2761,   286,  5361],\n",
            "        [50256,   357, 16632,  ..., 13650,   373,  5545]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 990, Loss: 6.2861\n",
            "tensor([[50256,  3467,    12,  ...,   220,   220,   220],\n",
            "        [50256,  4006,   410,  ...,    11,   198,   197],\n",
            "        [50256,  6103,  2523,  ...,   642,  3980,    11],\n",
            "        ...,\n",
            "        [50256,   220,   220,  ...,   220,   220,   220],\n",
            "        [50256,  1085,   706,  ...,   447,   251,  1976],\n",
            "        [50256,     3,  1849,  ..., 23330,    15,    92]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   379,   262,  ...,   262,  9443,   351],\n",
            "        [50256,   416, 16217,  ...,  8264,    82,   357],\n",
            "        [50256,   994,    11,  ...,  1016,   656,  1165],\n",
            "        ...,\n",
            "        [50256, 19253,   290,  ...,   257, 12147, 28773],\n",
            "        [50256,   220,   220,  ...,   249, 28938,   245],\n",
            "        [50256,   720,  3803,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  8936,     8,  ..., 21737,  3891,   796],\n",
            "        [50256,   262,  1578,  ..., 32281,    11, 42257],\n",
            "        [50256,   373,  3402,  ...,   259,  6184,   120],\n",
            "        ...,\n",
            "        [50256,  4248,    21,  ...,  1752,    12, 39624],\n",
            "        [50256,  1093,  1513,  ...,   379,   670,    13],\n",
            "        [50256,    62,   389,  ...,  3584,   465,   749]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    89, 47505,  ...,   262,   720,    49],\n",
            "        [50256,  6506,  1276,  ...,  2299, 15152,  3875],\n",
            "        [50256,    13,   198,  ...,   691,   706,  2506],\n",
            "        ...,\n",
            "        [50256,   991,   503,  ...,  2546,  1776,   198],\n",
            "        [50256,    13,  7055,  ...,     1,   286, 29178],\n",
            "        [50256,   198,  6248,  ...,   198,  2364,  1063]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   286, 14733,  ...,  1561,   546,   340],\n",
            "        [50256, 26959,  8987,  ..., 11860,    50,  2474],\n",
            "        [50256, 29885,  1771,  ...,   605,  9030,   329],\n",
            "        ...,\n",
            "        [50256,   198,   197,  ...,    26,   201,   198],\n",
            "        [50256,   447,   250,  ...,  1110,   706,  1110],\n",
            "        [50256,     1,   220,  ...,   220,   220,   220]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    12, 21186,  ...,    13,  1849,    58],\n",
            "        [50256,   198,    20,  ...,    17, 27493, 32590],\n",
            "        [50256,  1394,  9088,  ...,  5794,  8966,  1666],\n",
            "        ...,\n",
            "        [50256,   197,   197,  ..., 25138,  1222,  1391],\n",
            "        [50256,  9179,   281,  ...,   286, 40123,  8200],\n",
            "        [50256,   611,   345,  ...,   274,  1701,  1526]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  3574,   607,  ...,    11,   996,   339],\n",
            "        [50256,  9803,   286,  ...,  8224,   780,   286],\n",
            "        [50256,  4018,   286,  ...,   484,   389,   407],\n",
            "        ...,\n",
            "        [50256,    13,  3981,  ...,    13, 10863,  1921],\n",
            "        [50256,   928, 29690,  ..., 21356,  2528,    72],\n",
            "        [50256,    12, 15813,  ...,   262,  1266,   835]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,    92,    28,  ...,  1176, 10958,   720],\n",
            "        [50256,    13,    16,  ...,    12,  4906,  2625],\n",
            "        [50256,  2034,   695,  ...,   220,   220,   220],\n",
            "        ...,\n",
            "        [50256,  8213,    13,  ...,    13,  2102,    11],\n",
            "        [50256, 24843,   362,  ...,     1,   198,   220],\n",
            "        [50256, 32239,  5183,  ...,    12,    59,  5183]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,   717,   366,  ...,  1336, 28686,   325],\n",
            "        [50256,    18,    60,  ...,    92,   198,   198],\n",
            "        [50256,   262,  2811,  ...,   417,  1746,    11],\n",
            "        ...,\n",
            "        [50256,  1174,    17,  ...,   532,   352,     8],\n",
            "        [50256,   286,   883,  ...,    13,   198,   198],\n",
            "        [50256,   262,  2479,  ..., 17701,   935,   314]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "tensor([[50256,  5499,   286,  ..., 37295,   282, 11709],\n",
            "        [50256, 37914,    82,  ...,    11,   329,  1672],\n",
            "        [50256,   262,  4916,  ...,   423,  5081,   428],\n",
            "        ...,\n",
            "        [50256,  2346,   257,  ...,  3292,    12,  8210],\n",
            "        [50256,    13,   383,  ...,  1222, 17356,   461],\n",
            "        [50256,    83,  1577,  ...,   407, 37677,  2569]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n",
            "Step: 1000, Loss: 6.3125\n",
            "tensor([[50256, 15453,  2163,  ..., 28015,  1142,    12],\n",
            "        [50256,   416, 16869,  ...,  1429,   357, 10508],\n",
            "        [50256,   198,   220,  ...,   220,  1303,   361],\n",
            "        ...,\n",
            "        [50256,   286,  5242,  ..., 49614,   477,   663],\n",
            "        [50256,  8106,  1245,  ...,    35,     8,  7446],\n",
            "        [50256,   428,   318,  ...,  4697, 44511,   290]], device='cuda:0')\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "print(\"Number of batches:\", len(data_loader))\n",
        "for epoch in range(num_epochs):\n",
        "    for c, batch in tqdm.tqdm(enumerate(data_loader)):\n",
        "        tokens = batch['tokens'].cuda()\n",
        "        logits = model(tokens)\n",
        "        loss = lm_cross_entropy_loss(logits, tokens)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        losses.append(loss.item())\n",
        "        if c % log_every == 0:\n",
        "            print(f\"Step: {c}, Loss: {loss.item():.4f}\")\n",
        "        if c > max_steps:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn5hPQkc7Jzx"
      },
      "source": [
        "We can now plot a loss curve!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2BsLaOV7Jzx",
        "outputId": "6dca91be-259c-4933-db73-fdf8e043a0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"367d0cf8-b29b-4dc3-bfaa-16db612d5474\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"367d0cf8-b29b-4dc3-bfaa-16db612d5474\")) {                    Plotly.newPlot(                        \"367d0cf8-b29b-4dc3-bfaa-16db612d5474\",                        [{\"hovertemplate\":\"Tokens=%{x}<br>Loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,2048,4096,6144,8192,10240,12288,14336,16384,18432,20480,22528,24576,26624,28672,30720,32768,34816,36864,38912,40960,43008,45056,47104,49152,51200,53248,55296,57344,59392,61440,63488,65536,67584,69632,71680,73728,75776,77824,79872,81920,83968,86016,88064,90112,92160,94208,96256,98304,100352,102400,104448,106496,108544,110592,112640,114688,116736,118784,120832,122880,124928,126976,129024,131072,133120,135168,137216,139264,141312,143360,145408,147456,149504,151552,153600,155648,157696,159744,161792,163840,165888,167936,169984,172032,174080,176128,178176,180224,182272,184320,186368,188416,190464,192512,194560,196608,198656,200704,202752,204800,206848,208896,210944,212992,215040,217088,219136,221184,223232,225280,227328,229376,231424,233472,235520,237568,239616,241664,243712,245760,247808,249856,251904,253952,256000,258048,260096,262144,264192,266240,268288,270336,272384,274432,276480,278528,280576,282624,284672,286720,288768,290816,292864,294912,296960,299008,301056,303104,305152,307200,309248,311296,313344,315392,317440,319488,321536,323584,325632,327680,329728,331776,333824,335872,337920,339968,342016,344064,346112,348160,350208,352256,354304,356352,358400,360448,362496,364544,366592,368640,370688,372736,374784,376832,378880,380928,382976,385024,387072,389120,391168,393216,395264,397312,399360,401408,403456,405504,407552,409600,411648,413696,415744,417792,419840,421888,423936,425984,428032,430080,432128,434176,436224,438272,440320,442368,444416,446464,448512,450560,452608,454656,456704,458752,460800,462848,464896,466944,468992,471040,473088,475136,477184,479232,481280,483328,485376,487424,489472,491520,493568,495616,497664,499712,501760,503808,505856,507904,509952,512000,514048,516096,518144,520192,522240,524288,526336,528384,530432,532480,534528,536576,538624,540672,542720,544768,546816,548864,550912,552960,555008,557056,559104,561152,563200,565248,567296,569344,571392,573440,575488,577536,579584,581632,583680,585728,587776,589824,591872,593920,595968,598016,600064,602112,604160,606208,608256,610304,612352,614400,616448,618496,620544,622592,624640,626688,628736,630784,632832,634880,636928,638976,641024,643072,645120,647168,649216,651264,653312,655360,657408,659456,661504,663552,665600,667648,669696,671744,673792,675840,677888,679936,681984,684032,686080,688128,690176,692224,694272,696320,698368,700416,702464,704512,706560,708608,710656,712704,714752,716800,718848,720896,722944,724992,727040,729088,731136,733184,735232,737280,739328,741376,743424,745472,747520,749568,751616,753664,755712,757760,759808,761856,763904,765952,768000,770048,772096,774144,776192,778240,780288,782336,784384,786432,788480,790528,792576,794624,796672,798720,800768,802816,804864,806912,808960,811008,813056,815104,817152,819200,821248,823296,825344,827392,829440,831488,833536,835584,837632,839680,841728,843776,845824,847872,849920,851968,854016,856064,858112,860160,862208,864256,866304,868352,870400,872448,874496,876544,878592,880640,882688,884736,886784,888832,890880,892928,894976,897024,899072,901120,903168,905216,907264,909312,911360,913408,915456,917504,919552,921600,923648,925696,927744,929792,931840,933888,935936,937984,940032,942080,944128,946176,948224,950272,952320,954368,956416,958464,960512,962560,964608,966656,968704,970752,972800,974848,976896,978944,980992,983040,985088,987136,989184,991232,993280,995328,997376,999424,1001472,1003520,1005568,1007616,1009664,1011712,1013760,1015808,1017856,1019904,1021952,1024000,1026048,1028096,1030144,1032192,1034240,1036288,1038336,1040384,1042432,1044480,1046528,1048576,1050624,1052672,1054720,1056768,1058816,1060864,1062912,1064960,1067008,1069056,1071104,1073152,1075200,1077248,1079296,1081344,1083392,1085440,1087488,1089536,1091584,1093632,1095680,1097728,1099776,1101824,1103872,1105920,1107968,1110016,1112064,1114112,1116160,1118208,1120256,1122304,1124352,1126400,1128448,1130496,1132544,1134592,1136640,1138688,1140736,1142784,1144832,1146880,1148928,1150976,1153024,1155072,1157120,1159168,1161216,1163264,1165312,1167360,1169408,1171456,1173504,1175552,1177600,1179648,1181696,1183744,1185792,1187840,1189888,1191936,1193984,1196032,1198080,1200128,1202176,1204224,1206272,1208320,1210368,1212416,1214464,1216512,1218560,1220608,1222656,1224704,1226752,1228800,1230848,1232896,1234944,1236992,1239040,1241088,1243136,1245184,1247232,1249280,1251328,1253376,1255424,1257472,1259520,1261568,1263616,1265664,1267712,1269760,1271808,1273856,1275904,1277952,1280000,1282048,1284096,1286144,1288192,1290240,1292288,1294336,1296384,1298432,1300480,1302528,1304576,1306624,1308672,1310720,1312768,1314816,1316864,1318912,1320960,1323008,1325056,1327104,1329152,1331200,1333248,1335296,1337344,1339392,1341440,1343488,1345536,1347584,1349632,1351680,1353728,1355776,1357824,1359872,1361920,1363968,1366016,1368064,1370112,1372160,1374208,1376256,1378304,1380352,1382400,1384448,1386496,1388544,1390592,1392640,1394688,1396736,1398784,1400832,1402880,1404928,1406976,1409024,1411072,1413120,1415168,1417216,1419264,1421312,1423360,1425408,1427456,1429504,1431552,1433600,1435648,1437696,1439744,1441792,1443840,1445888,1447936,1449984,1452032,1454080,1456128,1458176,1460224,1462272,1464320,1466368,1468416,1470464,1472512,1474560,1476608,1478656,1480704,1482752,1484800,1486848,1488896,1490944,1492992,1495040,1497088,1499136,1501184,1503232,1505280,1507328,1509376,1511424,1513472,1515520,1517568,1519616,1521664,1523712,1525760,1527808,1529856,1531904,1533952,1536000,1538048,1540096,1542144,1544192,1546240,1548288,1550336,1552384,1554432,1556480,1558528,1560576,1562624,1564672,1566720,1568768,1570816,1572864,1574912,1576960,1579008,1581056,1583104,1585152,1587200,1589248,1591296,1593344,1595392,1597440,1599488,1601536,1603584,1605632,1607680,1609728,1611776,1613824,1615872,1617920,1619968,1622016,1624064,1626112,1628160,1630208,1632256,1634304,1636352,1638400,1640448,1642496,1644544,1646592,1648640,1650688,1652736,1654784,1656832,1658880,1660928,1662976,1665024,1667072,1669120,1671168,1673216,1675264,1677312,1679360,1681408,1683456,1685504,1687552,1689600,1691648,1693696,1695744,1697792,1699840,1701888,1703936,1705984,1708032,1710080,1712128,1714176,1716224,1718272,1720320,1722368,1724416,1726464,1728512,1730560,1732608,1734656,1736704,1738752,1740800,1742848,1744896,1746944,1748992,1751040,1753088,1755136,1757184,1759232,1761280,1763328,1765376,1767424,1769472,1771520,1773568,1775616,1777664,1779712,1781760,1783808,1785856,1787904,1789952,1792000,1794048,1796096,1798144,1800192,1802240,1804288,1806336,1808384,1810432,1812480,1814528,1816576,1818624,1820672,1822720,1824768,1826816,1828864,1830912,1832960,1835008,1837056,1839104,1841152,1843200,1845248,1847296,1849344,1851392,1853440,1855488,1857536,1859584,1861632,1863680,1865728,1867776,1869824,1871872,1873920,1875968,1878016,1880064,1882112,1884160,1886208,1888256,1890304,1892352,1894400,1896448,1898496,1900544,1902592,1904640,1906688,1908736,1910784,1912832,1914880,1916928,1918976,1921024,1923072,1925120,1927168,1929216,1931264,1933312,1935360,1937408,1939456,1941504,1943552,1945600,1947648,1949696,1951744,1953792,1955840,1957888,1959936,1961984,1964032,1966080,1968128,1970176,1972224,1974272,1976320,1978368,1980416,1982464,1984512,1986560,1988608,1990656,1992704,1994752,1996800,1998848,2000896,2002944,2004992,2007040,2009088,2011136,2013184,2015232,2017280,2019328,2021376,2023424,2025472,2027520,2029568,2031616,2033664,2035712,2037760,2039808,2041856,2043904,2045952,2048000,2050048],\"xaxis\":\"x\",\"y\":[10.896472930908203,10.649871826171875,10.29241943359375,10.184246063232422,9.736441612243652,9.138720512390137,9.67101001739502,9.393624305725098,9.064162254333496,8.790060997009277,7.514914035797119,8.243821144104004,8.262917518615723,7.242853164672852,8.253329277038574,7.840274333953857,8.250359535217285,7.594302654266357,8.12485408782959,8.30430793762207,7.569393634796143,7.208282947540283,7.734805107116699,8.139286994934082,7.33804988861084,7.185346603393555,8.04022216796875,7.111408233642578,7.742318630218506,7.799262523651123,7.383179664611816,8.036449432373047,7.990589618682861,7.66220235824585,7.80496072769165,8.093964576721191,8.104096412658691,7.8291778564453125,6.756611347198486,7.049890518188477,7.839699745178223,6.533968448638916,7.726529121398926,7.844339370727539,6.901150226593018,6.371743202209473,6.8723464012146,8.153303146362305,8.065062522888184,5.962797164916992,7.445861339569092,7.3109331130981445,8.008221626281738,7.477134704589844,7.676771640777588,6.843918800354004,7.1803297996521,6.966917991638184,7.621819496154785,7.779322147369385,6.7333455085754395,6.816803932189941,7.169915676116943,7.097427845001221,6.565755844116211,7.452333450317383,6.77173376083374,7.459644317626953,7.368793487548828,6.668182373046875,7.214612007141113,7.9199137687683105,6.730774879455566,7.371673583984375,8.270964622497559,7.624743938446045,6.092998027801514,7.389029502868652,6.650757312774658,6.837810516357422,6.974813461303711,7.217004299163818,7.051144599914551,7.440073490142822,7.272929668426514,6.759920120239258,7.1793718338012695,6.89608097076416,6.766129016876221,6.071669578552246,7.6794819831848145,6.897643566131592,7.797759056091309,4.949587821960449,7.2831902503967285,7.0978169441223145,7.612791538238525,5.967592716217041,6.340433120727539,7.595343589782715,7.369591236114502,6.60395622253418,7.139337062835693,5.993193626403809,6.790744304656982,7.246029376983643,7.528179168701172,7.469520092010498,7.229902267456055,6.572941303253174,6.605599403381348,6.012829303741455,7.3389387130737305,7.839309215545654,6.6445112228393555,5.660872936248779,6.766288757324219,7.122896671295166,7.644609451293945,7.514073371887207,6.664089679718018,6.937481880187988,6.792517185211182,6.579566955566406,5.970974922180176,6.807806968688965,5.389942169189453,5.545113563537598,6.148905277252197,7.635653018951416,6.356097221374512,6.202085971832275,7.601040840148926,7.611340522766113,7.388883113861084,6.162487506866455,6.081292629241943,7.6139960289001465,7.369604587554932,6.496182441711426,5.968060493469238,6.550771713256836,6.1632208824157715,7.16252326965332,6.980830669403076,6.6289849281311035,5.517934322357178,6.748228549957275,5.9548821449279785,7.195222854614258,6.972643852233887,7.058903217315674,7.141056060791016,6.393178939819336,6.422569751739502,6.835690021514893,6.229984283447266,6.5280256271362305,6.37548828125,6.569228649139404,7.304621696472168,6.119745254516602,7.665460109710693,6.860595703125,6.679319858551025,6.775871276855469,7.296160697937012,6.627458095550537,7.010868549346924,6.92637825012207,6.6269145011901855,7.0658111572265625,7.325143814086914,7.399959564208984,6.160802841186523,7.440094947814941,7.335261344909668,6.664492607116699,5.860925197601318,7.334861755371094,6.493974208831787,7.155978679656982,6.784849166870117,5.136635780334473,6.3918585777282715,6.554736614227295,6.5692243576049805,6.976587772369385,6.667442798614502,5.3443121910095215,7.056867599487305,6.719099044799805,7.01948356628418,6.874370098114014,6.4963202476501465,6.267223358154297,7.316714763641357,7.025234222412109,7.167085647583008,7.01524543762207,5.964258193969727,6.063109397888184,6.603215217590332,7.343660354614258,6.604808807373047,6.036338806152344,7.547696113586426,6.110152721405029,6.468507289886475,7.1070098876953125,6.827847957611084,7.153493881225586,6.120220184326172,7.040360927581787,6.0472235679626465,6.380882740020752,7.104788303375244,6.76039457321167,6.446795463562012,7.24607515335083,6.8850202560424805,5.925319194793701,7.6118597984313965,7.062377452850342,6.7997355461120605,6.310148239135742,7.217709541320801,6.398625373840332,7.252731800079346,6.010005950927734,7.385110855102539,5.394502639770508,6.4809250831604,5.7252197265625,6.729440689086914,6.8787102699279785,5.745416641235352,6.833723068237305,6.274974822998047,6.917370796203613,6.08820104598999,6.412586688995361,5.816028594970703,7.498866081237793,6.25690221786499,6.9448561668396,5.609394550323486,6.564971446990967,6.072396278381348,6.274774551391602,6.347899913787842,6.1931538581848145,6.126065731048584,6.496174335479736,6.577876567840576,7.060482501983643,6.809441566467285,7.3807573318481445,6.025542259216309,6.762639999389648,7.080175399780273,6.689283847808838,7.480740547180176,6.962410926818848,7.296313285827637,7.2696123123168945,7.066152095794678,7.148158550262451,7.295960426330566,5.603607654571533,6.976931095123291,6.247035980224609,6.163269996643066,5.757381916046143,7.073637962341309,7.086264610290527,6.812146186828613,6.819919586181641,6.225144863128662,6.490938663482666,7.0509033203125,6.25497579574585,4.960821151733398,6.2380146980285645,5.614446640014648,6.166778087615967,6.950851917266846,6.397035121917725,6.961339473724365,6.483515739440918,5.616453647613525,6.403929233551025,7.037153720855713,5.990762233734131,5.131038188934326,5.850371837615967,7.148658275604248,5.61220645904541,5.567000389099121,6.470785140991211,7.110090732574463,6.158227443695068,6.1374335289001465,6.469679355621338,5.9516777992248535,6.03797721862793,4.909177303314209,6.339208602905273,7.118636608123779,6.722955226898193,6.302555561065674,6.0106306076049805,6.504010200500488,7.332531452178955,6.473592281341553,7.09199333190918,5.867592811584473,5.705513954162598,6.834621429443359,6.15488862991333,6.831894874572754,6.975423812866211,7.139276504516602,6.249204635620117,6.718136787414551,6.882798671722412,5.460541725158691,7.0552191734313965,6.617654323577881,6.735739707946777,7.05470609664917,7.278626918792725,6.818779945373535,5.0416154861450195,5.86390495300293,5.089584827423096,6.846500873565674,6.620222091674805,6.294544696807861,7.0115275382995605,6.818002700805664,6.410370349884033,6.567370414733887,6.664964199066162,6.211482048034668,7.275457859039307,6.2567291259765625,5.823818206787109,6.443497657775879,6.003129005432129,6.702268600463867,5.028737545013428,6.865860462188721,6.0017170906066895,6.393706798553467,6.072779655456543,6.597579002380371,6.721137046813965,6.264805793762207,6.9214606285095215,5.639466762542725,6.984403133392334,5.537918567657471,4.708134651184082,6.536328315734863,6.076205253601074,6.010740756988525,6.209004878997803,6.5457377433776855,6.32678747177124,5.909273147583008,6.902957916259766,6.066483974456787,6.190511226654053,4.546083927154541,6.841104507446289,5.8812384605407715,5.809978008270264,6.8864216804504395,6.585826873779297,6.869868755340576,5.6697587966918945,6.442049980163574,6.070099353790283,5.846285343170166,6.797760963439941,6.860803127288818,6.260544776916504,7.04921817779541,7.43450927734375,6.4676408767700195,6.578566074371338,5.951355934143066,6.300815105438232,5.6220574378967285,6.726011753082275,6.8024582862854,6.482916831970215,6.694850444793701,6.616177082061768,7.2529120445251465,6.817054748535156,6.759407997131348,6.777517795562744,5.960831642150879,4.567942142486572,5.844524383544922,6.067371368408203,6.034862995147705,5.637198448181152,4.602235794067383,6.309315204620361,6.317496299743652,5.778522968292236,5.715685844421387,6.041024208068848,4.577006816864014,5.949084281921387,6.463957786560059,6.869561672210693,6.86801815032959,6.019073009490967,6.057679176330566,6.590861797332764,6.2150654792785645,5.689148902893066,7.014337062835693,6.7220940589904785,6.461933135986328,6.297605514526367,6.086015224456787,6.269143104553223,5.724635124206543,6.877871513366699,6.393110275268555,6.343127727508545,5.590798854827881,6.707541465759277,6.429413318634033,5.73850679397583,6.651941299438477,5.893059253692627,6.795019149780273,5.882919788360596,6.301055431365967,5.554955005645752,6.474797248840332,6.289332866668701,6.329134464263916,6.304546356201172,6.782632827758789,5.954469203948975,5.236234664916992,6.93798828125,6.568273067474365,6.332435607910156,5.553437232971191,6.648264408111572,5.805734157562256,7.363890171051025,5.7133893966674805,6.211064338684082,7.072641372680664,4.42235803604126,5.548674583435059,6.468390941619873,7.037937164306641,7.161112308502197,5.908481121063232,6.2462968826293945,6.438344478607178,6.632152557373047,6.406430721282959,5.916867733001709,5.924381732940674,5.46143913269043,5.669663429260254,5.829902648925781,6.273947238922119,6.228232383728027,5.802145004272461,5.784634590148926,7.057925701141357,6.471582889556885,5.493085861206055,6.112992763519287,6.583024978637695,5.982860088348389,6.4983320236206055,6.04404354095459,5.909013271331787,5.104674339294434,6.7121758460998535,6.143702507019043,6.677092552185059,4.9858527183532715,6.720542907714844,6.448782444000244,6.094540596008301,5.743159770965576,6.019299507141113,6.261141300201416,6.455882549285889,6.0398783683776855,5.7596869468688965,6.92165994644165,6.163115978240967,7.012482166290283,6.079646587371826,5.662843227386475,6.010019779205322,5.972062110900879,5.10048770904541,6.4498796463012695,6.01425838470459,6.0534443855285645,5.764902591705322,6.103679180145264,5.988709449768066,6.666451930999756,6.560019493103027,6.751781940460205,6.851278305053711,6.776527404785156,5.910150051116943,5.2517476081848145,6.7209062576293945,6.294642925262451,5.198061943054199,5.68263053894043,5.986272811889648,6.4107770919799805,5.318942546844482,5.878829479217529,6.110905647277832,6.447474002838135,6.408974647521973,5.770125389099121,6.438174724578857,5.9181647300720215,5.56285285949707,6.224276542663574,6.296618938446045,6.100960731506348,6.050637722015381,5.934208869934082,6.531025409698486,6.496581554412842,5.700477600097656,6.565980434417725,5.005342483520508,6.541269779205322,6.795907497406006,5.562687397003174,6.1887288093566895,6.642096042633057,6.616131782531738,5.63770055770874,6.025721549987793,6.536953926086426,6.120560646057129,6.287254333496094,5.683629512786865,6.502284526824951,5.580868244171143,7.413753509521484,6.878627300262451,5.259069442749023,6.802571773529053,5.418169021606445,5.052421569824219,6.703500747680664,6.755110263824463,6.2881317138671875,5.603967666625977,6.48527717590332,5.185421943664551,5.684944152832031,5.772030353546143,5.979978084564209,6.28797721862793,5.39696741104126,6.014667987823486,6.809011459350586,5.7158894538879395,6.243654727935791,5.939530849456787,6.172684192657471,6.271775722503662,6.236772060394287,5.1565117835998535,6.51466703414917,6.820234298706055,5.861982345581055,5.612056255340576,6.001986026763916,6.6070427894592285,4.8086137771606445,6.480127334594727,5.7932047843933105,5.0954813957214355,5.950100898742676,5.377420902252197,5.207622528076172,6.319263458251953,5.877720355987549,6.484279632568359,6.366223335266113,5.969048023223877,5.793450355529785,6.157839775085449,7.019706726074219,5.241933822631836,5.326191425323486,6.110030174255371,6.28408145904541,5.419315814971924,6.4786057472229,5.582111835479736,6.106991291046143,5.58944845199585,6.6099395751953125,5.882940292358398,5.906082630157471,5.048774719238281,6.343378067016602,5.813185691833496,6.640336990356445,6.726967811584473,6.510344505310059,6.467225074768066,5.8729705810546875,5.368085861206055,6.261070251464844,6.175673007965088,4.424572944641113,4.79524564743042,4.709039211273193,5.931037425994873,6.412145614624023,5.439438343048096,6.955881118774414,6.090803623199463,6.086918354034424,5.4774980545043945,6.4299211502075195,6.878376483917236,5.949400901794434,6.597194194793701,6.080079555511475,6.732656002044678,5.424319267272949,6.746528625488281,6.012312889099121,6.2112507820129395,6.3882269859313965,6.607003688812256,6.322328567504883,6.084603309631348,6.483201503753662,6.1647233963012695,6.1935715675354,6.4325456619262695,5.515254497528076,6.590915203094482,5.851435661315918,6.729544162750244,4.292140483856201,5.630667209625244,6.572243690490723,5.690135955810547,6.331210136413574,5.47109842300415,5.859545707702637,6.590108394622803,6.522262096405029,6.09503173828125,6.34695291519165,5.051654815673828,6.08450174331665,6.408421039581299,6.5598835945129395,6.027889251708984,4.5640435218811035,5.71299934387207,6.707309722900391,6.804598331451416,5.482250213623047,6.677924156188965,6.249630451202393,5.655696392059326,6.062164306640625,4.037267684936523,5.805892467498779,6.824724197387695,6.322749614715576,5.973834037780762,5.1924943923950195,6.530954837799072,5.795783042907715,5.724455833435059,5.55624532699585,5.94681978225708,5.995652675628662,5.762392997741699,5.945558071136475,6.778882026672363,4.943816184997559,5.688751697540283,5.342618465423584,5.23687219619751,5.88346004486084,6.71122407913208,6.147095680236816,6.116106986999512,5.244203567504883,5.882439613342285,6.28868293762207,5.918531894683838,5.738738536834717,6.488831996917725,4.808736801147461,6.45804500579834,6.321629524230957,5.511750221252441,6.60051155090332,5.82101583480835,5.864964008331299,6.147750377655029,5.746034622192383,5.587398052215576,5.591851711273193,6.034257888793945,6.566890716552734,5.270284175872803,6.450591087341309,5.871592044830322,6.27473783493042,5.785889625549316,6.497488975524902,5.835293292999268,5.974371910095215,5.845915794372559,5.537903785705566,6.097476005554199,5.970692157745361,5.902703762054443,6.3077850341796875,5.98158073425293,6.473354816436768,4.998295783996582,6.0326361656188965,6.500081539154053,5.0267333984375,6.1709394454956055,4.426368236541748,6.161679267883301,6.228329181671143,5.2939534187316895,6.302347183227539,5.990569114685059,6.186751842498779,4.291895866394043,5.967931747436523,4.633901119232178,6.0116472244262695,6.525629997253418,6.272889137268066,5.108316898345947,3.8719944953918457,6.474656581878662,6.145728588104248,6.144382953643799,6.508737564086914,6.444880962371826,4.456088542938232,6.183814525604248,5.521866798400879,6.2248945236206055,4.3636579513549805,6.280621528625488,4.997166633605957,6.159142971038818,5.801441669464111,6.441763401031494,6.488875389099121,6.374115467071533,6.454779624938965,5.2780866622924805,4.778683662414551,6.249582290649414,6.239433288574219,6.577775001525879,5.908884048461914,5.651880741119385,6.659267425537109,6.0489654541015625,4.68060302734375,6.808619499206543,5.980703830718994,4.649306297302246,6.0607733726501465,6.518980026245117,6.71677303314209,6.553688049316406,5.284183025360107,6.852456092834473,5.638508319854736,5.688324451446533,6.308634281158447,5.778197288513184,6.636101722717285,5.829906940460205,6.329143524169922,6.027944087982178,4.349518775939941,6.318879127502441,6.507206916809082,6.4684271812438965,6.534997463226318,6.357846260070801,6.842790126800537,6.226524353027344,6.088705062866211,6.827549934387207,6.55141544342041,5.940606117248535,5.549765586853027,6.349532604217529,5.810800552368164,5.839712619781494,6.76250696182251,5.811163902282715,4.860501289367676,6.247264385223389,5.471333980560303,6.112584590911865,5.27297830581665,5.469363212585449,6.765324592590332,4.592109203338623,6.305266380310059,6.2779364585876465,5.606800079345703,4.809711456298828,5.515326023101807,5.412936687469482,6.003257751464844,6.363229751586914,5.773120880126953,6.0918288230896,6.320509910583496,6.4840922355651855,6.035176753997803,6.177326202392578,6.80352258682251,6.456826686859131,6.651752471923828,5.752295970916748,6.222376823425293,5.9720306396484375,5.8889265060424805,5.608626842498779,6.240954875946045,5.390066146850586,6.200374126434326,6.840806484222412,6.018977165222168,6.403931617736816,6.69838809967041,5.822666645050049,5.720919609069824,5.538036346435547,5.925207138061523,6.105652809143066,5.460805892944336,6.247219085693359,6.2476959228515625,5.805757999420166,6.040390491485596,5.974035263061523,5.19677209854126,6.253490924835205,6.079061985015869,6.43535852432251,6.1136651039123535,6.1811933517456055,6.219644546508789,5.580427169799805,5.6842360496521,5.214226245880127,4.548379421234131,6.5352582931518555,6.305038928985596,4.259832859039307,5.43022346496582,4.691533088684082,5.423250675201416,6.153997421264648,5.8514790534973145,4.375926971435547,6.083535194396973,5.303853511810303,5.913130283355713,6.116579055786133,5.416950225830078,5.264775276184082,5.7069597244262695,4.879110336303711,6.1907219886779785,6.310817718505859,6.127166271209717,6.3035888671875,6.098214149475098,6.046891689300537,4.938118934631348,5.882304668426514,5.277460098266602,5.711557388305664,6.318455219268799,5.701699733734131,5.741060733795166,5.962649822235107,6.056667327880859,6.188363552093506,5.727383136749268,6.047022342681885,6.392878532409668,5.413839340209961,3.8876514434814453,5.4619550704956055,5.718979358673096,5.924065113067627,4.56587028503418,6.6959733963012695,6.025166988372803,5.889212131500244,4.911199569702148,6.4565253257751465,6.079008102416992,5.613343238830566,5.955289840698242,4.933139324188232,5.476666450500488,5.3304009437561035,6.067165851593018,5.835884094238281,6.476286888122559,5.457880020141602,6.2615132331848145,5.446887969970703,5.546850204467773,5.243153095245361,5.399294853210449,5.411843299865723,6.002954959869385,6.128457546234131,5.602977752685547,5.098181247711182,6.220280170440674,6.5000457763671875,5.083747386932373,6.096358299255371,4.988689422607422,5.413239479064941,6.243941307067871,5.2412285804748535,6.344566822052002,5.837466716766357,6.362389087677002,6.306844234466553,5.5571208000183105,6.350971698760986,5.616594314575195,6.234707355499268,5.715383052825928,5.385784149169922,5.938840866088867,5.494586944580078,5.059380054473877,5.361886978149414,6.586494445800781,5.619628429412842,5.86137056350708,4.917750835418701,5.7028279304504395,6.64005184173584,5.461989879608154,5.434953689575195,5.807638645172119,6.286146640777588,5.158875465393066,5.382192611694336,6.827823162078857,6.140214443206787,5.531525135040283,5.648279666900635,6.0659050941467285,5.475057125091553,5.861231803894043,6.31248140335083,6.128532886505127],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training curve for my tiny demo model!\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('367d0cf8-b29b-4dc3-bfaa-16db612d5474');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "px.line(y=losses, x=np.arange(len(losses))*(model_cfg.n_ctx * batch_size), labels={\"y\":\"Loss\", \"x\":\"Tokens\"}, title=\"Training curve for my tiny demo model!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c30318134664f168e12411f7b3a62f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a665a4d63c7a4235a0088e5152caedb8",
              "IPY_MODEL_785d4e1d191740b792eb82a0fbca147e",
              "IPY_MODEL_3354c61b535d4c8485283a5e0a77b866"
            ],
            "layout": "IPY_MODEL_b12d76a2023244deb30549f54935e55f"
          }
        },
        "a665a4d63c7a4235a0088e5152caedb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3bc9a80e4af4496b0bb2da5244839b1",
            "placeholder": "​",
            "style": "IPY_MODEL_dea4a4e76c1b40909b139dd96d01dc9d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "785d4e1d191740b792eb82a0fbca147e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd490f1a65a49ca8049bc5c122765f0",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfd851b6d7e04997a8c40863102488a8",
            "value": 665
          }
        },
        "3354c61b535d4c8485283a5e0a77b866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d16a076a624732b664d90a81a96708",
            "placeholder": "​",
            "style": "IPY_MODEL_27c7246ac0244c71bafdda41d04e85e6",
            "value": " 665/665 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "b12d76a2023244deb30549f54935e55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3bc9a80e4af4496b0bb2da5244839b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea4a4e76c1b40909b139dd96d01dc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecd490f1a65a49ca8049bc5c122765f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd851b6d7e04997a8c40863102488a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68d16a076a624732b664d90a81a96708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c7246ac0244c71bafdda41d04e85e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed26b3003ac24289b6b3acea3fc0a7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9118cb1a05140bca887dc4678877f5d",
              "IPY_MODEL_0731a7d3b8b74bbdb3ac32a0c7d1620f",
              "IPY_MODEL_795b04f0100442fc9641201c6a06f859"
            ],
            "layout": "IPY_MODEL_15921f8ab3d74ed6a6efd31f632690ee"
          }
        },
        "a9118cb1a05140bca887dc4678877f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffeb1ffc66114f3c8645b8bdbce7972d",
            "placeholder": "​",
            "style": "IPY_MODEL_15e64db013e24322b5bf432ec8ca67b4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0731a7d3b8b74bbdb3ac32a0c7d1620f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb37bca3f3d491b897560f7436997b5",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f61505ce2a6041d5802ea21e14ab6aba",
            "value": 548118077
          }
        },
        "795b04f0100442fc9641201c6a06f859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca6cf771a45a4ef084c9aeebe63f8187",
            "placeholder": "​",
            "style": "IPY_MODEL_3bfc16f854ee42399966335b47fad6e0",
            "value": " 548M/548M [00:03&lt;00:00, 174MB/s]"
          }
        },
        "15921f8ab3d74ed6a6efd31f632690ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffeb1ffc66114f3c8645b8bdbce7972d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e64db013e24322b5bf432ec8ca67b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eb37bca3f3d491b897560f7436997b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61505ce2a6041d5802ea21e14ab6aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca6cf771a45a4ef084c9aeebe63f8187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bfc16f854ee42399966335b47fad6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c078745fe92e438d88d2f3a66996cccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16877803dc85458d883fd19ecd4ac97d",
              "IPY_MODEL_57fd56fed32d4f9caa2df70eab7686dd",
              "IPY_MODEL_8cb9883ec9354d00880f5b5b2c66156c"
            ],
            "layout": "IPY_MODEL_9b93ac4f95e94b2db46e573082f96d75"
          }
        },
        "16877803dc85458d883fd19ecd4ac97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366cf2be416048e9bf4052626eac95ad",
            "placeholder": "​",
            "style": "IPY_MODEL_54d9e176d29a4389b0a2c7ed10b84dc8",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "57fd56fed32d4f9caa2df70eab7686dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a81c990369a41a38c7996fcfc7a192f",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0cd8e707d684bc08b5c9e417b4c8406",
            "value": 124
          }
        },
        "8cb9883ec9354d00880f5b5b2c66156c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d698479af18a4a2d9233e8b040c7daf3",
            "placeholder": "​",
            "style": "IPY_MODEL_900ade6ec3ab432a8026211731b6231a",
            "value": " 124/124 [00:00&lt;00:00, 3.76kB/s]"
          }
        },
        "9b93ac4f95e94b2db46e573082f96d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366cf2be416048e9bf4052626eac95ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d9e176d29a4389b0a2c7ed10b84dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a81c990369a41a38c7996fcfc7a192f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0cd8e707d684bc08b5c9e417b4c8406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d698479af18a4a2d9233e8b040c7daf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900ade6ec3ab432a8026211731b6231a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2968fcf539d94e688d5c7f9cb1b2b06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef1bd836722d4f9e9449e899640f09e2",
              "IPY_MODEL_0c9c0c87522442a7ad2a37d00506416d",
              "IPY_MODEL_f8d98132fb084c43bcfa7ea1245bcd9b"
            ],
            "layout": "IPY_MODEL_4e977cd076f74fd88f7664ea5a9c188b"
          }
        },
        "ef1bd836722d4f9e9449e899640f09e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25152be211964fda98e98bb6a8b0813e",
            "placeholder": "​",
            "style": "IPY_MODEL_1538fc0676ea47a09732ea64a9fbd4d6",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "0c9c0c87522442a7ad2a37d00506416d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_736d08ef15644c3b8a804b9b31b223ca",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_356cfd8a2a864a5bb8a70288d5e7ee57",
            "value": 1042301
          }
        },
        "f8d98132fb084c43bcfa7ea1245bcd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5e3c86d2e714e51899b8507ce365d72",
            "placeholder": "​",
            "style": "IPY_MODEL_1c100f8a119045509f112fae376a9c2b",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.22MB/s]"
          }
        },
        "4e977cd076f74fd88f7664ea5a9c188b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25152be211964fda98e98bb6a8b0813e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1538fc0676ea47a09732ea64a9fbd4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "736d08ef15644c3b8a804b9b31b223ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356cfd8a2a864a5bb8a70288d5e7ee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5e3c86d2e714e51899b8507ce365d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c100f8a119045509f112fae376a9c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e72bd63cef34784952a966aeb47b3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_904e1067414947bdae0586d09faefc24",
              "IPY_MODEL_ee3d7ca85b0d4363acf8a7b97b02c40c",
              "IPY_MODEL_5fd1fd15188b42d988bfe9f5030aaa22"
            ],
            "layout": "IPY_MODEL_49f694fedee648e4bdd6916574f4d300"
          }
        },
        "904e1067414947bdae0586d09faefc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e9833bf6fd4e2b8f229bdc7f9978f0",
            "placeholder": "​",
            "style": "IPY_MODEL_5939f3370daf4652a487a7186fdec46e",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "ee3d7ca85b0d4363acf8a7b97b02c40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce383db458ef45099ec45f6e3eb5c200",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b39e85abdc104e37b647a5e47571e2b1",
            "value": 456318
          }
        },
        "5fd1fd15188b42d988bfe9f5030aaa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c7e5676ddb40aa84bd195e5212101b",
            "placeholder": "​",
            "style": "IPY_MODEL_a63431715d674042b669ce7b3af9b4d7",
            "value": " 456k/456k [00:00&lt;00:00, 2.44MB/s]"
          }
        },
        "49f694fedee648e4bdd6916574f4d300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e9833bf6fd4e2b8f229bdc7f9978f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5939f3370daf4652a487a7186fdec46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce383db458ef45099ec45f6e3eb5c200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39e85abdc104e37b647a5e47571e2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9c7e5676ddb40aa84bd195e5212101b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63431715d674042b669ce7b3af9b4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ffa8defe964a299e3729c2eaf4b7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_744bafb36e824d718753e93d98cba113",
              "IPY_MODEL_c367d34375a142e7a62295211c4b82e3",
              "IPY_MODEL_b9c19c1f5b264843a0bbb74a8103dacd"
            ],
            "layout": "IPY_MODEL_c961d3f21a594f7da39adfe1e07693e9"
          }
        },
        "744bafb36e824d718753e93d98cba113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7dc039c3ee04b39873821b8431a3d00",
            "placeholder": "​",
            "style": "IPY_MODEL_d92b0148dcb544349a03045f1120db05",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "c367d34375a142e7a62295211c4b82e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374c5fd721db4315b28ab889fbb24090",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22e16cf24cd84e8f98c860840ea38fe5",
            "value": 1355256
          }
        },
        "b9c19c1f5b264843a0bbb74a8103dacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50d96ce16e6245f5a1ca3e7953f46bef",
            "placeholder": "​",
            "style": "IPY_MODEL_ac1e4bf2d44b4aaca7d072b3ca7bd7e3",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.28MB/s]"
          }
        },
        "c961d3f21a594f7da39adfe1e07693e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7dc039c3ee04b39873821b8431a3d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92b0148dcb544349a03045f1120db05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374c5fd721db4315b28ab889fbb24090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e16cf24cd84e8f98c860840ea38fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50d96ce16e6245f5a1ca3e7953f46bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1e4bf2d44b4aaca7d072b3ca7bd7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9923328fb94543dfa84e74e74d9deeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30bb7c1e945f46bb853190c5246284f6",
              "IPY_MODEL_5065866f0a0a4b7fbbd654786b7bc589",
              "IPY_MODEL_62b5b2758f624b6e93b126baf95bdf1b"
            ],
            "layout": "IPY_MODEL_a3e1eaa2a8304815bbc4566be63446a5"
          }
        },
        "30bb7c1e945f46bb853190c5246284f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d614ef7fac44d6190061515f54beb34",
            "placeholder": "​",
            "style": "IPY_MODEL_a2cdd9fe080445bc889174b8b030663e",
            "value": "100%"
          }
        },
        "5065866f0a0a4b7fbbd654786b7bc589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980baaacbcbf4c0bb28a8728e331eb5a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_530eb000fef64444a7a5ace0fcdd8f40",
            "value": 100
          }
        },
        "62b5b2758f624b6e93b126baf95bdf1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20d91b872e746dc98a17f0c2618a415",
            "placeholder": "​",
            "style": "IPY_MODEL_73b57cebf7ce42069376f773a3e55c2a",
            "value": " 100/100 [00:05&lt;00:00, 16.84it/s]"
          }
        },
        "a3e1eaa2a8304815bbc4566be63446a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d614ef7fac44d6190061515f54beb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2cdd9fe080445bc889174b8b030663e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "980baaacbcbf4c0bb28a8728e331eb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530eb000fef64444a7a5ace0fcdd8f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a20d91b872e746dc98a17f0c2618a415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b57cebf7ce42069376f773a3e55c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a100131cd0ff4eb594f019bc64731897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8df534a71d4a45e3ac4cdbabc7216161",
              "IPY_MODEL_9ee36679a49c49ecb71adb137b09a5f2",
              "IPY_MODEL_3e0beb0637db4fc2a13bd56fefc1c18a"
            ],
            "layout": "IPY_MODEL_d9a2b96c4d56494393e7afee8f2dd903"
          }
        },
        "8df534a71d4a45e3ac4cdbabc7216161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4760e3d486204495a6d880043e7e038c",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab76bdf66c54fc18d127855e192b88d",
            "value": "Downloading metadata: 100%"
          }
        },
        "9ee36679a49c49ecb71adb137b09a5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62faa33ab67846308000c578f0bed0b0",
            "max": 921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b14439f9f66f4866b64d6ef0e9e9f9e7",
            "value": 921
          }
        },
        "3e0beb0637db4fc2a13bd56fefc1c18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc999af42e34ff5bceb95fcf005d122",
            "placeholder": "​",
            "style": "IPY_MODEL_1d22a3e662fd45e7861526fc590d55ac",
            "value": " 921/921 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "d9a2b96c4d56494393e7afee8f2dd903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4760e3d486204495a6d880043e7e038c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab76bdf66c54fc18d127855e192b88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62faa33ab67846308000c578f0bed0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14439f9f66f4866b64d6ef0e9e9f9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bc999af42e34ff5bceb95fcf005d122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d22a3e662fd45e7861526fc590d55ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db1215247d6549708f5882a8e3e0e06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6705ae3aba84ef0a4be3d2af71b76fe",
              "IPY_MODEL_7cec327169d5459ba34c51ec9be96958",
              "IPY_MODEL_b5be4aa6309144a9bee4c3b097a651b0"
            ],
            "layout": "IPY_MODEL_d213fca3d962414398363b8d80302de2"
          }
        },
        "a6705ae3aba84ef0a4be3d2af71b76fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a270754e3546e0984b45318cd21e68",
            "placeholder": "​",
            "style": "IPY_MODEL_452c61deeca44e8fa8bca082e21228d1",
            "value": "Downloading readme: 100%"
          }
        },
        "7cec327169d5459ba34c51ec9be96958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5e387680b64eec8ee11dc041187636",
            "max": 373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c458efe2eff4d76befbcae0d37edcae",
            "value": 373
          }
        },
        "b5be4aa6309144a9bee4c3b097a651b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df4066eb1e540a2a3f1d7d2cd8048d5",
            "placeholder": "​",
            "style": "IPY_MODEL_8d752366d6cd4eb6b30fe924c87740a6",
            "value": " 373/373 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "d213fca3d962414398363b8d80302de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a270754e3546e0984b45318cd21e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452c61deeca44e8fa8bca082e21228d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b5e387680b64eec8ee11dc041187636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c458efe2eff4d76befbcae0d37edcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6df4066eb1e540a2a3f1d7d2cd8048d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d752366d6cd4eb6b30fe924c87740a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3803cfba463142bebb7441dffdaa2806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f748dc13e89464a88012a1982ddc431",
              "IPY_MODEL_70982a3c2bc0419e8c9bee58d5b473d5",
              "IPY_MODEL_e4a3d98fb49447e6b0c3ecd6fbb07c23"
            ],
            "layout": "IPY_MODEL_80b5a4ef3ab848a1a9a8bc4a5cdd2d3f"
          }
        },
        "0f748dc13e89464a88012a1982ddc431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f1a09199f24f3491380a7a8009796c",
            "placeholder": "​",
            "style": "IPY_MODEL_67736dc2643641fe926a3ef2b4c05cbe",
            "value": "Downloading data files: 100%"
          }
        },
        "70982a3c2bc0419e8c9bee58d5b473d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a10f7ed9f0e48538655181c7147527c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e31bfabdbb941e89d29de305e8b5637",
            "value": 1
          }
        },
        "e4a3d98fb49447e6b0c3ecd6fbb07c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926839e4b4874bbe85af07bf388f5c51",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8a3d5f19fe43c1967d273099ab8a91",
            "value": " 1/1 [00:02&lt;00:00,  2.63s/it]"
          }
        },
        "80b5a4ef3ab848a1a9a8bc4a5cdd2d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f1a09199f24f3491380a7a8009796c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67736dc2643641fe926a3ef2b4c05cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a10f7ed9f0e48538655181c7147527c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e31bfabdbb941e89d29de305e8b5637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "926839e4b4874bbe85af07bf388f5c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8a3d5f19fe43c1967d273099ab8a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e6ed4d42f37411fae03083593d989d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9644eff4a8f34e12b119e7b331dad4e9",
              "IPY_MODEL_afc49a7d6c0543b1b89ea5278e53be10",
              "IPY_MODEL_d79e20b348be48a29ef82e3b9c695c4a"
            ],
            "layout": "IPY_MODEL_ed19cdc8239647dfafa7c8e8ce2e32b3"
          }
        },
        "9644eff4a8f34e12b119e7b331dad4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15bed864ded34a17af5ad12b1ee4c4ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e96fca33515f44f497e8c75f5ccf1264",
            "value": "Downloading data: 100%"
          }
        },
        "afc49a7d6c0543b1b89ea5278e53be10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb19b8f159e0426aa8db16907218dfd3",
            "max": 33262901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b1ca04e4aa4408380be2a9590de237b",
            "value": 33262901
          }
        },
        "d79e20b348be48a29ef82e3b9c695c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9d77493f234160a7f8e73806172261",
            "placeholder": "​",
            "style": "IPY_MODEL_009f88400ad540d5930ae175cf2c8108",
            "value": " 33.3M/33.3M [00:01&lt;00:00, 26.3MB/s]"
          }
        },
        "ed19cdc8239647dfafa7c8e8ce2e32b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15bed864ded34a17af5ad12b1ee4c4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96fca33515f44f497e8c75f5ccf1264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb19b8f159e0426aa8db16907218dfd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1ca04e4aa4408380be2a9590de237b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9d77493f234160a7f8e73806172261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009f88400ad540d5930ae175cf2c8108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86ce34e018dc41daa7d129623f525ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d007e00d5a4c3f9a36eb739534be4e",
              "IPY_MODEL_e5024993af2144d0a9fa68259c5ecbdb",
              "IPY_MODEL_f0a86f3b41c64bc380c7920efea263c3"
            ],
            "layout": "IPY_MODEL_21b7fde6a0d14c5aa578a864ac7e5b71"
          }
        },
        "e4d007e00d5a4c3f9a36eb739534be4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b87a1d181749488af9eb23f46024fe",
            "placeholder": "​",
            "style": "IPY_MODEL_760b4881e36c463f911beb6769ee6588",
            "value": "Extracting data files: 100%"
          }
        },
        "e5024993af2144d0a9fa68259c5ecbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979b55d6ba1c41e8a7e2cecb49a0fd14",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a04c000acd94b57be04f67a5b26965a",
            "value": 1
          }
        },
        "f0a86f3b41c64bc380c7920efea263c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5412f556fa44d6910d174c8e2584b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0a8298c3b7114facb717e483b5d2990c",
            "value": " 1/1 [00:00&lt;00:00, 23.50it/s]"
          }
        },
        "21b7fde6a0d14c5aa578a864ac7e5b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b87a1d181749488af9eb23f46024fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "760b4881e36c463f911beb6769ee6588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979b55d6ba1c41e8a7e2cecb49a0fd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a04c000acd94b57be04f67a5b26965a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e5412f556fa44d6910d174c8e2584b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8298c3b7114facb717e483b5d2990c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9b839666962421fbc05fc3c725efcc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f6a45cb311f47c4a1c33872f84f2184",
              "IPY_MODEL_5cb1e7ab42ad47a3ba176697c6e22a9d",
              "IPY_MODEL_928fd5fb25a14c3680c10673800c8e07"
            ],
            "layout": "IPY_MODEL_733860a1dac84b0da259257dda9d930e"
          }
        },
        "4f6a45cb311f47c4a1c33872f84f2184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d6026014544469b5d0bcf87df18e90",
            "placeholder": "​",
            "style": "IPY_MODEL_9c2334857ac6459796ba973e006a4780",
            "value": "Generating train split: 100%"
          }
        },
        "5cb1e7ab42ad47a3ba176697c6e22a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9124343056a54a2e9df1e2791731c211",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa3ab2f405640d3beff9b3c99a47151",
            "value": 10000
          }
        },
        "928fd5fb25a14c3680c10673800c8e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af85fa56cbaf40ab81281b1e65adac7f",
            "placeholder": "​",
            "style": "IPY_MODEL_156968a3a726473f87b578cd95e92e9a",
            "value": " 10000/10000 [00:01&lt;00:00, 9074.18 examples/s]"
          }
        },
        "733860a1dac84b0da259257dda9d930e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "03d6026014544469b5d0bcf87df18e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2334857ac6459796ba973e006a4780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9124343056a54a2e9df1e2791731c211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa3ab2f405640d3beff9b3c99a47151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af85fa56cbaf40ab81281b1e65adac7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156968a3a726473f87b578cd95e92e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89aa711acba34ad29ea3b76445be0eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9f6c36bb0cf42738d4c68330040793c",
              "IPY_MODEL_d3c7a665864245eabea0940f29d1109b",
              "IPY_MODEL_c7098c24e0504908b3c7baa0f55207ce"
            ],
            "layout": "IPY_MODEL_18e2b180f6714da487dd351d56ec6a9e"
          }
        },
        "e9f6c36bb0cf42738d4c68330040793c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b8a262ce52446b90b86e4d2c652a29",
            "placeholder": "​",
            "style": "IPY_MODEL_c317547da3f347229884b8468ab59879",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "d3c7a665864245eabea0940f29d1109b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9daf7d7cf3744c07a6f64bc4b8b0db6f",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23c0ec9c27434a54b05dadb9c38abc31",
            "value": 10000
          }
        },
        "c7098c24e0504908b3c7baa0f55207ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebdfb6b9614647e2bc235b209b57e488",
            "placeholder": "​",
            "style": "IPY_MODEL_7dc2ecb44a5d4e86bd2d7b4ba245dc85",
            "value": " 10000/10000 [01:25&lt;00:00, 212.35 examples/s]"
          }
        },
        "18e2b180f6714da487dd351d56ec6a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "18b8a262ce52446b90b86e4d2c652a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c317547da3f347229884b8468ab59879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9daf7d7cf3744c07a6f64bc4b8b0db6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c0ec9c27434a54b05dadb9c38abc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebdfb6b9614647e2bc235b209b57e488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc2ecb44a5d4e86bd2d7b4ba245dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af870668ef7d4c94abcdc65087917741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0ce69f38c44cb5964bd00b2b0ebbda",
              "IPY_MODEL_652ba460eebb4f77b2791d7e5f9b44c0",
              "IPY_MODEL_d814d827344541988d08ff013b23e816"
            ],
            "layout": "IPY_MODEL_9b6c3e466e8b448fb084a0c4977f96f3"
          }
        },
        "fe0ce69f38c44cb5964bd00b2b0ebbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0df624074bc465db646d8b00aa3a8c3",
            "placeholder": "​",
            "style": "IPY_MODEL_9579ac7250654b81a2410db981559492",
            "value": ""
          }
        },
        "652ba460eebb4f77b2791d7e5f9b44c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e27fc7ec674b7f96528974d8c3f45f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82b149c803d741f0a15e55036e441068",
            "value": 1
          }
        },
        "d814d827344541988d08ff013b23e816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0b6caf8cdb45858adfbca54605510b",
            "placeholder": "​",
            "style": "IPY_MODEL_76b556a7f2ca4f77b556e7801385c933",
            "value": " 1001/? [01:35&lt;00:00, 10.53it/s]"
          }
        },
        "9b6c3e466e8b448fb084a0c4977f96f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0df624074bc465db646d8b00aa3a8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9579ac7250654b81a2410db981559492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e27fc7ec674b7f96528974d8c3f45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "82b149c803d741f0a15e55036e441068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a0b6caf8cdb45858adfbca54605510b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b556a7f2ca4f77b556e7801385c933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}